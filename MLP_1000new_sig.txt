nohup: ignoring input
EPOCH 1:
  batch 1000 loss: 6.257483834505082
LOSS train 6.257483834505082 valid 5.044211387634277
EPOCH 2:
  batch 1000 loss: 4.919015320301056
LOSS train 4.919015320301056 valid 4.7947998046875
EPOCH 3:
  batch 1000 loss: 4.727822348356247
LOSS train 4.727822348356247 valid 4.605794906616211
EPOCH 4:
  batch 1000 loss: 4.576516386032105
LOSS train 4.576516386032105 valid 4.419104099273682
EPOCH 5:
  batch 1000 loss: 4.26635378074646
LOSS train 4.26635378074646 valid 4.085322380065918
EPOCH 6:
  batch 1000 loss: 4.004997875213623
LOSS train 4.004997875213623 valid 3.9617350101470947
EPOCH 7:
  batch 1000 loss: 3.864635941028595
LOSS train 3.864635941028595 valid 3.8265199661254883
EPOCH 8:
  batch 1000 loss: 3.8131138992309572
LOSS train 3.8131138992309572 valid 3.809910774230957
EPOCH 9:
  batch 1000 loss: 3.730357302904129
LOSS train 3.730357302904129 valid 3.743208169937134
EPOCH 10:
  batch 1000 loss: 3.6936034719944
LOSS train 3.6936034719944 valid 3.690978527069092
EPOCH 11:
  batch 1000 loss: 3.668908023357391
LOSS train 3.668908023357391 valid 3.763859510421753
EPOCH 12:
  batch 1000 loss: 3.6475788478851316
LOSS train 3.6475788478851316 valid 3.635352611541748
EPOCH 13:
  batch 1000 loss: 3.626111540079117
LOSS train 3.626111540079117 valid 3.6169188022613525
EPOCH 14:
  batch 1000 loss: 3.6167938430309294
LOSS train 3.6167938430309294 valid 3.6119441986083984
EPOCH 15:
  batch 1000 loss: 3.5827855081558226
LOSS train 3.5827855081558226 valid 3.576082229614258
EPOCH 16:
  batch 1000 loss: 3.562068649291992
LOSS train 3.562068649291992 valid 3.5491795539855957
EPOCH 17:
  batch 1000 loss: 3.557525457382202
LOSS train 3.557525457382202 valid 3.7150940895080566
EPOCH 18:
  batch 1000 loss: 3.53235503411293
LOSS train 3.53235503411293 valid 3.5397396087646484
EPOCH 19:
  batch 1000 loss: 3.542576770544052
LOSS train 3.542576770544052 valid 3.5680670738220215
EPOCH 20:
  batch 1000 loss: 3.5082218573093416
LOSS train 3.5082218573093416 valid 3.5453977584838867
EPOCH 21:
  batch 1000 loss: 3.520383534669876
LOSS train 3.520383534669876 valid 3.6002614498138428
EPOCH 22:
  batch 1000 loss: 3.49936377620697
LOSS train 3.49936377620697 valid 3.4977986812591553
EPOCH 23:
  batch 1000 loss: 3.4819463317394255
LOSS train 3.4819463317394255 valid 3.4892027378082275
EPOCH 24:
  batch 1000 loss: 3.494847197294235
LOSS train 3.494847197294235 valid 3.4752330780029297
EPOCH 25:
  batch 1000 loss: 3.4758791025877
LOSS train 3.4758791025877 valid 3.52960467338562
EPOCH 26:
  batch 1000 loss: 3.481963071346283
LOSS train 3.481963071346283 valid 3.4832658767700195
EPOCH 27:
  batch 1000 loss: 3.465566732406616
LOSS train 3.465566732406616 valid 3.4962499141693115
EPOCH 28:
  batch 1000 loss: 3.4950315916538237
LOSS train 3.4950315916538237 valid 3.462602138519287
EPOCH 29:
  batch 1000 loss: 3.450469622850418
LOSS train 3.450469622850418 valid 3.4824910163879395
EPOCH 30:
  batch 1000 loss: 3.441624369382858
LOSS train 3.441624369382858 valid 3.470471143722534
EPOCH 31:
  batch 1000 loss: 3.4421281034946443
LOSS train 3.4421281034946443 valid 3.4327754974365234
EPOCH 32:
  batch 1000 loss: 3.48022616147995
LOSS train 3.48022616147995 valid 3.434516429901123
EPOCH 33:
  batch 1000 loss: 3.4243134343624115
LOSS train 3.4243134343624115 valid 3.447313070297241
EPOCH 34:
  batch 1000 loss: 3.4444471781253814
LOSS train 3.4444471781253814 valid 3.424114465713501
EPOCH 35:
  batch 1000 loss: 3.4337787830829622
LOSS train 3.4337787830829622 valid 3.6246497631073
EPOCH 36:
  batch 1000 loss: 3.423780317783356
LOSS train 3.423780317783356 valid 3.4521689414978027
EPOCH 37:
  batch 1000 loss: 3.403558264493942
LOSS train 3.403558264493942 valid 3.471863031387329
EPOCH 38:
  batch 1000 loss: 3.4406554832458496
LOSS train 3.4406554832458496 valid 3.4207515716552734
EPOCH 39:
  batch 1000 loss: 3.4168074605464933
LOSS train 3.4168074605464933 valid 3.424359083175659
EPOCH 40:
  batch 1000 loss: 3.421715343236923
LOSS train 3.421715343236923 valid 3.4537837505340576
EPOCH 41:
  batch 1000 loss: 3.404234711885452
LOSS train 3.404234711885452 valid 3.4059643745422363
EPOCH 42:
  batch 1000 loss: 3.418343806028366
LOSS train 3.418343806028366 valid 3.489623785018921
EPOCH 43:
  batch 1000 loss: 3.404383559703827
LOSS train 3.404383559703827 valid 3.4454312324523926
EPOCH 44:
  batch 1000 loss: 3.4020016951560974
LOSS train 3.4020016951560974 valid 3.4013071060180664
EPOCH 45:
  batch 1000 loss: 3.402300931930542
LOSS train 3.402300931930542 valid 3.407881259918213
EPOCH 46:
  batch 1000 loss: 3.4123983352184295
LOSS train 3.4123983352184295 valid 3.4902477264404297
EPOCH 47:
  batch 1000 loss: 3.3905950329303742
LOSS train 3.3905950329303742 valid 3.433103322982788
EPOCH 48:
  batch 1000 loss: 3.3938312034606932
LOSS train 3.3938312034606932 valid 3.4092116355895996
EPOCH 49:
  batch 1000 loss: 3.400995191335678
LOSS train 3.400995191335678 valid 3.399230480194092
EPOCH 50:
  batch 1000 loss: 3.3918483333587646
LOSS train 3.3918483333587646 valid 3.4128506183624268
EPOCH 51:
  batch 1000 loss: 3.3873795331716536
LOSS train 3.3873795331716536 valid 3.442131996154785
EPOCH 52:
  batch 1000 loss: 3.3960919127464293
LOSS train 3.3960919127464293 valid 3.424917459487915
EPOCH 53:
  batch 1000 loss: 3.389688330411911
LOSS train 3.389688330411911 valid 3.426173686981201
EPOCH 54:
  batch 1000 loss: 3.3681402804851532
LOSS train 3.3681402804851532 valid 3.3677077293395996
EPOCH 55:
  batch 1000 loss: 3.3548437511920928
LOSS train 3.3548437511920928 valid 3.4276070594787598
EPOCH 56:
  batch 1000 loss: 3.3755559015274046
LOSS train 3.3755559015274046 valid 3.382891893386841
EPOCH 57:
  batch 1000 loss: 3.3524154382944107
LOSS train 3.3524154382944107 valid 3.375725507736206
EPOCH 58:
  batch 1000 loss: 3.3658910179138184
LOSS train 3.3658910179138184 valid 3.4566266536712646
EPOCH 59:
  batch 1000 loss: 3.383654269218445
LOSS train 3.383654269218445 valid 3.3667588233947754
EPOCH 60:
  batch 1000 loss: 3.393228508234024
LOSS train 3.393228508234024 valid 3.4272255897521973
EPOCH 61:
  batch 1000 loss: 3.383394834756851
LOSS train 3.383394834756851 valid 3.364593505859375
EPOCH 62:
  batch 1000 loss: 3.3803250164985656
LOSS train 3.3803250164985656 valid 3.4318065643310547
EPOCH 63:
  batch 1000 loss: 3.350923594713211
LOSS train 3.350923594713211 valid 3.3883535861968994
EPOCH 64:
  batch 1000 loss: 3.367591631650925
LOSS train 3.367591631650925 valid 3.3586366176605225
EPOCH 65:
  batch 1000 loss: 3.359566078901291
LOSS train 3.359566078901291 valid 3.3665244579315186
EPOCH 66:
  batch 1000 loss: 3.35344306409359
LOSS train 3.35344306409359 valid 3.3531103134155273
EPOCH 67:
  batch 1000 loss: 3.33255160176754
LOSS train 3.33255160176754 valid 3.6743366718292236
EPOCH 68:
  batch 1000 loss: 3.3483326992988585
LOSS train 3.3483326992988585 valid 3.3551483154296875
EPOCH 69:
  batch 1000 loss: 3.3633913164138796
LOSS train 3.3633913164138796 valid 3.3502635955810547
EPOCH 70:
  batch 1000 loss: 3.3485691537857054
LOSS train 3.3485691537857054 valid 3.3642385005950928
EPOCH 71:
  batch 1000 loss: 3.355213299274445
LOSS train 3.355213299274445 valid 3.3504748344421387
EPOCH 72:
  batch 1000 loss: 3.362039089679718
LOSS train 3.362039089679718 valid 3.3414580821990967
EPOCH 73:
  batch 1000 loss: 3.339694875717163
LOSS train 3.339694875717163 valid 3.3713696002960205
EPOCH 74:
  batch 1000 loss: 3.3447554354667663
LOSS train 3.3447554354667663 valid 3.3388445377349854
EPOCH 75:
  batch 1000 loss: 3.3371856071949004
LOSS train 3.3371856071949004 valid 3.341592311859131
EPOCH 76:
  batch 1000 loss: 3.343381357431412
LOSS train 3.343381357431412 valid 3.332974433898926
EPOCH 77:
  batch 1000 loss: 3.331399465560913
LOSS train 3.331399465560913 valid 3.3420917987823486
EPOCH 78:
  batch 1000 loss: 3.35516091132164
LOSS train 3.35516091132164 valid 3.3711957931518555
EPOCH 79:
  batch 1000 loss: 3.3649320504665376
LOSS train 3.3649320504665376 valid 3.3542792797088623
EPOCH 80:
  batch 1000 loss: 3.3571159875392915
LOSS train 3.3571159875392915 valid 3.356226921081543
EPOCH 81:
  batch 1000 loss: 3.3309267213344573
LOSS train 3.3309267213344573 valid 3.3531508445739746
EPOCH 82:
  batch 1000 loss: 3.3594089829921723
LOSS train 3.3594089829921723 valid 3.3292014598846436
EPOCH 83:
  batch 1000 loss: 3.3358991264104843
LOSS train 3.3358991264104843 valid 3.3417913913726807
EPOCH 84:
  batch 1000 loss: 3.339745021820068
LOSS train 3.339745021820068 valid 3.3379151821136475
EPOCH 85:
  batch 1000 loss: 3.346631525158882
LOSS train 3.346631525158882 valid 3.424257278442383
EPOCH 86:
  batch 1000 loss: 3.311451756238937
LOSS train 3.311451756238937 valid 3.342510223388672
EPOCH 87:
  batch 1000 loss: 3.344584883570671
LOSS train 3.344584883570671 valid 3.3483214378356934
EPOCH 88:
  batch 1000 loss: 3.324997462749481
Epoch 00088: reducing learning rate of group 0 to 5.0000e-04.
LOSS train 3.324997462749481 valid 3.3322136402130127
EPOCH 89:
  batch 1000 loss: 3.2602784041166304
LOSS train 3.2602784041166304 valid 3.308542013168335
EPOCH 90:
  batch 1000 loss: 3.2723036534786223
LOSS train 3.2723036534786223 valid 3.293593645095825
EPOCH 91:
  batch 1000 loss: 3.2786032831668854
LOSS train 3.2786032831668854 valid 3.2866885662078857
EPOCH 92:
  batch 1000 loss: 3.288523395895958
LOSS train 3.288523395895958 valid 3.298161029815674
EPOCH 93:
  batch 1000 loss: 3.2627724903821944
LOSS train 3.2627724903821944 valid 3.298679828643799
EPOCH 94:
  batch 1000 loss: 3.2709557325839995
LOSS train 3.2709557325839995 valid 3.285984516143799
EPOCH 95:
  batch 1000 loss: 3.2487423527240753
LOSS train 3.2487423527240753 valid 3.2786295413970947
EPOCH 96:
  batch 1000 loss: 3.2521928968429568
LOSS train 3.2521928968429568 valid 3.2785468101501465
EPOCH 97:
  batch 1000 loss: 3.2426434335708616
LOSS train 3.2426434335708616 valid 3.2754924297332764
EPOCH 98:
  batch 1000 loss: 3.2582018364667893
LOSS train 3.2582018364667893 valid 3.2767865657806396
EPOCH 99:
  batch 1000 loss: 3.2489920616149903
LOSS train 3.2489920616149903 valid 3.2897820472717285
EPOCH 100:
  batch 1000 loss: 3.247910052895546
LOSS train 3.247910052895546 valid 3.2751009464263916
EPOCH 101:
  batch 1000 loss: 3.260743420600891
LOSS train 3.260743420600891 valid 3.2774527072906494
EPOCH 102:
  batch 1000 loss: 3.2480513048171997
LOSS train 3.2480513048171997 valid 3.27927827835083
EPOCH 103:
  batch 1000 loss: 3.254295131444931
LOSS train 3.254295131444931 valid 3.2909748554229736
EPOCH 104:
  batch 1000 loss: 3.2522811799049376
LOSS train 3.2522811799049376 valid 3.2678275108337402
EPOCH 105:
  batch 1000 loss: 3.2613060622215273
LOSS train 3.2613060622215273 valid 3.286034345626831
EPOCH 106:
  batch 1000 loss: 3.247524094820023
LOSS train 3.247524094820023 valid 3.2748711109161377
EPOCH 107:
  batch 1000 loss: 3.2590035798549652
LOSS train 3.2590035798549652 valid 3.2687947750091553
EPOCH 108:
  batch 1000 loss: 3.2582481997013093
LOSS train 3.2582481997013093 valid 3.283424139022827
EPOCH 109:
  batch 1000 loss: 3.2552311642169953
LOSS train 3.2552311642169953 valid 3.2680106163024902
EPOCH 110:
  batch 1000 loss: 3.2397339797019957
Epoch 00110: reducing learning rate of group 0 to 2.5000e-04.
LOSS train 3.2397339797019957 valid 3.2808923721313477
EPOCH 111:
  batch 1000 loss: 3.223364702343941
LOSS train 3.223364702343941 valid 3.251415729522705
EPOCH 112:
  batch 1000 loss: 3.2241930539608004
LOSS train 3.2241930539608004 valid 3.2498021125793457
EPOCH 113:
  batch 1000 loss: 3.229013594865799
LOSS train 3.229013594865799 valid 3.2485296726226807
EPOCH 114:
  batch 1000 loss: 3.2161231583356855
LOSS train 3.2161231583356855 valid 3.249971866607666
EPOCH 115:
  batch 1000 loss: 3.222519353866577
LOSS train 3.222519353866577 valid 3.2453253269195557
EPOCH 116:
  batch 1000 loss: 3.231371386885643
LOSS train 3.231371386885643 valid 3.249217987060547
EPOCH 117:
  batch 1000 loss: 3.2164734275341034
LOSS train 3.2164734275341034 valid 3.247903823852539
EPOCH 118:
  batch 1000 loss: 3.222573972463608
LOSS train 3.222573972463608 valid 3.2519617080688477
EPOCH 119:
  batch 1000 loss: 3.2185906693935395
LOSS train 3.2185906693935395 valid 3.249175786972046
EPOCH 120:
  batch 1000 loss: 3.208381739497185
LOSS train 3.208381739497185 valid 3.250455617904663
EPOCH 121:
  batch 1000 loss: 3.211875839471817
Epoch 00121: reducing learning rate of group 0 to 1.2500e-04.
LOSS train 3.211875839471817 valid 3.2523868083953857
EPOCH 122:
  batch 1000 loss: 3.217712546825409
LOSS train 3.217712546825409 valid 3.2386279106140137
EPOCH 123:
  batch 1000 loss: 3.201883314847946
LOSS train 3.201883314847946 valid 3.239767074584961
EPOCH 124:
  batch 1000 loss: 3.2093777341842653
LOSS train 3.2093777341842653 valid 3.239361047744751
EPOCH 125:
  batch 1000 loss: 3.202540876507759
LOSS train 3.202540876507759 valid 3.237107276916504
EPOCH 126:
  batch 1000 loss: 3.210843878984451
LOSS train 3.210843878984451 valid 3.236787796020508
EPOCH 127:
  batch 1000 loss: 3.204402279138565
LOSS train 3.204402279138565 valid 3.234163522720337
EPOCH 128:
  batch 1000 loss: 3.193847190618515
LOSS train 3.193847190618515 valid 3.236292600631714
EPOCH 129:
  batch 1000 loss: 3.2154750517606736
LOSS train 3.2154750517606736 valid 3.2361791133880615
EPOCH 130:
  batch 1000 loss: 3.216366527915001
LOSS train 3.216366527915001 valid 3.2347307205200195
EPOCH 131:
  batch 1000 loss: 3.2037834999561308
LOSS train 3.2037834999561308 valid 3.235135316848755
EPOCH 132:
  batch 1000 loss: 3.198730785250664
LOSS train 3.198730785250664 valid 3.234288454055786
EPOCH 133:
  batch 1000 loss: 3.2211643588542938
Epoch 00133: reducing learning rate of group 0 to 6.2500e-05.
LOSS train 3.2211643588542938 valid 3.2341482639312744
EPOCH 134:
  batch 1000 loss: 3.191612885594368
LOSS train 3.191612885594368 valid 3.2300877571105957
EPOCH 135:
  batch 1000 loss: 3.1881743154525757
LOSS train 3.1881743154525757 valid 3.230865716934204
EPOCH 136:
  batch 1000 loss: 3.21197326362133
LOSS train 3.21197326362133 valid 3.2304205894470215
EPOCH 137:
  batch 1000 loss: 3.1975783426761626
LOSS train 3.1975783426761626 valid 3.230522632598877
EPOCH 138:
  batch 1000 loss: 3.18943204665184
LOSS train 3.18943204665184 valid 3.230504274368286
EPOCH 139:
  batch 1000 loss: 3.1975415954589845
LOSS train 3.1975415954589845 valid 3.2291457653045654
EPOCH 140:
  batch 1000 loss: 3.1871692953109743
LOSS train 3.1871692953109743 valid 3.2303695678710938
EPOCH 141:
  batch 1000 loss: 3.202417189836502
LOSS train 3.202417189836502 valid 3.2301995754241943
EPOCH 142:
  batch 1000 loss: 3.1979401330947876
LOSS train 3.1979401330947876 valid 3.2294716835021973
EPOCH 143:
  batch 1000 loss: 3.198177914619446
LOSS train 3.198177914619446 valid 3.228691577911377
EPOCH 144:
  batch 1000 loss: 3.2094854698181154
LOSS train 3.2094854698181154 valid 3.230710744857788
EPOCH 145:
  batch 1000 loss: 3.1998634705543516
LOSS train 3.1998634705543516 valid 3.230081796646118
EPOCH 146:
  batch 1000 loss: 3.19522221493721
LOSS train 3.19522221493721 valid 3.2307863235473633
EPOCH 147:
  batch 1000 loss: 3.1926917221546174
LOSS train 3.1926917221546174 valid 3.2311012744903564
EPOCH 148:
  batch 1000 loss: 3.2158157250881194
LOSS train 3.2158157250881194 valid 3.2298684120178223
EPOCH 149:
  batch 1000 loss: 3.209534405469894
Epoch 00149: reducing learning rate of group 0 to 3.1250e-05.
LOSS train 3.209534405469894 valid 3.2289087772369385
EPOCH 150:
  batch 1000 loss: 3.195757537841797
LOSS train 3.195757537841797 valid 3.2276580333709717
EPOCH 151:
  batch 1000 loss: 3.1965501021146774
LOSS train 3.1965501021146774 valid 3.228846549987793
EPOCH 152:
  batch 1000 loss: 3.1880564887523652
LOSS train 3.1880564887523652 valid 3.228067398071289
EPOCH 153:
  batch 1000 loss: 3.2029987754821776
LOSS train 3.2029987754821776 valid 3.2277464866638184
EPOCH 154:
  batch 1000 loss: 3.2105406732559203
LOSS train 3.2105406732559203 valid 3.2272603511810303
EPOCH 155:
  batch 1000 loss: 3.1850795891284944
LOSS train 3.1850795891284944 valid 3.227116107940674
EPOCH 156:
  batch 1000 loss: 3.1957701424360274
LOSS train 3.1957701424360274 valid 3.2267398834228516
EPOCH 157:
  batch 1000 loss: 3.204730571746826
LOSS train 3.204730571746826 valid 3.2267520427703857
EPOCH 158:
  batch 1000 loss: 3.2038165256977083
LOSS train 3.2038165256977083 valid 3.2279040813446045
EPOCH 159:
  batch 1000 loss: 3.195765514612198
LOSS train 3.195765514612198 valid 3.2276947498321533
EPOCH 160:
  batch 1000 loss: 3.1981689279079437
LOSS train 3.1981689279079437 valid 3.2268903255462646
EPOCH 161:
  batch 1000 loss: 3.1947024525403975
LOSS train 3.1947024525403975 valid 3.226806640625
EPOCH 162:
  batch 1000 loss: 3.2096116154193877
Epoch 00162: reducing learning rate of group 0 to 1.5625e-05.
LOSS train 3.2096116154193877 valid 3.226736068725586
EPOCH 163:
  batch 1000 loss: 3.187971214413643
LOSS train 3.187971214413643 valid 3.2256743907928467
EPOCH 164:
  batch 1000 loss: 3.2035704181194307
LOSS train 3.2035704181194307 valid 3.2263102531433105
EPOCH 165:
  batch 1000 loss: 3.1930734965801237
LOSS train 3.1930734965801237 valid 3.2264130115509033
EPOCH 166:
  batch 1000 loss: 3.18287396466732
LOSS train 3.18287396466732 valid 3.226710796356201
EPOCH 167:
  batch 1000 loss: 3.185092252492905
LOSS train 3.185092252492905 valid 3.2254014015197754
EPOCH 168:
  batch 1000 loss: 3.1958541033267975
LOSS train 3.1958541033267975 valid 3.2264211177825928
EPOCH 169:
  batch 1000 loss: 3.1873087043762207
Epoch 00169: reducing learning rate of group 0 to 7.8125e-06.
LOSS train 3.1873087043762207 valid 3.2258474826812744
EPOCH 170:
  batch 1000 loss: 3.1930491089820863
LOSS train 3.1930491089820863 valid 3.226654291152954
EPOCH 171:
  batch 1000 loss: 3.1956910293102263
LOSS train 3.1956910293102263 valid 3.226120948791504
EPOCH 172:
  batch 1000 loss: 3.1957818019390105
LOSS train 3.1957818019390105 valid 3.224872350692749
EPOCH 173:
  batch 1000 loss: 3.1915996181964874
LOSS train 3.1915996181964874 valid 3.223595380783081
EPOCH 174:
  batch 1000 loss: 3.1871325986385344
LOSS train 3.1871325986385344 valid 3.2249538898468018
EPOCH 175:
  batch 1000 loss: 3.1928210804462434
LOSS train 3.1928210804462434 valid 3.225005626678467
EPOCH 176:
  batch 1000 loss: 3.206226541519165
LOSS train 3.206226541519165 valid 3.2255499362945557
EPOCH 177:
  batch 1000 loss: 3.1847919075489046
LOSS train 3.1847919075489046 valid 3.2260220050811768
EPOCH 178:
  batch 1000 loss: 3.194304996609688
LOSS train 3.194304996609688 valid 3.2247982025146484
EPOCH 179:
  batch 1000 loss: 3.1930234577655794
Epoch 00179: reducing learning rate of group 0 to 3.9063e-06.
LOSS train 3.1930234577655794 valid 3.2252848148345947
EPOCH 180:
  batch 1000 loss: 3.1954084523916246
LOSS train 3.1954084523916246 valid 3.225538969039917
EPOCH 181:
  batch 1000 loss: 3.198263921022415
LOSS train 3.198263921022415 valid 3.2253737449645996
EPOCH 182:
  batch 1000 loss: 3.185882302045822
LOSS train 3.185882302045822 valid 3.226114273071289
EPOCH 183:
  batch 1000 loss: 3.2012718863487244
LOSS train 3.2012718863487244 valid 3.225541830062866
EPOCH 184:
  batch 1000 loss: 3.1974444156885147
LOSS train 3.1974444156885147 valid 3.2254819869995117
EPOCH 185:
  batch 1000 loss: 3.2007777087688445
Epoch 00185: reducing learning rate of group 0 to 1.9531e-06.
LOSS train 3.2007777087688445 valid 3.22567081451416
EPOCH 186:
  batch 1000 loss: 3.1771452004909517
LOSS train 3.1771452004909517 valid 3.2252984046936035
EPOCH 187:
  batch 1000 loss: 3.1779733847379683
LOSS train 3.1779733847379683 valid 3.224761724472046
EPOCH 188:
  batch 1000 loss: 3.189545694708824
LOSS train 3.189545694708824 valid 3.2254140377044678
EPOCH 189:
  batch 1000 loss: 3.1837226295471193
LOSS train 3.1837226295471193 valid 3.225226640701294
EPOCH 190:
  batch 1000 loss: 3.187691447496414
LOSS train 3.187691447496414 valid 3.2261290550231934
EPOCH 191:
  batch 1000 loss: 3.2003910554647446
Epoch 00191: reducing learning rate of group 0 to 9.7656e-07.
LOSS train 3.2003910554647446 valid 3.225360155105591
EPOCH 192:
  batch 1000 loss: 3.2021194220781326
LOSS train 3.2021194220781326 valid 3.224876642227173
EPOCH 193:
  batch 1000 loss: 3.2062917046546935
LOSS train 3.2062917046546935 valid 3.225733995437622
EPOCH 194:
  batch 1000 loss: 3.189272756099701
LOSS train 3.189272756099701 valid 3.224738359451294
EPOCH 195:
  batch 1000 loss: 3.1896889846324923
LOSS train 3.1896889846324923 valid 3.2257468700408936
EPOCH 196:
  batch 1000 loss: 3.191496326684952
LOSS train 3.191496326684952 valid 3.225207805633545
EPOCH 197:
  batch 1000 loss: 3.1882599864006043
Epoch 00197: reducing learning rate of group 0 to 4.8828e-07.
LOSS train 3.1882599864006043 valid 3.2244651317596436
EPOCH 198:
  batch 1000 loss: 3.178055951595306
LOSS train 3.178055951595306 valid 3.2261385917663574
EPOCH 199:
  batch 1000 loss: 3.19180016541481
LOSS train 3.19180016541481 valid 3.2241358757019043
EPOCH 200:
  batch 1000 loss: 3.2093023697137832
LOSS train 3.2093023697137832 valid 3.225553274154663
EPOCH 201:
  batch 1000 loss: 3.1949031261205674
LOSS train 3.1949031261205674 valid 3.2247180938720703
EPOCH 202:
  batch 1000 loss: 3.1764639699459076
LOSS train 3.1764639699459076 valid 3.2251086235046387
EPOCH 203:
  batch 1000 loss: 3.1842269649505615
Epoch 00203: reducing learning rate of group 0 to 2.4414e-07.
LOSS train 3.1842269649505615 valid 3.2248315811157227
EPOCH 204:
  batch 1000 loss: 3.1974254212379454
LOSS train 3.1974254212379454 valid 3.2253599166870117
EPOCH 205:
  batch 1000 loss: 3.2047039139270783
LOSS train 3.2047039139270783 valid 3.2257232666015625
EPOCH 206:
  batch 1000 loss: 3.180455408215523
LOSS train 3.180455408215523 valid 3.225172281265259
EPOCH 207:
  batch 1000 loss: 3.1907661776542664
LOSS train 3.1907661776542664 valid 3.225660562515259
EPOCH 208:
  batch 1000 loss: 3.1681434828042985
LOSS train 3.1681434828042985 valid 3.2251527309417725
EPOCH 209:
  batch 1000 loss: 3.1900186495780947
Epoch 00209: reducing learning rate of group 0 to 1.2207e-07.
LOSS train 3.1900186495780947 valid 3.22593355178833
EPOCH 210:
  batch 1000 loss: 3.1997912697792055
LOSS train 3.1997912697792055 valid 3.225520133972168
EPOCH 211:
  batch 1000 loss: 3.1923190095424654
LOSS train 3.1923190095424654 valid 3.2253804206848145
EPOCH 212:
  batch 1000 loss: 3.1930922849178316
LOSS train 3.1930922849178316 valid 3.2239484786987305
EPOCH 213:
  batch 1000 loss: 3.1948523753881455
LOSS train 3.1948523753881455 valid 3.2241263389587402
EPOCH 214:
  batch 1000 loss: 3.2087594408988953
LOSS train 3.2087594408988953 valid 3.224526882171631
EPOCH 215:
  batch 1000 loss: 3.1878710067272187
Epoch 00215: reducing learning rate of group 0 to 6.1035e-08.
LOSS train 3.1878710067272187 valid 3.225229024887085
EPOCH 216:
  batch 1000 loss: 3.211576330900192
LOSS train 3.211576330900192 valid 3.2256009578704834
EPOCH 217:
  batch 1000 loss: 3.1856053245067595
LOSS train 3.1856053245067595 valid 3.2253215312957764
EPOCH 218:
  batch 1000 loss: 3.197409963130951
LOSS train 3.197409963130951 valid 3.225388526916504
EPOCH 219:
  batch 1000 loss: 3.200063700914383
LOSS train 3.200063700914383 valid 3.2246549129486084
EPOCH 220:
  batch 1000 loss: 3.173999130368233
LOSS train 3.173999130368233 valid 3.2261040210723877
EPOCH 221:
  batch 1000 loss: 3.2072497458457945
Epoch 00221: reducing learning rate of group 0 to 3.0518e-08.
LOSS train 3.2072497458457945 valid 3.2244930267333984
EPOCH 222:
  batch 1000 loss: 3.188814831972122
LOSS train 3.188814831972122 valid 3.225167751312256
EPOCH 223:
  batch 1000 loss: 3.194743463397026
LOSS train 3.194743463397026 valid 3.225611925125122
EPOCH 224:
  batch 1000 loss: 3.182384158730507
LOSS train 3.182384158730507 valid 3.2243685722351074
EPOCH 225:
  batch 1000 loss: 3.192930505275726
LOSS train 3.192930505275726 valid 3.2245311737060547
EPOCH 226:
  batch 1000 loss: 3.201666224002838
LOSS train 3.201666224002838 valid 3.225374937057495
EPOCH 227:
  batch 1000 loss: 3.194312668323517
Epoch 00227: reducing learning rate of group 0 to 1.5259e-08.
LOSS train 3.194312668323517 valid 3.225956439971924
EPOCH 228:
  batch 1000 loss: 3.1907147244215013
LOSS train 3.1907147244215013 valid 3.225172281265259
EPOCH 229:
  batch 1000 loss: 3.195601300597191
LOSS train 3.195601300597191 valid 3.2252960205078125
EPOCH 230:
  batch 1000 loss: 3.2045286979675294
LOSS train 3.2045286979675294 valid 3.225175619125366
EPOCH 231:
  batch 1000 loss: 3.210783147931099
LOSS train 3.210783147931099 valid 3.225248098373413
EPOCH 232:
  batch 1000 loss: 3.1957262177467345
LOSS train 3.1957262177467345 valid 3.2255539894104004
EPOCH 233:
  batch 1000 loss: 3.176519228100777
LOSS train 3.176519228100777 valid 3.2260818481445312
EPOCH 234:
  batch 1000 loss: 3.2137360219955444
LOSS train 3.2137360219955444 valid 3.225308895111084
EPOCH 235:
  batch 1000 loss: 3.203112276315689
LOSS train 3.203112276315689 valid 3.2254464626312256
EPOCH 236:
  batch 1000 loss: 3.2014721423387527
LOSS train 3.2014721423387527 valid 3.2251806259155273
EPOCH 237:
  batch 1000 loss: 3.20260311627388
LOSS train 3.20260311627388 valid 3.2254769802093506
EPOCH 238:
  batch 1000 loss: 3.2044944469928742
LOSS train 3.2044944469928742 valid 3.223989725112915
EPOCH 239:
  batch 1000 loss: 3.1776269429922106
LOSS train 3.1776269429922106 valid 3.2254180908203125
EPOCH 240:
  batch 1000 loss: 3.183557606458664
LOSS train 3.183557606458664 valid 3.2253613471984863
EPOCH 241:
  batch 1000 loss: 3.2045698903799056
LOSS train 3.2045698903799056 valid 3.225931406021118
EPOCH 242:
  batch 1000 loss: 3.199234828233719
LOSS train 3.199234828233719 valid 3.2247462272644043
EPOCH 243:
  batch 1000 loss: 3.198324033498764
LOSS train 3.198324033498764 valid 3.225618362426758
EPOCH 244:
  batch 1000 loss: 3.207971769571304
LOSS train 3.207971769571304 valid 3.2252895832061768
EPOCH 245:
  batch 1000 loss: 3.195728772044182
LOSS train 3.195728772044182 valid 3.2260169982910156
EPOCH 246:
  batch 1000 loss: 3.194847170352936
LOSS train 3.194847170352936 valid 3.2246499061584473
EPOCH 247:
  batch 1000 loss: 3.1848608162403105
LOSS train 3.1848608162403105 valid 3.225330352783203
EPOCH 248:
  batch 1000 loss: 3.216001669883728
LOSS train 3.216001669883728 valid 3.2262966632843018
EPOCH 249:
  batch 1000 loss: 3.2059443272352217
LOSS train 3.2059443272352217 valid 3.2252159118652344
EPOCH 250:
  batch 1000 loss: 3.198441410064697
LOSS train 3.198441410064697 valid 3.2260096073150635
EPOCH 251:
  batch 1000 loss: 3.1870313433408737
LOSS train 3.1870313433408737 valid 3.2244691848754883
EPOCH 252:
  batch 1000 loss: 3.198432340860367
LOSS train 3.198432340860367 valid 3.225829839706421
EPOCH 253:
  batch 1000 loss: 3.1889290384054183
LOSS train 3.1889290384054183 valid 3.225281238555908
EPOCH 254:
  batch 1000 loss: 3.195874801158905
LOSS train 3.195874801158905 valid 3.22529935836792
EPOCH 255:
  batch 1000 loss: 3.1974854190349578
LOSS train 3.1974854190349578 valid 3.2247378826141357
EPOCH 256:
  batch 1000 loss: 3.184649702310562
LOSS train 3.184649702310562 valid 3.2251698970794678
EPOCH 257:
  batch 1000 loss: 3.175736607789993
LOSS train 3.175736607789993 valid 3.2263412475585938
EPOCH 258:
  batch 1000 loss: 3.180154350042343
LOSS train 3.180154350042343 valid 3.2261297702789307
EPOCH 259:
  batch 1000 loss: 3.189821352481842
LOSS train 3.189821352481842 valid 3.224709987640381
EPOCH 260:
  batch 1000 loss: 3.192238349556923
LOSS train 3.192238349556923 valid 3.225128412246704
EPOCH 261:
  batch 1000 loss: 3.21185182762146
LOSS train 3.21185182762146 valid 3.225152015686035
EPOCH 262:
  batch 1000 loss: 3.2012141182422638
LOSS train 3.2012141182422638 valid 3.2247254848480225
EPOCH 263:
  batch 1000 loss: 3.1958049310445786
LOSS train 3.1958049310445786 valid 3.2246458530426025
EPOCH 264:
  batch 1000 loss: 3.206051309108734
LOSS train 3.206051309108734 valid 3.2266180515289307
EPOCH 265:
  batch 1000 loss: 3.204549404859543
LOSS train 3.204549404859543 valid 3.2253966331481934
EPOCH 266:
  batch 1000 loss: 3.197602227449417
LOSS train 3.197602227449417 valid 3.2260706424713135
EPOCH 267:
  batch 1000 loss: 3.185625112295151
LOSS train 3.185625112295151 valid 3.225120782852173
EPOCH 268:
  batch 1000 loss: 3.205928187608719
LOSS train 3.205928187608719 valid 3.225308895111084
EPOCH 269:
  batch 1000 loss: 3.200787539482117
LOSS train 3.200787539482117 valid 3.2252793312072754
EPOCH 270:
  batch 1000 loss: 3.205483400583267
LOSS train 3.205483400583267 valid 3.2253575325012207
EPOCH 271:
  batch 1000 loss: 3.2137270687818527
LOSS train 3.2137270687818527 valid 3.223963975906372
EPOCH 272:
  batch 1000 loss: 3.1784560540914537
LOSS train 3.1784560540914537 valid 3.2248528003692627
EPOCH 273:
  batch 1000 loss: 3.184567272186279
LOSS train 3.184567272186279 valid 3.22532057762146
EPOCH 274:
  batch 1000 loss: 3.200202297091484
LOSS train 3.200202297091484 valid 3.2244439125061035
EPOCH 275:
  batch 1000 loss: 3.1948485703468323
LOSS train 3.1948485703468323 valid 3.225661277770996
EPOCH 276:
  batch 1000 loss: 3.1948348395824433
LOSS train 3.1948348395824433 valid 3.226090669631958
EPOCH 277:
  batch 1000 loss: 3.2080339846611023
LOSS train 3.2080339846611023 valid 3.225163459777832
EPOCH 278:
  batch 1000 loss: 3.1824143431186678
LOSS train 3.1824143431186678 valid 3.2253165245056152
EPOCH 279:
  batch 1000 loss: 3.198472182750702
LOSS train 3.198472182750702 valid 3.22529935836792
EPOCH 280:
  batch 1000 loss: 3.2048038952350617
LOSS train 3.2048038952350617 valid 3.2264392375946045
EPOCH 281:
  batch 1000 loss: 3.187540966749191
LOSS train 3.187540966749191 valid 3.226081132888794
EPOCH 282:
  batch 1000 loss: 3.2069531140327454
LOSS train 3.2069531140327454 valid 3.224531650543213
EPOCH 283:
  batch 1000 loss: 3.192800722837448
LOSS train 3.192800722837448 valid 3.2254884243011475
EPOCH 284:
  batch 1000 loss: 3.1927476580142975
LOSS train 3.1927476580142975 valid 3.2245867252349854
EPOCH 285:
  batch 1000 loss: 3.2019156625270844
LOSS train 3.2019156625270844 valid 3.226267099380493
EPOCH 286:
  batch 1000 loss: 3.1954802091121675
LOSS train 3.1954802091121675 valid 3.225599527359009
EPOCH 287:
  batch 1000 loss: 3.1959735429286957
LOSS train 3.1959735429286957 valid 3.2246499061584473
EPOCH 288:
  batch 1000 loss: 3.1951038613319396
LOSS train 3.1951038613319396 valid 3.2245986461639404
EPOCH 289:
  batch 1000 loss: 3.1897601375579834
LOSS train 3.1897601375579834 valid 3.2254772186279297
EPOCH 290:
  batch 1000 loss: 3.1817174102067947
LOSS train 3.1817174102067947 valid 3.225080728530884
EPOCH 291:
  batch 1000 loss: 3.186411289215088
LOSS train 3.186411289215088 valid 3.2259926795959473
EPOCH 292:
  batch 1000 loss: 3.186682728171349
LOSS train 3.186682728171349 valid 3.225893259048462
EPOCH 293:
  batch 1000 loss: 3.1864953112602232
LOSS train 3.1864953112602232 valid 3.225337505340576
EPOCH 294:
  batch 1000 loss: 3.2088169239759443
LOSS train 3.2088169239759443 valid 3.2251861095428467
EPOCH 295:
  batch 1000 loss: 3.197493463039398
LOSS train 3.197493463039398 valid 3.2255444526672363
EPOCH 296:
  batch 1000 loss: 3.1923267068862917
LOSS train 3.1923267068862917 valid 3.2247140407562256
EPOCH 297:
  batch 1000 loss: 3.196023052096367
LOSS train 3.196023052096367 valid 3.225571632385254
EPOCH 298:
  batch 1000 loss: 3.19141000854969
LOSS train 3.19141000854969 valid 3.225634813308716
EPOCH 299:
  batch 1000 loss: 3.176543482542038
LOSS train 3.176543482542038 valid 3.2255539894104004
EPOCH 300:
  batch 1000 loss: 3.195305431127548
LOSS train 3.195305431127548 valid 3.226163864135742
EPOCH 301:
  batch 1000 loss: 3.1936470980644227
LOSS train 3.1936470980644227 valid 3.2246406078338623
EPOCH 302:
  batch 1000 loss: 3.202916393995285
LOSS train 3.202916393995285 valid 3.2254130840301514
EPOCH 303:
  batch 1000 loss: 3.1951452326774596
LOSS train 3.1951452326774596 valid 3.2247719764709473
EPOCH 304:
  batch 1000 loss: 3.199236032485962
LOSS train 3.199236032485962 valid 3.224693536758423
EPOCH 305:
  batch 1000 loss: 3.1954649369716646
LOSS train 3.1954649369716646 valid 3.2251675128936768
EPOCH 306:
  batch 1000 loss: 3.2003201212882995
LOSS train 3.2003201212882995 valid 3.2255098819732666
EPOCH 307:
  batch 1000 loss: 3.205331533908844
LOSS train 3.205331533908844 valid 3.225398302078247
EPOCH 308:
  batch 1000 loss: 3.2025700883865356
LOSS train 3.2025700883865356 valid 3.2243523597717285
EPOCH 309:
  batch 1000 loss: 3.1880081582069395
LOSS train 3.1880081582069395 valid 3.224560260772705
EPOCH 310:
  batch 1000 loss: 3.1974969612360002
LOSS train 3.1974969612360002 valid 3.2244296073913574
EPOCH 311:
  batch 1000 loss: 3.2077894021272657
LOSS train 3.2077894021272657 valid 3.2253878116607666
EPOCH 312:
  batch 1000 loss: 3.1958739955425264
LOSS train 3.1958739955425264 valid 3.2241780757904053
EPOCH 313:
  batch 1000 loss: 3.185697643637657
LOSS train 3.185697643637657 valid 3.225480318069458
EPOCH 314:
  batch 1000 loss: 3.1928407306671143
LOSS train 3.1928407306671143 valid 3.2252860069274902
EPOCH 315:
  batch 1000 loss: 3.186203082203865
LOSS train 3.186203082203865 valid 3.225196123123169
EPOCH 316:
  batch 1000 loss: 3.192910921931267
LOSS train 3.192910921931267 valid 3.224646806716919
EPOCH 317:
  batch 1000 loss: 3.2013942681550978
LOSS train 3.2013942681550978 valid 3.2260897159576416
EPOCH 318:
  batch 1000 loss: 3.1808468512296675
LOSS train 3.1808468512296675 valid 3.2269716262817383
EPOCH 319:
  batch 1000 loss: 3.1988717226982115
LOSS train 3.1988717226982115 valid 3.2252681255340576
EPOCH 320:
  batch 1000 loss: 3.1958508155345915
LOSS train 3.1958508155345915 valid 3.224642038345337
EPOCH 321:
  batch 1000 loss: 3.1891185322999953
LOSS train 3.1891185322999953 valid 3.224533796310425
EPOCH 322:
  batch 1000 loss: 3.187012840151787
LOSS train 3.187012840151787 valid 3.2243666648864746
EPOCH 323:
  batch 1000 loss: 3.1959930609464644
LOSS train 3.1959930609464644 valid 3.2260708808898926
EPOCH 324:
  batch 1000 loss: 3.1941830793619155
LOSS train 3.1941830793619155 valid 3.2255241870880127
EPOCH 325:
  batch 1000 loss: 3.209988608121872
LOSS train 3.209988608121872 valid 3.2248363494873047
EPOCH 326:
  batch 1000 loss: 3.1980443395376206
LOSS train 3.1980443395376206 valid 3.2242562770843506
EPOCH 327:
  batch 1000 loss: 3.2004761765003202
LOSS train 3.2004761765003202 valid 3.2249948978424072
EPOCH 328:
  batch 1000 loss: 3.1942876012325288
LOSS train 3.1942876012325288 valid 3.226151704788208
EPOCH 329:
  batch 1000 loss: 3.201759124517441
LOSS train 3.201759124517441 valid 3.225116729736328
EPOCH 330:
  batch 1000 loss: 3.188976852893829
LOSS train 3.188976852893829 valid 3.2260870933532715
EPOCH 331:
  batch 1000 loss: 3.1942691955566405
LOSS train 3.1942691955566405 valid 3.226227045059204
EPOCH 332:
  batch 1000 loss: 3.1971949944496156
LOSS train 3.1971949944496156 valid 3.225360155105591
EPOCH 333:
  batch 1000 loss: 3.1940539309978484
LOSS train 3.1940539309978484 valid 3.225733995437622
EPOCH 334:
  batch 1000 loss: 3.1942762691974638
LOSS train 3.1942762691974638 valid 3.2253341674804688
EPOCH 335:
  batch 1000 loss: 3.1889618353843687
LOSS train 3.1889618353843687 valid 3.2251548767089844
EPOCH 336:
  batch 1000 loss: 3.1885593938827514
LOSS train 3.1885593938827514 valid 3.225142002105713
EPOCH 337:
  batch 1000 loss: 3.196237959384918
LOSS train 3.196237959384918 valid 3.2252004146575928
EPOCH 338:
  batch 1000 loss: 3.201314544439316
LOSS train 3.201314544439316 valid 3.2251546382904053
EPOCH 339:
  batch 1000 loss: 3.2078648397922516
LOSS train 3.2078648397922516 valid 3.223881483078003
EPOCH 340:
  batch 1000 loss: 3.1897564177513122
LOSS train 3.1897564177513122 valid 3.2259953022003174
EPOCH 341:
  batch 1000 loss: 3.196694006919861
LOSS train 3.196694006919861 valid 3.2264761924743652
EPOCH 342:
  batch 1000 loss: 3.1781165825128554
LOSS train 3.1781165825128554 valid 3.2245261669158936
EPOCH 343:
  batch 1000 loss: 3.194185935020447
LOSS train 3.194185935020447 valid 3.226153612136841
EPOCH 344:
  batch 1000 loss: 3.205501079797745
LOSS train 3.205501079797745 valid 3.2254700660705566
EPOCH 345:
  batch 1000 loss: 3.1833325036764144
LOSS train 3.1833325036764144 valid 3.225173234939575
EPOCH 346:
  batch 1000 loss: 3.18748445224762
LOSS train 3.18748445224762 valid 3.22515869140625
EPOCH 347:
  batch 1000 loss: 3.1984334864616395
LOSS train 3.1984334864616395 valid 3.225236177444458
EPOCH 348:
  batch 1000 loss: 3.2019231023788453
LOSS train 3.2019231023788453 valid 3.224630355834961
EPOCH 349:
  batch 1000 loss: 3.1903907618522642
LOSS train 3.1903907618522642 valid 3.224609375
EPOCH 350:
  batch 1000 loss: 3.1879557693004608
LOSS train 3.1879557693004608 valid 3.223538398742676
EPOCH 351:
  batch 1000 loss: 3.2035281920433043
LOSS train 3.2035281920433043 valid 3.225277900695801
EPOCH 352:
  batch 1000 loss: 3.185212571620941
LOSS train 3.185212571620941 valid 3.2252235412597656
EPOCH 353:
  batch 1000 loss: 3.1896305620670318
LOSS train 3.1896305620670318 valid 3.2261083126068115
EPOCH 354:
  batch 1000 loss: 3.1923340559005737
LOSS train 3.1923340559005737 valid 3.225149393081665
EPOCH 355:
  batch 1000 loss: 3.198162992477417
LOSS train 3.198162992477417 valid 3.2244224548339844
EPOCH 356:
  batch 1000 loss: 3.1822046983242034
LOSS train 3.1822046983242034 valid 3.225292205810547
EPOCH 357:
  batch 1000 loss: 3.193896294593811
LOSS train 3.193896294593811 valid 3.225935459136963
EPOCH 358:
  batch 1000 loss: 3.1771995877027512
LOSS train 3.1771995877027512 valid 3.2244958877563477
EPOCH 359:
  batch 1000 loss: 3.1974615771770476
LOSS train 3.1974615771770476 valid 3.2248220443725586
EPOCH 360:
  batch 1000 loss: 3.1969866312742234
LOSS train 3.1969866312742234 valid 3.224381446838379
EPOCH 361:
  batch 1000 loss: 3.1847755222320555
LOSS train 3.1847755222320555 valid 3.2244489192962646
EPOCH 362:
  batch 1000 loss: 3.211094453573227
LOSS train 3.211094453573227 valid 3.2265889644622803
EPOCH 363:
  batch 1000 loss: 3.203806918263435
LOSS train 3.203806918263435 valid 3.2252144813537598
EPOCH 364:
  batch 1000 loss: 3.2039923623800277
LOSS train 3.2039923623800277 valid 3.2246387004852295
EPOCH 365:
  batch 1000 loss: 3.1968779487609864
LOSS train 3.1968779487609864 valid 3.2258386611938477
EPOCH 366:
  batch 1000 loss: 3.1968704664707186
LOSS train 3.1968704664707186 valid 3.224726915359497
EPOCH 367:
  batch 1000 loss: 3.2087745645046235
LOSS train 3.2087745645046235 valid 3.2251343727111816
EPOCH 368:
  batch 1000 loss: 3.176347554445267
LOSS train 3.176347554445267 valid 3.225133180618286
EPOCH 369:
  batch 1000 loss: 3.196751583099365
LOSS train 3.196751583099365 valid 3.225142478942871
EPOCH 370:
