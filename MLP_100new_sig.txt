nohup: ignoring input
EPOCH 1:
  batch 1000 loss: 6.395884081363678
LOSS train 6.395884081363678 valid 5.160440921783447
EPOCH 2:
  batch 1000 loss: 4.996022285699844
LOSS train 4.996022285699844 valid 4.8530778884887695
EPOCH 3:
  batch 1000 loss: 4.770018885612488
LOSS train 4.770018885612488 valid 4.6916046142578125
EPOCH 4:
  batch 1000 loss: 4.541793182373047
LOSS train 4.541793182373047 valid 4.455389976501465
EPOCH 5:
  batch 1000 loss: 4.38271373462677
LOSS train 4.38271373462677 valid 4.34716272354126
EPOCH 6:
  batch 1000 loss: 4.2553450589179995
LOSS train 4.2553450589179995 valid 4.217308044433594
EPOCH 7:
  batch 1000 loss: 4.185804934740067
LOSS train 4.185804934740067 valid 4.161739826202393
EPOCH 8:
  batch 1000 loss: 4.097269989013672
LOSS train 4.097269989013672 valid 4.083569049835205
EPOCH 9:
  batch 1000 loss: 4.061524397611618
LOSS train 4.061524397611618 valid 4.038296699523926
EPOCH 10:
  batch 1000 loss: 4.015055559396743
LOSS train 4.015055559396743 valid 4.0162200927734375
EPOCH 11:
  batch 1000 loss: 3.96905952167511
LOSS train 3.96905952167511 valid 3.9723105430603027
EPOCH 12:
  batch 1000 loss: 3.947298272371292
LOSS train 3.947298272371292 valid 3.973330497741699
EPOCH 13:
  batch 1000 loss: 3.9276468124389647
LOSS train 3.9276468124389647 valid 3.9551808834075928
EPOCH 14:
  batch 1000 loss: 3.8841581547260287
LOSS train 3.8841581547260287 valid 3.9253787994384766
EPOCH 15:
  batch 1000 loss: 3.85546523976326
LOSS train 3.85546523976326 valid 3.900926113128662
EPOCH 16:
  batch 1000 loss: 3.8758297061920164
LOSS train 3.8758297061920164 valid 3.8811190128326416
EPOCH 17:
  batch 1000 loss: 3.87701055932045
LOSS train 3.87701055932045 valid 3.8473780155181885
EPOCH 18:
  batch 1000 loss: 3.834951143026352
LOSS train 3.834951143026352 valid 3.875356674194336
EPOCH 19:
  batch 1000 loss: 3.8151978743076325
LOSS train 3.8151978743076325 valid 3.8454554080963135
EPOCH 20:
  batch 1000 loss: 3.8114289581775664
LOSS train 3.8114289581775664 valid 3.842082977294922
EPOCH 21:
  batch 1000 loss: 3.841329667210579
LOSS train 3.841329667210579 valid 3.8358876705169678
EPOCH 22:
  batch 1000 loss: 3.8050385687351227
LOSS train 3.8050385687351227 valid 3.8515920639038086
EPOCH 23:
  batch 1000 loss: 3.802871481180191
LOSS train 3.802871481180191 valid 3.815541982650757
EPOCH 24:
  batch 1000 loss: 3.8023068602085113
LOSS train 3.8023068602085113 valid 3.8507933616638184
EPOCH 25:
  batch 1000 loss: 3.786592621445656
LOSS train 3.786592621445656 valid 3.797966241836548
EPOCH 26:
  batch 1000 loss: 3.784444196462631
LOSS train 3.784444196462631 valid 3.8120827674865723
EPOCH 27:
  batch 1000 loss: 3.7711053173542024
LOSS train 3.7711053173542024 valid 3.786316156387329
EPOCH 28:
  batch 1000 loss: 3.762886803627014
LOSS train 3.762886803627014 valid 3.7863330841064453
EPOCH 29:
  batch 1000 loss: 3.7568917368650436
LOSS train 3.7568917368650436 valid 3.833116054534912
EPOCH 30:
  batch 1000 loss: 3.7565688641071318
LOSS train 3.7565688641071318 valid 3.759643316268921
EPOCH 31:
  batch 1000 loss: 3.7380975997447967
LOSS train 3.7380975997447967 valid 3.7666964530944824
EPOCH 32:
  batch 1000 loss: 3.766811879634857
LOSS train 3.766811879634857 valid 3.8063228130340576
EPOCH 33:
  batch 1000 loss: 3.7304125430583954
LOSS train 3.7304125430583954 valid 3.8380026817321777
EPOCH 34:
  batch 1000 loss: 3.747705696463585
LOSS train 3.747705696463585 valid 3.7649359703063965
EPOCH 35:
  batch 1000 loss: 3.7365461683273313
LOSS train 3.7365461683273313 valid 3.7458155155181885
EPOCH 36:
  batch 1000 loss: 3.7343411996364595
LOSS train 3.7343411996364595 valid 3.7481958866119385
EPOCH 37:
  batch 1000 loss: 3.744350919961929
LOSS train 3.744350919961929 valid 3.72933030128479
EPOCH 38:
  batch 1000 loss: 3.6940685712099075
LOSS train 3.6940685712099075 valid 3.7363369464874268
EPOCH 39:
  batch 1000 loss: 3.719450716853142
LOSS train 3.719450716853142 valid 3.731170892715454
EPOCH 40:
  batch 1000 loss: 3.7390750254392624
LOSS train 3.7390750254392624 valid 3.714251756668091
EPOCH 41:
  batch 1000 loss: 3.703898948669434
LOSS train 3.703898948669434 valid 3.708801746368408
EPOCH 42:
  batch 1000 loss: 3.6892727530002594
LOSS train 3.6892727530002594 valid 3.752467632293701
EPOCH 43:
  batch 1000 loss: 3.7286946024894716
LOSS train 3.7286946024894716 valid 3.700472354888916
EPOCH 44:
  batch 1000 loss: 3.6879947789907455
LOSS train 3.6879947789907455 valid 3.731013536453247
EPOCH 45:
  batch 1000 loss: 3.7027725998163223
LOSS train 3.7027725998163223 valid 3.716789722442627
EPOCH 46:
  batch 1000 loss: 3.7123259123563765
LOSS train 3.7123259123563765 valid 3.7048025131225586
EPOCH 47:
  batch 1000 loss: 3.683805191040039
LOSS train 3.683805191040039 valid 3.713848829269409
EPOCH 48:
  batch 1000 loss: 3.6993911774158477
LOSS train 3.6993911774158477 valid 3.7027804851531982
EPOCH 49:
  batch 1000 loss: 3.7095655169487
LOSS train 3.7095655169487 valid 3.6970043182373047
EPOCH 50:
  batch 1000 loss: 3.673772216320038
LOSS train 3.673772216320038 valid 3.742763042449951
EPOCH 51:
  batch 1000 loss: 3.6868661181926727
LOSS train 3.6868661181926727 valid 3.720444917678833
EPOCH 52:
  batch 1000 loss: 3.716126235961914
LOSS train 3.716126235961914 valid 3.7309377193450928
EPOCH 53:
  batch 1000 loss: 3.682271011352539
LOSS train 3.682271011352539 valid 3.6810920238494873
EPOCH 54:
  batch 1000 loss: 3.667529485464096
LOSS train 3.667529485464096 valid 3.7080276012420654
EPOCH 55:
  batch 1000 loss: 3.668195772886276
LOSS train 3.668195772886276 valid 3.697192430496216
EPOCH 56:
  batch 1000 loss: 3.6577652382850645
LOSS train 3.6577652382850645 valid 3.687584400177002
EPOCH 57:
  batch 1000 loss: 3.6802514204978944
LOSS train 3.6802514204978944 valid 3.6775569915771484
EPOCH 58:
  batch 1000 loss: 3.6364731149673464
LOSS train 3.6364731149673464 valid 3.6756632328033447
EPOCH 59:
  batch 1000 loss: 3.6463306294679643
LOSS train 3.6463306294679643 valid 3.714185953140259
EPOCH 60:
  batch 1000 loss: 3.6593154122829437
LOSS train 3.6593154122829437 valid 3.679417848587036
EPOCH 61:
  batch 1000 loss: 3.662015022754669
LOSS train 3.662015022754669 valid 3.762533664703369
EPOCH 62:
  batch 1000 loss: 3.655402708530426
LOSS train 3.655402708530426 valid 3.668548583984375
EPOCH 63:
  batch 1000 loss: 3.6382428292036058
LOSS train 3.6382428292036058 valid 3.677208185195923
EPOCH 64:
  batch 1000 loss: 3.644767178654671
LOSS train 3.644767178654671 valid 3.6553666591644287
EPOCH 65:
  batch 1000 loss: 3.6616479642391204
LOSS train 3.6616479642391204 valid 3.672577142715454
EPOCH 66:
  batch 1000 loss: 3.680888009548187
LOSS train 3.680888009548187 valid 3.671161413192749
EPOCH 67:
  batch 1000 loss: 3.655816971540451
LOSS train 3.655816971540451 valid 3.680168390274048
EPOCH 68:
  batch 1000 loss: 3.6252209621667864
LOSS train 3.6252209621667864 valid 3.6666386127471924
EPOCH 69:
  batch 1000 loss: 3.6152924876213075
LOSS train 3.6152924876213075 valid 3.7513322830200195
EPOCH 70:
  batch 1000 loss: 3.6524158354997636
LOSS train 3.6524158354997636 valid 3.64913010597229
EPOCH 71:
  batch 1000 loss: 3.6451272280216216
LOSS train 3.6451272280216216 valid 3.651017665863037
EPOCH 72:
  batch 1000 loss: 3.6499686897993087
LOSS train 3.6499686897993087 valid 3.6607096195220947
EPOCH 73:
  batch 1000 loss: 3.611508979678154
LOSS train 3.611508979678154 valid 3.649533748626709
EPOCH 74:
  batch 1000 loss: 3.644782064676285
LOSS train 3.644782064676285 valid 3.6401100158691406
EPOCH 75:
  batch 1000 loss: 3.645072239398956
LOSS train 3.645072239398956 valid 3.65567946434021
EPOCH 76:
  batch 1000 loss: 3.6201804933547974
LOSS train 3.6201804933547974 valid 3.6370785236358643
EPOCH 77:
  batch 1000 loss: 3.616670612692833
LOSS train 3.616670612692833 valid 3.648054361343384
EPOCH 78:
  batch 1000 loss: 3.609167560458183
LOSS train 3.609167560458183 valid 3.6363227367401123
EPOCH 79:
  batch 1000 loss: 3.618112821817398
LOSS train 3.618112821817398 valid 3.6724116802215576
EPOCH 80:
  batch 1000 loss: 3.6223184734582903
LOSS train 3.6223184734582903 valid 3.66243314743042
EPOCH 81:
  batch 1000 loss: 3.6226261365413666
LOSS train 3.6226261365413666 valid 3.647881507873535
EPOCH 82:
  batch 1000 loss: 3.6247064411640166
LOSS train 3.6247064411640166 valid 3.620971918106079
EPOCH 83:
  batch 1000 loss: 3.605626263022423
LOSS train 3.605626263022423 valid 3.6353254318237305
EPOCH 84:
  batch 1000 loss: 3.6232301856279374
LOSS train 3.6232301856279374 valid 3.6517601013183594
EPOCH 85:
  batch 1000 loss: 3.6107369921207426
LOSS train 3.6107369921207426 valid 3.6332621574401855
EPOCH 86:
  batch 1000 loss: 3.6166857476234435
LOSS train 3.6166857476234435 valid 3.645001173019409
EPOCH 87:
  batch 1000 loss: 3.6038504292964935
LOSS train 3.6038504292964935 valid 3.6167750358581543
EPOCH 88:
  batch 1000 loss: 3.5953173666000366
LOSS train 3.5953173666000366 valid 3.638137102127075
EPOCH 89:
  batch 1000 loss: 3.613484374523163
LOSS train 3.613484374523163 valid 3.6284701824188232
EPOCH 90:
  batch 1000 loss: 3.597126502275467
LOSS train 3.597126502275467 valid 3.6571121215820312
EPOCH 91:
  batch 1000 loss: 3.6120174462795256
LOSS train 3.6120174462795256 valid 3.636301040649414
EPOCH 92:
  batch 1000 loss: 3.6204753050804137
LOSS train 3.6204753050804137 valid 3.6187121868133545
EPOCH 93:
  batch 1000 loss: 3.61085540163517
Epoch 00093: reducing learning rate of group 0 to 5.0000e-04.
LOSS train 3.61085540163517 valid 3.629737138748169
EPOCH 94:
  batch 1000 loss: 3.5688071103096006
LOSS train 3.5688071103096006 valid 3.5914974212646484
EPOCH 95:
  batch 1000 loss: 3.5670206619501115
LOSS train 3.5670206619501115 valid 3.5831546783447266
EPOCH 96:
  batch 1000 loss: 3.551842712521553
LOSS train 3.551842712521553 valid 3.6049904823303223
EPOCH 97:
  batch 1000 loss: 3.551146364569664
LOSS train 3.551146364569664 valid 3.5826704502105713
EPOCH 98:
  batch 1000 loss: 3.5665168356895447
LOSS train 3.5665168356895447 valid 3.5781984329223633
EPOCH 99:
  batch 1000 loss: 3.5540960713624954
LOSS train 3.5540960713624954 valid 3.5904884338378906
EPOCH 100:
  batch 1000 loss: 3.5680484392642975
LOSS train 3.5680484392642975 valid 3.5809555053710938
EPOCH 101:
  batch 1000 loss: 3.5561251957416533
LOSS train 3.5561251957416533 valid 3.5803685188293457
EPOCH 102:
  batch 1000 loss: 3.56113059091568
LOSS train 3.56113059091568 valid 3.5824503898620605
EPOCH 103:
  batch 1000 loss: 3.545333542227745
LOSS train 3.545333542227745 valid 3.584536075592041
EPOCH 104:
  batch 1000 loss: 3.5616505563259127
Epoch 00104: reducing learning rate of group 0 to 2.5000e-04.
LOSS train 3.5616505563259127 valid 3.5830395221710205
EPOCH 105:
  batch 1000 loss: 3.5345148363113403
LOSS train 3.5345148363113403 valid 3.57181978225708
EPOCH 106:
  batch 1000 loss: 3.509188149690628
LOSS train 3.509188149690628 valid 3.5578408241271973
EPOCH 107:
  batch 1000 loss: 3.5180822401046754
LOSS train 3.5180822401046754 valid 3.5555334091186523
EPOCH 108:
  batch 1000 loss: 3.5381174879074098
LOSS train 3.5381174879074098 valid 3.552708625793457
EPOCH 109:
  batch 1000 loss: 3.533019781589508
LOSS train 3.533019781589508 valid 3.5497446060180664
EPOCH 110:
  batch 1000 loss: 3.5301552679538726
LOSS train 3.5301552679538726 valid 3.551616668701172
EPOCH 111:
  batch 1000 loss: 3.499768614768982
LOSS train 3.499768614768982 valid 3.5641591548919678
EPOCH 112:
  batch 1000 loss: 3.520093732714653
LOSS train 3.520093732714653 valid 3.5514068603515625
EPOCH 113:
  batch 1000 loss: 3.5471566591262818
LOSS train 3.5471566591262818 valid 3.554006338119507
EPOCH 114:
  batch 1000 loss: 3.5144646060466767
LOSS train 3.5144646060466767 valid 3.5470950603485107
EPOCH 115:
  batch 1000 loss: 3.5333349249362946
LOSS train 3.5333349249362946 valid 3.548877000808716
EPOCH 116:
  batch 1000 loss: 3.535225042819977
LOSS train 3.535225042819977 valid 3.547091007232666
EPOCH 117:
  batch 1000 loss: 3.513494716048241
LOSS train 3.513494716048241 valid 3.543980836868286
EPOCH 118:
  batch 1000 loss: 3.5209689934253694
LOSS train 3.5209689934253694 valid 3.5469579696655273
EPOCH 119:
  batch 1000 loss: 3.5105240424871447
LOSS train 3.5105240424871447 valid 3.546363353729248
EPOCH 120:
  batch 1000 loss: 3.502690929174423
LOSS train 3.502690929174423 valid 3.5470426082611084
EPOCH 121:
  batch 1000 loss: 3.5279035534858703
LOSS train 3.5279035534858703 valid 3.5454275608062744
EPOCH 122:
  batch 1000 loss: 3.5158594516515733
LOSS train 3.5158594516515733 valid 3.5424554347991943
EPOCH 123:
  batch 1000 loss: 3.497341886758804
LOSS train 3.497341886758804 valid 3.5439939498901367
EPOCH 124:
  batch 1000 loss: 3.5030274674892428
LOSS train 3.5030274674892428 valid 3.5412609577178955
EPOCH 125:
  batch 1000 loss: 3.5151726253032685
LOSS train 3.5151726253032685 valid 3.539278745651245
EPOCH 126:
  batch 1000 loss: 3.5335450854301453
LOSS train 3.5335450854301453 valid 3.54725980758667
EPOCH 127:
  batch 1000 loss: 3.5024248555898665
LOSS train 3.5024248555898665 valid 3.546231985092163
EPOCH 128:
  batch 1000 loss: 3.5183837649822234
LOSS train 3.5183837649822234 valid 3.542496919631958
EPOCH 129:
  batch 1000 loss: 3.523054296731949
LOSS train 3.523054296731949 valid 3.540452718734741
EPOCH 130:
  batch 1000 loss: 3.520378604054451
LOSS train 3.520378604054451 valid 3.5421359539031982
EPOCH 131:
  batch 1000 loss: 3.503462092399597
Epoch 00131: reducing learning rate of group 0 to 1.2500e-04.
LOSS train 3.503462092399597 valid 3.543052911758423
EPOCH 132:
  batch 1000 loss: 3.517712809085846
LOSS train 3.517712809085846 valid 3.5326364040374756
EPOCH 133:
  batch 1000 loss: 3.516931610584259
LOSS train 3.516931610584259 valid 3.532827615737915
EPOCH 134:
  batch 1000 loss: 3.5016509033441543
LOSS train 3.5016509033441543 valid 3.530367612838745
EPOCH 135:
  batch 1000 loss: 3.491376342535019
LOSS train 3.491376342535019 valid 3.529841423034668
EPOCH 136:
  batch 1000 loss: 3.5052942039966584
LOSS train 3.5052942039966584 valid 3.531076431274414
EPOCH 137:
  batch 1000 loss: 3.5081091418266297
LOSS train 3.5081091418266297 valid 3.5314834117889404
EPOCH 138:
  batch 1000 loss: 3.4868578140735624
LOSS train 3.4868578140735624 valid 3.527452230453491
EPOCH 139:
  batch 1000 loss: 3.493871235132217
LOSS train 3.493871235132217 valid 3.526871919631958
EPOCH 140:
  batch 1000 loss: 3.5051958146095274
LOSS train 3.5051958146095274 valid 3.527323007583618
EPOCH 141:
  batch 1000 loss: 3.4809513622522354
LOSS train 3.4809513622522354 valid 3.5241971015930176
EPOCH 142:
  batch 1000 loss: 3.506521189928055
LOSS train 3.506521189928055 valid 3.5281107425689697
EPOCH 143:
  batch 1000 loss: 3.5011522438526153
LOSS train 3.5011522438526153 valid 3.526564121246338
EPOCH 144:
  batch 1000 loss: 3.47876655626297
LOSS train 3.47876655626297 valid 3.5246667861938477
EPOCH 145:
  batch 1000 loss: 3.493898048043251
LOSS train 3.493898048043251 valid 3.527038097381592
EPOCH 146:
  batch 1000 loss: 3.51136258494854
LOSS train 3.51136258494854 valid 3.5292627811431885
EPOCH 147:
  batch 1000 loss: 3.5016639106273653
Epoch 00147: reducing learning rate of group 0 to 6.2500e-05.
LOSS train 3.5016639106273653 valid 3.523970127105713
EPOCH 148:
  batch 1000 loss: 3.4832801686525343
LOSS train 3.4832801686525343 valid 3.5221900939941406
EPOCH 149:
  batch 1000 loss: 3.487433156967163
LOSS train 3.487433156967163 valid 3.520267963409424
EPOCH 150:
  batch 1000 loss: 3.4828533260822296
LOSS train 3.4828533260822296 valid 3.5213589668273926
EPOCH 151:
  batch 1000 loss: 3.477688684821129
LOSS train 3.477688684821129 valid 3.5205328464508057
EPOCH 152:
  batch 1000 loss: 3.484731461524963
LOSS train 3.484731461524963 valid 3.520139217376709
EPOCH 153:
  batch 1000 loss: 3.472482949972153
LOSS train 3.472482949972153 valid 3.5211353302001953
EPOCH 154:
  batch 1000 loss: 3.467439344167709
LOSS train 3.467439344167709 valid 3.519491195678711
EPOCH 155:
  batch 1000 loss: 3.5022849321365355
LOSS train 3.5022849321365355 valid 3.521886110305786
EPOCH 156:
  batch 1000 loss: 3.488335272073746
LOSS train 3.488335272073746 valid 3.520054578781128
EPOCH 157:
  batch 1000 loss: 3.4862902426719664
LOSS train 3.4862902426719664 valid 3.520139217376709
EPOCH 158:
  batch 1000 loss: 3.480502998113632
LOSS train 3.480502998113632 valid 3.5186381340026855
EPOCH 159:
  batch 1000 loss: 3.4818993338346482
LOSS train 3.4818993338346482 valid 3.5189015865325928
EPOCH 160:
  batch 1000 loss: 3.478357421875
LOSS train 3.478357421875 valid 3.5197644233703613
EPOCH 161:
  batch 1000 loss: 3.4800827860832215
LOSS train 3.4800827860832215 valid 3.5185744762420654
EPOCH 162:
  batch 1000 loss: 3.481821593046188
LOSS train 3.481821593046188 valid 3.5186831951141357
EPOCH 163:
  batch 1000 loss: 3.4801222212314604
LOSS train 3.4801222212314604 valid 3.518616199493408
EPOCH 164:
  batch 1000 loss: 3.4828218355178833
Epoch 00164: reducing learning rate of group 0 to 3.1250e-05.
LOSS train 3.4828218355178833 valid 3.5191571712493896
EPOCH 165:
  batch 1000 loss: 3.4771405687332155
LOSS train 3.4771405687332155 valid 3.5169830322265625
EPOCH 166:
  batch 1000 loss: 3.4972261192798615
LOSS train 3.4972261192798615 valid 3.517063617706299
EPOCH 167:
  batch 1000 loss: 3.4901397838592527
LOSS train 3.4901397838592527 valid 3.5171010494232178
EPOCH 168:
  batch 1000 loss: 3.4874632720947267
LOSS train 3.4874632720947267 valid 3.516096353530884
EPOCH 169:
  batch 1000 loss: 3.4746914418935777
LOSS train 3.4746914418935777 valid 3.515688419342041
EPOCH 170:
  batch 1000 loss: 3.471190243244171
LOSS train 3.471190243244171 valid 3.5159833431243896
EPOCH 171:
  batch 1000 loss: 3.477726495027542
LOSS train 3.477726495027542 valid 3.5164852142333984
EPOCH 172:
  batch 1000 loss: 3.4737049281597137
LOSS train 3.4737049281597137 valid 3.516106605529785
EPOCH 173:
  batch 1000 loss: 3.494105324625969
LOSS train 3.494105324625969 valid 3.516401529312134
EPOCH 174:
  batch 1000 loss: 3.4899783518314362
LOSS train 3.4899783518314362 valid 3.515625
EPOCH 175:
  batch 1000 loss: 3.4856599980592726
Epoch 00175: reducing learning rate of group 0 to 1.5625e-05.
LOSS train 3.4856599980592726 valid 3.516309976577759
EPOCH 176:
  batch 1000 loss: 3.486763594985008
LOSS train 3.486763594985008 valid 3.514453887939453
EPOCH 177:
  batch 1000 loss: 3.4968250850439073
LOSS train 3.4968250850439073 valid 3.514582633972168
EPOCH 178:
  batch 1000 loss: 3.4828047499656676
LOSS train 3.4828047499656676 valid 3.514936923980713
EPOCH 179:
  batch 1000 loss: 3.4774071966409683
LOSS train 3.4774071966409683 valid 3.515925407409668
EPOCH 180:
  batch 1000 loss: 3.4787186534404753
LOSS train 3.4787186534404753 valid 3.5140762329101562
EPOCH 181:
  batch 1000 loss: 3.4714622011184693
LOSS train 3.4714622011184693 valid 3.515066385269165
EPOCH 182:
  batch 1000 loss: 3.475549130439758
LOSS train 3.475549130439758 valid 3.5146310329437256
EPOCH 183:
  batch 1000 loss: 3.4769228570461275
LOSS train 3.4769228570461275 valid 3.515059232711792
EPOCH 184:
  batch 1000 loss: 3.4793010637760164
LOSS train 3.4793010637760164 valid 3.514251947402954
EPOCH 185:
  batch 1000 loss: 3.480632180452347
LOSS train 3.480632180452347 valid 3.5145392417907715
EPOCH 186:
  batch 1000 loss: 3.4909939517974853
Epoch 00186: reducing learning rate of group 0 to 7.8125e-06.
LOSS train 3.4909939517974853 valid 3.5143837928771973
EPOCH 187:
  batch 1000 loss: 3.493710026502609
LOSS train 3.493710026502609 valid 3.5140762329101562
EPOCH 188:
  batch 1000 loss: 3.4836404099464415
LOSS train 3.4836404099464415 valid 3.51410174369812
EPOCH 189:
  batch 1000 loss: 3.4769990471601484
LOSS train 3.4769990471601484 valid 3.514758825302124
EPOCH 190:
  batch 1000 loss: 3.463874460697174
LOSS train 3.463874460697174 valid 3.5141892433166504
EPOCH 191:
  batch 1000 loss: 3.4857397800683976
LOSS train 3.4857397800683976 valid 3.514030933380127
EPOCH 192:
  batch 1000 loss: 3.4782692798376083
Epoch 00192: reducing learning rate of group 0 to 3.9063e-06.
LOSS train 3.4782692798376083 valid 3.514389991760254
EPOCH 193:
  batch 1000 loss: 3.449679864645004
LOSS train 3.449679864645004 valid 3.513657808303833
EPOCH 194:
  batch 1000 loss: 3.4851351013183596
LOSS train 3.4851351013183596 valid 3.5145976543426514
EPOCH 195:
  batch 1000 loss: 3.4554408860206602
LOSS train 3.4554408860206602 valid 3.5136663913726807
EPOCH 196:
  batch 1000 loss: 3.4642590950727463
LOSS train 3.4642590950727463 valid 3.5137248039245605
EPOCH 197:
  batch 1000 loss: 3.485065801858902
LOSS train 3.485065801858902 valid 3.5143556594848633
EPOCH 198:
  batch 1000 loss: 3.480986272573471
LOSS train 3.480986272573471 valid 3.5136492252349854
EPOCH 199:
  batch 1000 loss: 3.4688404085636138
Epoch 00199: reducing learning rate of group 0 to 1.9531e-06.
LOSS train 3.4688404085636138 valid 3.5143744945526123
EPOCH 200:
  batch 1000 loss: 3.4707286121845247
LOSS train 3.4707286121845247 valid 3.513353109359741
EPOCH 201:
  batch 1000 loss: 3.481935169458389
LOSS train 3.481935169458389 valid 3.51370906829834
EPOCH 202:
  batch 1000 loss: 3.475136616230011
LOSS train 3.475136616230011 valid 3.5136513710021973
EPOCH 203:
  batch 1000 loss: 3.4683786387443543
LOSS train 3.4683786387443543 valid 3.5138330459594727
EPOCH 204:
  batch 1000 loss: 3.4878787678480148
LOSS train 3.4878787678480148 valid 3.51459002494812
EPOCH 205:
  batch 1000 loss: 3.4780334672927857
Epoch 00205: reducing learning rate of group 0 to 9.7656e-07.
LOSS train 3.4780334672927857 valid 3.5139000415802
EPOCH 206:
  batch 1000 loss: 3.4714575299024584
LOSS train 3.4714575299024584 valid 3.513920545578003
EPOCH 207:
  batch 1000 loss: 3.4801143090724946
LOSS train 3.4801143090724946 valid 3.5130388736724854
EPOCH 208:
  batch 1000 loss: 3.468408066034317
LOSS train 3.468408066034317 valid 3.5138401985168457
EPOCH 209:
  batch 1000 loss: 3.485269879579544
LOSS train 3.485269879579544 valid 3.51371693611145
EPOCH 210:
  batch 1000 loss: 3.4901831877231597
LOSS train 3.4901831877231597 valid 3.51375412940979
EPOCH 211:
  batch 1000 loss: 3.4698780398368836
LOSS train 3.4698780398368836 valid 3.513692855834961
EPOCH 212:
  batch 1000 loss: 3.4750604162216185
LOSS train 3.4750604162216185 valid 3.513676166534424
EPOCH 213:
  batch 1000 loss: 3.4712210091352462
Epoch 00213: reducing learning rate of group 0 to 4.8828e-07.
LOSS train 3.4712210091352462 valid 3.5146427154541016
EPOCH 214:
  batch 1000 loss: 3.4614453485012056
LOSS train 3.4614453485012056 valid 3.514390468597412
EPOCH 215:
  batch 1000 loss: 3.4570083379745484
LOSS train 3.4570083379745484 valid 3.514585494995117
EPOCH 216:
  batch 1000 loss: 3.4862348531484604
LOSS train 3.4862348531484604 valid 3.513655424118042
EPOCH 217:
  batch 1000 loss: 3.4695580877065657
LOSS train 3.4695580877065657 valid 3.5138099193573
EPOCH 218:
  batch 1000 loss: 3.4818258240222932
LOSS train 3.4818258240222932 valid 3.5134057998657227
EPOCH 219:
  batch 1000 loss: 3.4639883785247805
Epoch 00219: reducing learning rate of group 0 to 2.4414e-07.
LOSS train 3.4639883785247805 valid 3.5132853984832764
EPOCH 220:
  batch 1000 loss: 3.4693794736862182
LOSS train 3.4693794736862182 valid 3.5139224529266357
EPOCH 221:
  batch 1000 loss: 3.471007896900177
LOSS train 3.471007896900177 valid 3.5145459175109863
EPOCH 222:
  batch 1000 loss: 3.4821326277256013
LOSS train 3.4821326277256013 valid 3.513773202896118
EPOCH 223:
  batch 1000 loss: 3.4944460710287095
LOSS train 3.4944460710287095 valid 3.5139412879943848
EPOCH 224:
  batch 1000 loss: 3.4773413915634155
LOSS train 3.4773413915634155 valid 3.5128707885742188
EPOCH 225:
  batch 1000 loss: 3.4678475135564804
Epoch 00225: reducing learning rate of group 0 to 1.2207e-07.
LOSS train 3.4678475135564804 valid 3.5139615535736084
EPOCH 226:
  batch 1000 loss: 3.4573670196533204
LOSS train 3.4573670196533204 valid 3.5133039951324463
EPOCH 227:
  batch 1000 loss: 3.4710468623638153
LOSS train 3.4710468623638153 valid 3.513653516769409
EPOCH 228:
  batch 1000 loss: 3.458269429564476
LOSS train 3.458269429564476 valid 3.5136685371398926
EPOCH 229:
  batch 1000 loss: 3.4834277040958406
LOSS train 3.4834277040958406 valid 3.5138001441955566
EPOCH 230:
  batch 1000 loss: 3.4619023853540423
LOSS train 3.4619023853540423 valid 3.513620138168335
EPOCH 231:
  batch 1000 loss: 3.498712815284729
Epoch 00231: reducing learning rate of group 0 to 6.1035e-08.
LOSS train 3.498712815284729 valid 3.5133707523345947
EPOCH 232:
  batch 1000 loss: 3.4581968928575515
LOSS train 3.4581968928575515 valid 3.5136613845825195
EPOCH 233:
  batch 1000 loss: 3.4681011004447937
LOSS train 3.4681011004447937 valid 3.514286756515503
EPOCH 234:
  batch 1000 loss: 3.4660286395549775
LOSS train 3.4660286395549775 valid 3.5132601261138916
EPOCH 235:
  batch 1000 loss: 3.4854951202869415
LOSS train 3.4854951202869415 valid 3.5136899948120117
EPOCH 236:
  batch 1000 loss: 3.4854031307697295
LOSS train 3.4854031307697295 valid 3.5142593383789062
EPOCH 237:
  batch 1000 loss: 3.47931783246994
Epoch 00237: reducing learning rate of group 0 to 3.0518e-08.
LOSS train 3.47931783246994 valid 3.5133659839630127
EPOCH 238:
  batch 1000 loss: 3.471272270321846
LOSS train 3.471272270321846 valid 3.5138847827911377
EPOCH 239:
  batch 1000 loss: 3.4577773653268813
LOSS train 3.4577773653268813 valid 3.513862133026123
EPOCH 240:
  batch 1000 loss: 3.472425899505615
LOSS train 3.472425899505615 valid 3.5133349895477295
EPOCH 241:
  batch 1000 loss: 3.447158013820648
LOSS train 3.447158013820648 valid 3.5147316455841064
EPOCH 242:
  batch 1000 loss: 3.479705782532692
LOSS train 3.479705782532692 valid 3.5138447284698486
EPOCH 243:
  batch 1000 loss: 3.4827573288679123
Epoch 00243: reducing learning rate of group 0 to 1.5259e-08.
LOSS train 3.4827573288679123 valid 3.5142452716827393
EPOCH 244:
  batch 1000 loss: 3.4659885121583938
LOSS train 3.4659885121583938 valid 3.5128042697906494
EPOCH 245:
  batch 1000 loss: 3.4665323491096496
LOSS train 3.4665323491096496 valid 3.5132009983062744
EPOCH 246:
  batch 1000 loss: 3.4702783094644545
LOSS train 3.4702783094644545 valid 3.5145819187164307
EPOCH 247:
  batch 1000 loss: 3.4752172396183014
LOSS train 3.4752172396183014 valid 3.513566493988037
EPOCH 248:
  batch 1000 loss: 3.482878524303436
LOSS train 3.482878524303436 valid 3.51340913772583
EPOCH 249:
  batch 1000 loss: 3.4891501744985582
LOSS train 3.4891501744985582 valid 3.513713836669922
EPOCH 250:
  batch 1000 loss: 3.480358186125755
LOSS train 3.480358186125755 valid 3.5137441158294678
EPOCH 251:
  batch 1000 loss: 3.4671231145858763
LOSS train 3.4671231145858763 valid 3.5136449337005615
EPOCH 252:
  batch 1000 loss: 3.487724359035492
LOSS train 3.487724359035492 valid 3.51363205909729
EPOCH 253:
  batch 1000 loss: 3.4571511318683625
LOSS train 3.4571511318683625 valid 3.5132126808166504
EPOCH 254:
  batch 1000 loss: 3.4606358059644697
LOSS train 3.4606358059644697 valid 3.513997793197632
EPOCH 255:
  batch 1000 loss: 3.486592304468155
LOSS train 3.486592304468155 valid 3.5135629177093506
EPOCH 256:
  batch 1000 loss: 3.4712234137058258
LOSS train 3.4712234137058258 valid 3.5136942863464355
EPOCH 257:
  batch 1000 loss: 3.4802249591350556
LOSS train 3.4802249591350556 valid 3.513225793838501
EPOCH 258:
  batch 1000 loss: 3.46354418694973
LOSS train 3.46354418694973 valid 3.5139355659484863
EPOCH 259:
  batch 1000 loss: 3.461457832813263
LOSS train 3.461457832813263 valid 3.513570785522461
EPOCH 260:
  batch 1000 loss: 3.449300480365753
LOSS train 3.449300480365753 valid 3.5133509635925293
EPOCH 261:
  batch 1000 loss: 3.46856194627285
LOSS train 3.46856194627285 valid 3.513291835784912
EPOCH 262:
  batch 1000 loss: 3.486272030830383
LOSS train 3.486272030830383 valid 3.5135867595672607
EPOCH 263:
  batch 1000 loss: 3.46822331738472
LOSS train 3.46822331738472 valid 3.514448881149292
EPOCH 264:
  batch 1000 loss: 3.484954124212265
LOSS train 3.484954124212265 valid 3.513101577758789
EPOCH 265:
  batch 1000 loss: 3.469625005245209
LOSS train 3.469625005245209 valid 3.513787269592285
EPOCH 266:
  batch 1000 loss: 3.4858000167608263
LOSS train 3.4858000167608263 valid 3.5136895179748535
EPOCH 267:
  batch 1000 loss: 3.4826244695186617
LOSS train 3.4826244695186617 valid 3.5138051509857178
EPOCH 268:
  batch 1000 loss: 3.462999344110489
LOSS train 3.462999344110489 valid 3.513674259185791
EPOCH 269:
  batch 1000 loss: 3.480568565249443
LOSS train 3.480568565249443 valid 3.513395071029663
EPOCH 270:
  batch 1000 loss: 3.476805602312088
LOSS train 3.476805602312088 valid 3.5136797428131104
EPOCH 271:
  batch 1000 loss: 3.482363384485245
LOSS train 3.482363384485245 valid 3.513033628463745
EPOCH 272:
  batch 1000 loss: 3.471699505209923
LOSS train 3.471699505209923 valid 3.5137245655059814
EPOCH 273:
  batch 1000 loss: 3.4646980621814727
LOSS train 3.4646980621814727 valid 3.513418436050415
EPOCH 274:
  batch 1000 loss: 3.4766105753183365
LOSS train 3.4766105753183365 valid 3.513864040374756
EPOCH 275:
  batch 1000 loss: 3.46626957988739
LOSS train 3.46626957988739 valid 3.512791156768799
EPOCH 276:
  batch 1000 loss: 3.466979363679886
LOSS train 3.466979363679886 valid 3.513812303543091
EPOCH 277:
  batch 1000 loss: 3.4672192758321763
LOSS train 3.4672192758321763 valid 3.513847827911377
EPOCH 278:
  batch 1000 loss: 3.4584926406145096
LOSS train 3.4584926406145096 valid 3.5145609378814697
EPOCH 279:
  batch 1000 loss: 3.4642417818307876
LOSS train 3.4642417818307876 valid 3.5134317874908447
EPOCH 280:
  batch 1000 loss: 3.5094538214206694
LOSS train 3.5094538214206694 valid 3.5143673419952393
EPOCH 281:
  batch 1000 loss: 3.4640919444561002
LOSS train 3.4640919444561002 valid 3.5136804580688477
EPOCH 282:
  batch 1000 loss: 3.481023330926895
LOSS train 3.481023330926895 valid 3.514453887939453
EPOCH 283:
  batch 1000 loss: 3.4793980190753935
LOSS train 3.4793980190753935 valid 3.513834238052368
EPOCH 284:
  batch 1000 loss: 3.4710871450901033
LOSS train 3.4710871450901033 valid 3.513965606689453
EPOCH 285:
  batch 1000 loss: 3.47548113656044
LOSS train 3.47548113656044 valid 3.5128016471862793
EPOCH 286:
  batch 1000 loss: 3.4749058331251144
LOSS train 3.4749058331251144 valid 3.5146682262420654
EPOCH 287:
  batch 1000 loss: 3.478460233569145
LOSS train 3.478460233569145 valid 3.5131707191467285
EPOCH 288:
  batch 1000 loss: 3.4624612393379213
LOSS train 3.4624612393379213 valid 3.51383638381958
EPOCH 289:
  batch 1000 loss: 3.4800816631317137
LOSS train 3.4800816631317137 valid 3.513231039047241
EPOCH 290:
  batch 1000 loss: 3.4924143468141557
LOSS train 3.4924143468141557 valid 3.5138425827026367
EPOCH 291:
  batch 1000 loss: 3.4683964179754256
LOSS train 3.4683964179754256 valid 3.5132477283477783
EPOCH 292:
  batch 1000 loss: 3.4747988849878313
LOSS train 3.4747988849878313 valid 3.513511896133423
EPOCH 293:
  batch 1000 loss: 3.4696688400506974
LOSS train 3.4696688400506974 valid 3.514000177383423
EPOCH 294:
  batch 1000 loss: 3.4761628984212876
LOSS train 3.4761628984212876 valid 3.514244794845581
EPOCH 295:
  batch 1000 loss: 3.4927897325754165
LOSS train 3.4927897325754165 valid 3.51435923576355
EPOCH 296:
  batch 1000 loss: 3.4905582313537598
LOSS train 3.4905582313537598 valid 3.5136613845825195
EPOCH 297:
  batch 1000 loss: 3.480961070537567
LOSS train 3.480961070537567 valid 3.5136473178863525
EPOCH 298:
  batch 1000 loss: 3.4813526556491854
LOSS train 3.4813526556491854 valid 3.5136992931365967
EPOCH 299:
  batch 1000 loss: 3.4944211935997007
LOSS train 3.4944211935997007 valid 3.5136656761169434
EPOCH 300:
  batch 1000 loss: 3.492381829380989
LOSS train 3.492381829380989 valid 3.513092041015625
EPOCH 301:
  batch 1000 loss: 3.455894709944725
LOSS train 3.455894709944725 valid 3.5133423805236816
EPOCH 302:
  batch 1000 loss: 3.4648528032302854
LOSS train 3.4648528032302854 valid 3.5136396884918213
EPOCH 303:
  batch 1000 loss: 3.461704923629761
LOSS train 3.461704923629761 valid 3.513270378112793
EPOCH 304:
  batch 1000 loss: 3.4543374359607695
LOSS train 3.4543374359607695 valid 3.514451503753662
EPOCH 305:
  batch 1000 loss: 3.4673959604501725
LOSS train 3.4673959604501725 valid 3.5137133598327637
EPOCH 306:
  batch 1000 loss: 3.4709873411655425
LOSS train 3.4709873411655425 valid 3.513669013977051
EPOCH 307:
  batch 1000 loss: 3.484834834098816
LOSS train 3.484834834098816 valid 3.5136971473693848
EPOCH 308:
  batch 1000 loss: 3.476497838616371
LOSS train 3.476497838616371 valid 3.5130887031555176
EPOCH 309:
  batch 1000 loss: 3.4814364171028136
LOSS train 3.4814364171028136 valid 3.5133373737335205
EPOCH 310:
  batch 1000 loss: 3.4806969265937804
LOSS train 3.4806969265937804 valid 3.5138168334960938
EPOCH 311:
  batch 1000 loss: 3.4934243004322054
LOSS train 3.4934243004322054 valid 3.513740062713623
EPOCH 312:
  batch 1000 loss: 3.482769581079483
LOSS train 3.482769581079483 valid 3.513824939727783
EPOCH 313:
  batch 1000 loss: 3.467336501121521
LOSS train 3.467336501121521 valid 3.513409376144409
EPOCH 314:
  batch 1000 loss: 3.4800505571365354
LOSS train 3.4800505571365354 valid 3.5132546424865723
EPOCH 315:
  batch 1000 loss: 3.4773594064712525
LOSS train 3.4773594064712525 valid 3.5136849880218506
EPOCH 316:
  batch 1000 loss: 3.4720862681865694
LOSS train 3.4720862681865694 valid 3.5139787197113037
EPOCH 317:
  batch 1000 loss: 3.4828229447603225
LOSS train 3.4828229447603225 valid 3.5138189792633057
EPOCH 318:
  batch 1000 loss: 3.457429528474808
LOSS train 3.457429528474808 valid 3.5134129524230957
EPOCH 319:
  batch 1000 loss: 3.4717280012369156
LOSS train 3.4717280012369156 valid 3.5138089656829834
EPOCH 320:
  batch 1000 loss: 3.4649556615352632
LOSS train 3.4649556615352632 valid 3.513942241668701
EPOCH 321:
  batch 1000 loss: 3.4756082381010054
LOSS train 3.4756082381010054 valid 3.5136029720306396
EPOCH 322:
  batch 1000 loss: 3.48519276034832
LOSS train 3.48519276034832 valid 3.513052225112915
EPOCH 323:
  batch 1000 loss: 3.4655402290821073
LOSS train 3.4655402290821073 valid 3.513892412185669
EPOCH 324:
  batch 1000 loss: 3.467693480014801
LOSS train 3.467693480014801 valid 3.513810634613037
EPOCH 325:
  batch 1000 loss: 3.466390140771866
LOSS train 3.466390140771866 valid 3.5139665603637695
EPOCH 326:
  batch 1000 loss: 3.466993980407715
LOSS train 3.466993980407715 valid 3.5142641067504883
EPOCH 327:
  batch 1000 loss: 3.4794576873779297
LOSS train 3.4794576873779297 valid 3.514622926712036
EPOCH 328:
  batch 1000 loss: 3.4727309820652006
LOSS train 3.4727309820652006 valid 3.513841390609741
EPOCH 329:
  batch 1000 loss: 3.4731898552179334
LOSS train 3.4731898552179334 valid 3.513887882232666
EPOCH 330:
  batch 1000 loss: 3.4849452764987947
LOSS train 3.4849452764987947 valid 3.5145552158355713
EPOCH 331:
  batch 1000 loss: 3.479038920760155
LOSS train 3.479038920760155 valid 3.5137994289398193
EPOCH 332:
  batch 1000 loss: 3.4813859560489653
LOSS train 3.4813859560489653 valid 3.51420521736145
EPOCH 333:
  batch 1000 loss: 3.479245409011841
LOSS train 3.479245409011841 valid 3.513545513153076
EPOCH 334:
  batch 1000 loss: 3.469781007885933
LOSS train 3.469781007885933 valid 3.513688087463379
EPOCH 335:
  batch 1000 loss: 3.482672011256218
LOSS train 3.482672011256218 valid 3.513881206512451
EPOCH 336:
  batch 1000 loss: 3.4777276030778883
LOSS train 3.4777276030778883 valid 3.513376235961914
EPOCH 337:
  batch 1000 loss: 3.4747921485900877
LOSS train 3.4747921485900877 valid 3.513745069503784
EPOCH 338:
  batch 1000 loss: 3.473568999171257
LOSS train 3.473568999171257 valid 3.5138113498687744
EPOCH 339:
  batch 1000 loss: 3.476808547258377
LOSS train 3.476808547258377 valid 3.5138931274414062
EPOCH 340:
  batch 1000 loss: 3.4737653641700743
LOSS train 3.4737653641700743 valid 3.51387357711792
EPOCH 341:
  batch 1000 loss: 3.4852201792001725
LOSS train 3.4852201792001725 valid 3.513852596282959
EPOCH 342:
  batch 1000 loss: 3.4920634405612945
LOSS train 3.4920634405612945 valid 3.5132977962493896
EPOCH 343:
  batch 1000 loss: 3.484033323764801
LOSS train 3.484033323764801 valid 3.514435291290283
EPOCH 344:
  batch 1000 loss: 3.474522361755371
LOSS train 3.474522361755371 valid 3.513643741607666
EPOCH 345:
  batch 1000 loss: 3.488880264997482
LOSS train 3.488880264997482 valid 3.5133020877838135
EPOCH 346:
  batch 1000 loss: 3.4677124264240264
LOSS train 3.4677124264240264 valid 3.5139389038085938
EPOCH 347:
  batch 1000 loss: 3.4601941969394683
LOSS train 3.4601941969394683 valid 3.513256072998047
EPOCH 348:
  batch 1000 loss: 3.475831856250763
LOSS train 3.475831856250763 valid 3.513876438140869
EPOCH 349:
  batch 1000 loss: 3.4900591468811033
LOSS train 3.4900591468811033 valid 3.513633966445923
EPOCH 350:
  batch 1000 loss: 3.480785007953644
LOSS train 3.480785007953644 valid 3.5141053199768066
EPOCH 351:
  batch 1000 loss: 3.4900001019239424
LOSS train 3.4900001019239424 valid 3.513770341873169
EPOCH 352:
  batch 1000 loss: 3.5109727545976637
LOSS train 3.5109727545976637 valid 3.513665199279785
EPOCH 353:
  batch 1000 loss: 3.46171123957634
LOSS train 3.46171123957634 valid 3.5136194229125977
EPOCH 354:
  batch 1000 loss: 3.4704573751688
LOSS train 3.4704573751688 valid 3.5133683681488037
EPOCH 355:
  batch 1000 loss: 3.470042908787727
LOSS train 3.470042908787727 valid 3.5135457515716553
EPOCH 356:
  batch 1000 loss: 3.485059236526489
LOSS train 3.485059236526489 valid 3.5138909816741943
EPOCH 357:
  batch 1000 loss: 3.483684402227402
LOSS train 3.483684402227402 valid 3.5136520862579346
EPOCH 358:
  batch 1000 loss: 3.4670224397182463
LOSS train 3.4670224397182463 valid 3.5129036903381348
EPOCH 359:
  batch 1000 loss: 3.471151591658592
LOSS train 3.471151591658592 valid 3.5137927532196045
EPOCH 360:
  batch 1000 loss: 3.471050020456314
LOSS train 3.471050020456314 valid 3.5137314796447754
EPOCH 361:
  batch 1000 loss: 3.4575973855257036
LOSS train 3.4575973855257036 valid 3.513476610183716
EPOCH 362:
  batch 1000 loss: 3.4735070284605025
LOSS train 3.4735070284605025 valid 3.5135583877563477
EPOCH 363:
  batch 1000 loss: 3.4807728704214096
LOSS train 3.4807728704214096 valid 3.513981580734253
EPOCH 364:
  batch 1000 loss: 3.475347069501877
LOSS train 3.475347069501877 valid 3.513939619064331
EPOCH 365:
  batch 1000 loss: 3.475726064324379
LOSS train 3.475726064324379 valid 3.513978958129883
EPOCH 366:
  batch 1000 loss: 3.486528590917587
LOSS train 3.486528590917587 valid 3.513505697250366
EPOCH 367:
  batch 1000 loss: 3.4640628089904784
LOSS train 3.4640628089904784 valid 3.5140936374664307
EPOCH 368:
  batch 1000 loss: 3.4866954426765444
LOSS train 3.4866954426765444 valid 3.5139312744140625
EPOCH 369:
  batch 1000 loss: 3.4741090166568758
LOSS train 3.4741090166568758 valid 3.5137174129486084
EPOCH 370:
  batch 1000 loss: 3.49189883685112
LOSS train 3.49189883685112 valid 3.5137948989868164
EPOCH 371:
  batch 1000 loss: 3.4712481639385224
LOSS train 3.4712481639385224 valid 3.513200044631958
EPOCH 372:
  batch 1000 loss: 3.4800290043354036
LOSS train 3.4800290043354036 valid 3.514171838760376
EPOCH 373:
  batch 1000 loss: 3.47786514377594
LOSS train 3.47786514377594 valid 3.5140836238861084
EPOCH 374:
  batch 1000 loss: 3.469398282408714
LOSS train 3.469398282408714 valid 3.5142388343811035
EPOCH 375:
  batch 1000 loss: 3.458782621383667
LOSS train 3.458782621383667 valid 3.513770580291748
EPOCH 376:
  batch 1000 loss: 3.4794770175218583
LOSS train 3.4794770175218583 valid 3.5138802528381348
EPOCH 377:
  batch 1000 loss: 3.469861128807068
LOSS train 3.469861128807068 valid 3.514986991882324
EPOCH 378:
  batch 1000 loss: 3.4710350259542464
LOSS train 3.4710350259542464 valid 3.513767719268799
EPOCH 379:
  batch 1000 loss: 3.4880378992557524
LOSS train 3.4880378992557524 valid 3.513298988342285
EPOCH 380:
  batch 1000 loss: 3.472941570997238
LOSS train 3.472941570997238 valid 3.513838291168213
EPOCH 381:
  batch 1000 loss: 3.4722013009786608
LOSS train 3.4722013009786608 valid 3.5136640071868896
EPOCH 382:
  batch 1000 loss: 3.4694296159744265
LOSS train 3.4694296159744265 valid 3.5138790607452393
EPOCH 383:
  batch 1000 loss: 3.4747758995294573
LOSS train 3.4747758995294573 valid 3.513418436050415
EPOCH 384:
  batch 1000 loss: 3.474312675833702
LOSS train 3.474312675833702 valid 3.513235330581665
EPOCH 385:
  batch 1000 loss: 3.4718407875299455
LOSS train 3.4718407875299455 valid 3.513892412185669
EPOCH 386:
  batch 1000 loss: 3.4866137380599977
LOSS train 3.4866137380599977 valid 3.5137853622436523
EPOCH 387:
  batch 1000 loss: 3.4734736495018006
LOSS train 3.4734736495018006 valid 3.5139193534851074
EPOCH 388:
  batch 1000 loss: 3.4818302273750303
LOSS train 3.4818302273750303 valid 3.5136072635650635
EPOCH 389:
  batch 1000 loss: 3.4709747956991195
LOSS train 3.4709747956991195 valid 3.5139200687408447
EPOCH 390:
  batch 1000 loss: 3.482975982666016
LOSS train 3.482975982666016 valid 3.51359486579895
EPOCH 391:
  batch 1000 loss: 3.4533996284008026
LOSS train 3.4533996284008026 valid 3.5137436389923096
EPOCH 392:
  batch 1000 loss: 3.4646610873937607
LOSS train 3.4646610873937607 valid 3.5137205123901367
EPOCH 393:
  batch 1000 loss: 3.4895773097276686
LOSS train 3.4895773097276686 valid 3.514484405517578
EPOCH 394:
  batch 1000 loss: 3.4747952053546904
LOSS train 3.4747952053546904 valid 3.513660192489624
EPOCH 395:
  batch 1000 loss: 3.471696489572525
LOSS train 3.471696489572525 valid 3.512814998626709
EPOCH 396:
  batch 1000 loss: 3.4825734167099
LOSS train 3.4825734167099 valid 3.513376235961914
EPOCH 397:
  batch 1000 loss: 3.468631047964096
LOSS train 3.468631047964096 valid 3.5140724182128906
EPOCH 398:
  batch 1000 loss: 3.4771613812446596
LOSS train 3.4771613812446596 valid 3.5137598514556885
EPOCH 399:
  batch 1000 loss: 3.4722452548742293
LOSS train 3.4722452548742293 valid 3.512781858444214
EPOCH 400:
  batch 1000 loss: 3.4791601959466933
LOSS train 3.4791601959466933 valid 3.514214277267456
EPOCH 401:
  batch 1000 loss: 3.476954073429108
LOSS train 3.476954073429108 valid 3.513275146484375
EPOCH 402:
  batch 1000 loss: 3.4792961463928225
LOSS train 3.4792961463928225 valid 3.5132827758789062
EPOCH 403:
  batch 1000 loss: 3.483926030397415
LOSS train 3.483926030397415 valid 3.5137853622436523
EPOCH 404:
  batch 1000 loss: 3.4613397043943404
LOSS train 3.4613397043943404 valid 3.5138330459594727
EPOCH 405:
  batch 1000 loss: 3.4804182093143465
LOSS train 3.4804182093143465 valid 3.5137598514556885
EPOCH 406:
  batch 1000 loss: 3.4550587931871415
LOSS train 3.4550587931871415 valid 3.5134687423706055
EPOCH 407:
  batch 1000 loss: 3.460015543341637
LOSS train 3.460015543341637 valid 3.5136470794677734
EPOCH 408:
  batch 1000 loss: 3.483129593372345
LOSS train 3.483129593372345 valid 3.514472007751465
EPOCH 409:
  batch 1000 loss: 3.4755480830669403
LOSS train 3.4755480830669403 valid 3.5138423442840576
EPOCH 410:
  batch 1000 loss: 3.473448686361313
LOSS train 3.473448686361313 valid 3.513292074203491
EPOCH 411:
  batch 1000 loss: 3.4839226295948027
LOSS train 3.4839226295948027 valid 3.513869524002075
EPOCH 412:
  batch 1000 loss: 3.4921895308494566
LOSS train 3.4921895308494566 valid 3.5135843753814697
EPOCH 413:
  batch 1000 loss: 3.47569824886322
LOSS train 3.47569824886322 valid 3.513697862625122
EPOCH 414:
  batch 1000 loss: 3.482935557126999
LOSS train 3.482935557126999 valid 3.513547658920288
EPOCH 415:
  batch 1000 loss: 3.475187911748886
LOSS train 3.475187911748886 valid 3.513875722885132
EPOCH 416:
  batch 1000 loss: 3.4852381196022035
LOSS train 3.4852381196022035 valid 3.5134103298187256
EPOCH 417:
  batch 1000 loss: 3.484431674838066
LOSS train 3.484431674838066 valid 3.514237642288208
EPOCH 418:
  batch 1000 loss: 3.4746261019706726
LOSS train 3.4746261019706726 valid 3.5141637325286865
EPOCH 419:
  batch 1000 loss: 3.486422591924667
LOSS train 3.486422591924667 valid 3.5134332180023193
EPOCH 420:
  batch 1000 loss: 3.4627064471244813
LOSS train 3.4627064471244813 valid 3.5139269828796387
EPOCH 421:
  batch 1000 loss: 3.462941832780838
LOSS train 3.462941832780838 valid 3.5133655071258545
EPOCH 422:
  batch 1000 loss: 3.499248987197876
LOSS train 3.499248987197876 valid 3.513408660888672
EPOCH 423:
  batch 1000 loss: 3.4713957872390746
LOSS train 3.4713957872390746 valid 3.5138630867004395
EPOCH 424:
  batch 1000 loss: 3.4808673944473267
LOSS train 3.4808673944473267 valid 3.5135891437530518
EPOCH 425:
  batch 1000 loss: 3.4682400894165037
LOSS train 3.4682400894165037 valid 3.514465570449829
EPOCH 426:
  batch 1000 loss: 3.465563743829727
LOSS train 3.465563743829727 valid 3.512927770614624
EPOCH 427:
  batch 1000 loss: 3.474274927139282
LOSS train 3.474274927139282 valid 3.5140297412872314
EPOCH 428:
  batch 1000 loss: 3.4754761855602263
LOSS train 3.4754761855602263 valid 3.513908863067627
EPOCH 429:
  batch 1000 loss: 3.474489106297493
LOSS train 3.474489106297493 valid 3.514512300491333
EPOCH 430:
  batch 1000 loss: 3.4785621342658994
LOSS train 3.4785621342658994 valid 3.5140058994293213
EPOCH 431:
  batch 1000 loss: 3.4670303168296814
LOSS train 3.4670303168296814 valid 3.513962745666504
EPOCH 432:
  batch 1000 loss: 3.4890555634498597
LOSS train 3.4890555634498597 valid 3.513806104660034
EPOCH 433:
  batch 1000 loss: 3.4841321873664857
LOSS train 3.4841321873664857 valid 3.51363205909729
EPOCH 434:
  batch 1000 loss: 3.4842834712266924
LOSS train 3.4842834712266924 valid 3.5136234760284424
EPOCH 435:
  batch 1000 loss: 3.4724926443099977
LOSS train 3.4724926443099977 valid 3.5137598514556885
EPOCH 436:
  batch 1000 loss: 3.470976648211479
LOSS train 3.470976648211479 valid 3.513413429260254
EPOCH 437:
  batch 1000 loss: 3.482840517759323
LOSS train 3.482840517759323 valid 3.514130115509033
EPOCH 438:
  batch 1000 loss: 3.485171003818512
LOSS train 3.485171003818512 valid 3.5132763385772705
EPOCH 439:
  batch 1000 loss: 3.4729832475185396
LOSS train 3.4729832475185396 valid 3.5137109756469727
EPOCH 440:
  batch 1000 loss: 3.4758208911418915
LOSS train 3.4758208911418915 valid 3.5132477283477783
EPOCH 441:
  batch 1000 loss: 3.475831436753273
LOSS train 3.475831436753273 valid 3.514134645462036
EPOCH 442:
  batch 1000 loss: 3.472148689508438
LOSS train 3.472148689508438 valid 3.513632297515869
EPOCH 443:
  batch 1000 loss: 3.4611137088537216
LOSS train 3.4611137088537216 valid 3.5133564472198486
EPOCH 444:
  batch 1000 loss: 3.4787784707546234
LOSS train 3.4787784707546234 valid 3.5140304565429688
EPOCH 445:
  batch 1000 loss: 3.478438897371292
LOSS train 3.478438897371292 valid 3.5143415927886963
EPOCH 446:
  batch 1000 loss: 3.4718859584331514
LOSS train 3.4718859584331514 valid 3.5137760639190674
EPOCH 447:
  batch 1000 loss: 3.488362021923065
LOSS train 3.488362021923065 valid 3.512974500656128
EPOCH 448:
  batch 1000 loss: 3.475654860854149
LOSS train 3.475654860854149 valid 3.5135750770568848
EPOCH 449:
  batch 1000 loss: 3.4878618414402007
LOSS train 3.4878618414402007 valid 3.513880729675293
EPOCH 450:
  batch 1000 loss: 3.4918913803100584
LOSS train 3.4918913803100584 valid 3.5138022899627686
EPOCH 451:
  batch 1000 loss: 3.4632639985084532
LOSS train 3.4632639985084532 valid 3.5139200687408447
EPOCH 452:
  batch 1000 loss: 3.4775676653385164
LOSS train 3.4775676653385164 valid 3.5132884979248047
EPOCH 453:
  batch 1000 loss: 3.486858764767647
LOSS train 3.486858764767647 valid 3.5136189460754395
EPOCH 454:
  batch 1000 loss: 3.4779268176555633
LOSS train 3.4779268176555633 valid 3.514594316482544
EPOCH 455:
  batch 1000 loss: 3.4651895936727524
LOSS train 3.4651895936727524 valid 3.513669013977051
EPOCH 456:
  batch 1000 loss: 3.482460426211357
LOSS train 3.482460426211357 valid 3.513852119445801
EPOCH 457:
  batch 1000 loss: 3.473720262169838
LOSS train 3.473720262169838 valid 3.5138792991638184
EPOCH 458:
  batch 1000 loss: 3.4856416239738466
LOSS train 3.4856416239738466 valid 3.513756275177002
EPOCH 459:
  batch 1000 loss: 3.468710247755051
LOSS train 3.468710247755051 valid 3.5135140419006348
EPOCH 460:
  batch 1000 loss: 3.4751309883594512
LOSS train 3.4751309883594512 valid 3.5133039951324463
EPOCH 461:
  batch 1000 loss: 3.4618511093854902
LOSS train 3.4618511093854902 valid 3.513619899749756
EPOCH 462:
  batch 1000 loss: 3.473992973089218
LOSS train 3.473992973089218 valid 3.5135414600372314
EPOCH 463:
  batch 1000 loss: 3.473035244345665
LOSS train 3.473035244345665 valid 3.513195276260376
EPOCH 464:
  batch 1000 loss: 3.470239283323288
LOSS train 3.470239283323288 valid 3.513753890991211
EPOCH 465:
  batch 1000 loss: 3.481356507778168
LOSS train 3.481356507778168 valid 3.513978958129883
EPOCH 466:
  batch 1000 loss: 3.4662131435871126
LOSS train 3.4662131435871126 valid 3.513948440551758
EPOCH 467:
  batch 1000 loss: 3.4949038965702055
LOSS train 3.4949038965702055 valid 3.513641595840454
EPOCH 468:
  batch 1000 loss: 3.486302752494812
LOSS train 3.486302752494812 valid 3.5132741928100586
EPOCH 469:
  batch 1000 loss: 3.4832470153570174
LOSS train 3.4832470153570174 valid 3.513566017150879
EPOCH 470:
  batch 1000 loss: 3.47061102104187
LOSS train 3.47061102104187 valid 3.5137109756469727
EPOCH 471:
  batch 1000 loss: 3.4666471643447876
LOSS train 3.4666471643447876 valid 3.513633966445923
EPOCH 472:
  batch 1000 loss: 3.481476226568222
LOSS train 3.481476226568222 valid 3.5136682987213135
EPOCH 473:
  batch 1000 loss: 3.4656027257442474
LOSS train 3.4656027257442474 valid 3.5143115520477295
EPOCH 474:
  batch 1000 loss: 3.469556508421898
LOSS train 3.469556508421898 valid 3.51450777053833
EPOCH 475:
  batch 1000 loss: 3.4801095287799835
LOSS train 3.4801095287799835 valid 3.5136804580688477
EPOCH 476:
  batch 1000 loss: 3.472579455137253
LOSS train 3.472579455137253 valid 3.5134339332580566
EPOCH 477:
  batch 1000 loss: 3.468851716160774
LOSS train 3.468851716160774 valid 3.51401686668396
EPOCH 478:
  batch 1000 loss: 3.4787804695367814
LOSS train 3.4787804695367814 valid 3.512897253036499
EPOCH 479:
  batch 1000 loss: 3.4870521004199984
LOSS train 3.4870521004199984 valid 3.51379656791687
EPOCH 480:
  batch 1000 loss: 3.474808013319969
LOSS train 3.474808013319969 valid 3.513195514678955
EPOCH 481:
  batch 1000 loss: 3.4657961444854735
LOSS train 3.4657961444854735 valid 3.514512538909912
EPOCH 482:
  batch 1000 loss: 3.4713885217905043
LOSS train 3.4713885217905043 valid 3.513556718826294
EPOCH 483:
  batch 1000 loss: 3.4852650742530824
LOSS train 3.4852650742530824 valid 3.5134658813476562
EPOCH 484:
  batch 1000 loss: 3.472619917035103
LOSS train 3.472619917035103 valid 3.5132839679718018
EPOCH 485:
  batch 1000 loss: 3.4571271609067917
LOSS train 3.4571271609067917 valid 3.5136122703552246
EPOCH 486:
  batch 1000 loss: 3.4758832647800446
LOSS train 3.4758832647800446 valid 3.5134849548339844
EPOCH 487:
  batch 1000 loss: 3.467021139740944
LOSS train 3.467021139740944 valid 3.512918710708618
EPOCH 488:
  batch 1000 loss: 3.4655242763757705
LOSS train 3.4655242763757705 valid 3.5133652687072754
EPOCH 489:
  batch 1000 loss: 3.4671635665893556
LOSS train 3.4671635665893556 valid 3.513751983642578
EPOCH 490:
  batch 1000 loss: 3.4838289828300475
LOSS train 3.4838289828300475 valid 3.513183832168579
EPOCH 491:
  batch 1000 loss: 3.488934814929962
LOSS train 3.488934814929962 valid 3.5136404037475586
EPOCH 492:
  batch 1000 loss: 3.4824385755062104
LOSS train 3.4824385755062104 valid 3.5134615898132324
EPOCH 493:
  batch 1000 loss: 3.4763611226081848
LOSS train 3.4763611226081848 valid 3.513284921646118
EPOCH 494:
  batch 1000 loss: 3.4605130512714384
LOSS train 3.4605130512714384 valid 3.5145089626312256
EPOCH 495:
  batch 1000 loss: 3.477247605443001
LOSS train 3.477247605443001 valid 3.5135042667388916
EPOCH 496:
  batch 1000 loss: 3.472332376718521
LOSS train 3.472332376718521 valid 3.5132031440734863
EPOCH 497:
  batch 1000 loss: 3.499644584774971
LOSS train 3.499644584774971 valid 3.514050245285034
EPOCH 498:
  batch 1000 loss: 3.4753236935138703
LOSS train 3.4753236935138703 valid 3.513294219970703
EPOCH 499:
  batch 1000 loss: 3.4864396151304247
LOSS train 3.4864396151304247 valid 3.514002561569214
EPOCH 500:
  batch 1000 loss: 3.47236070561409
LOSS train 3.47236070561409 valid 3.5131728649139404
