nohup: ignoring input
EPOCH 1:
  batch 1000 loss: 6.361650497436523
LOSS train 6.361650497436523 valid 5.1612348556518555
EPOCH 2:
  batch 1000 loss: 5.0240266275405885
LOSS train 5.0240266275405885 valid 4.913748741149902
EPOCH 3:
  batch 1000 loss: 4.82898405623436
LOSS train 4.82898405623436 valid 4.739729404449463
EPOCH 4:
  batch 1000 loss: 4.625206686973572
LOSS train 4.625206686973572 valid 4.561253547668457
EPOCH 5:
  batch 1000 loss: 4.477376565217972
LOSS train 4.477376565217972 valid 4.432767868041992
EPOCH 6:
  batch 1000 loss: 4.34578617978096
LOSS train 4.34578617978096 valid 4.313969135284424
EPOCH 7:
  batch 1000 loss: 4.286729078292847
LOSS train 4.286729078292847 valid 4.259900093078613
EPOCH 8:
  batch 1000 loss: 4.1941397132873535
LOSS train 4.1941397132873535 valid 4.236013412475586
EPOCH 9:
  batch 1000 loss: 4.165328389167786
LOSS train 4.165328389167786 valid 4.136756896972656
EPOCH 10:
  batch 1000 loss: 4.110458015441894
LOSS train 4.110458015441894 valid 4.1269001960754395
EPOCH 11:
  batch 1000 loss: 4.0714883699417115
LOSS train 4.0714883699417115 valid 4.061827659606934
EPOCH 12:
  batch 1000 loss: 4.039098672151566
LOSS train 4.039098672151566 valid 4.086063861846924
EPOCH 13:
  batch 1000 loss: 4.023489602565766
LOSS train 4.023489602565766 valid 4.035315036773682
EPOCH 14:
  batch 1000 loss: 3.97607371878624
LOSS train 3.97607371878624 valid 4.000302314758301
EPOCH 15:
  batch 1000 loss: 3.9506272614002227
LOSS train 3.9506272614002227 valid 3.98136830329895
EPOCH 16:
  batch 1000 loss: 3.962074106693268
LOSS train 3.962074106693268 valid 3.982365369796753
EPOCH 17:
  batch 1000 loss: 3.9696936609745026
LOSS train 3.9696936609745026 valid 3.941924571990967
EPOCH 18:
  batch 1000 loss: 3.9287024335861207
LOSS train 3.9287024335861207 valid 3.9547364711761475
EPOCH 19:
  batch 1000 loss: 3.9042701325416567
LOSS train 3.9042701325416567 valid 3.9449212551116943
EPOCH 20:
  batch 1000 loss: 3.894798222780228
LOSS train 3.894798222780228 valid 3.935366153717041
EPOCH 21:
  batch 1000 loss: 3.9244945108890534
LOSS train 3.9244945108890534 valid 3.909041404724121
EPOCH 22:
  batch 1000 loss: 3.8875816798210145
LOSS train 3.8875816798210145 valid 3.952310800552368
EPOCH 23:
  batch 1000 loss: 3.882760260343552
LOSS train 3.882760260343552 valid 3.911508798599243
EPOCH 24:
  batch 1000 loss: 3.877279236316681
LOSS train 3.877279236316681 valid 3.9973812103271484
EPOCH 25:
  batch 1000 loss: 3.864435190677643
LOSS train 3.864435190677643 valid 3.859137535095215
EPOCH 26:
  batch 1000 loss: 3.8661465079784394
LOSS train 3.8661465079784394 valid 3.90371036529541
EPOCH 27:
  batch 1000 loss: 3.857057025671005
LOSS train 3.857057025671005 valid 3.899611711502075
EPOCH 28:
  batch 1000 loss: 3.8542553169727327
LOSS train 3.8542553169727327 valid 3.8686892986297607
EPOCH 29:
  batch 1000 loss: 3.831822997689247
LOSS train 3.831822997689247 valid 3.92213773727417
EPOCH 30:
  batch 1000 loss: 3.823704316854477
LOSS train 3.823704316854477 valid 3.843355655670166
EPOCH 31:
  batch 1000 loss: 3.818808356761932
LOSS train 3.818808356761932 valid 3.849771499633789
EPOCH 32:
  batch 1000 loss: 3.845182745695114
LOSS train 3.845182745695114 valid 3.833406686782837
EPOCH 33:
  batch 1000 loss: 3.8213051421642303
LOSS train 3.8213051421642303 valid 3.880807876586914
EPOCH 34:
  batch 1000 loss: 3.8261084203720093
LOSS train 3.8261084203720093 valid 3.8358142375946045
EPOCH 35:
  batch 1000 loss: 3.808036376476288
LOSS train 3.808036376476288 valid 3.834728479385376
EPOCH 36:
  batch 1000 loss: 3.80659272313118
LOSS train 3.80659272313118 valid 3.846684455871582
EPOCH 37:
  batch 1000 loss: 3.8316537780761717
LOSS train 3.8316537780761717 valid 3.8087522983551025
EPOCH 38:
  batch 1000 loss: 3.771662038087845
LOSS train 3.771662038087845 valid 3.825777769088745
EPOCH 39:
  batch 1000 loss: 3.8004175524711608
LOSS train 3.8004175524711608 valid 3.817653179168701
EPOCH 40:
  batch 1000 loss: 3.822577446222305
LOSS train 3.822577446222305 valid 3.8041117191314697
EPOCH 41:
  batch 1000 loss: 3.784606578350067
LOSS train 3.784606578350067 valid 3.780827760696411
EPOCH 42:
  batch 1000 loss: 3.770247372865677
LOSS train 3.770247372865677 valid 3.801990509033203
EPOCH 43:
  batch 1000 loss: 3.808575471162796
LOSS train 3.808575471162796 valid 3.799713611602783
EPOCH 44:
  batch 1000 loss: 3.7795093073844908
LOSS train 3.7795093073844908 valid 3.8079490661621094
EPOCH 45:
  batch 1000 loss: 3.7799307940006255
LOSS train 3.7799307940006255 valid 3.803884983062744
EPOCH 46:
  batch 1000 loss: 3.786928819298744
LOSS train 3.786928819298744 valid 3.7877402305603027
EPOCH 47:
  batch 1000 loss: 3.7614933953285217
Epoch 00047: reducing learning rate of group 0 to 5.0000e-04.
LOSS train 3.7614933953285217 valid 3.793281316757202
EPOCH 48:
  batch 1000 loss: 3.7302278490066527
LOSS train 3.7302278490066527 valid 3.740816354751587
EPOCH 49:
  batch 1000 loss: 3.740861771821976
LOSS train 3.740861771821976 valid 3.7457361221313477
EPOCH 50:
  batch 1000 loss: 3.701963729143143
LOSS train 3.701963729143143 valid 3.7342419624328613
EPOCH 51:
  batch 1000 loss: 3.7091186056137087
LOSS train 3.7091186056137087 valid 3.7281816005706787
EPOCH 52:
  batch 1000 loss: 3.7277883894443513
LOSS train 3.7277883894443513 valid 3.732727527618408
EPOCH 53:
  batch 1000 loss: 3.7040537257194517
LOSS train 3.7040537257194517 valid 3.7205371856689453
EPOCH 54:
  batch 1000 loss: 3.692347313165665
LOSS train 3.692347313165665 valid 3.725116014480591
EPOCH 55:
  batch 1000 loss: 3.685670804977417
LOSS train 3.685670804977417 valid 3.7247302532196045
EPOCH 56:
  batch 1000 loss: 3.6703755180835724
LOSS train 3.6703755180835724 valid 3.729541778564453
EPOCH 57:
  batch 1000 loss: 3.700811435699463
LOSS train 3.700811435699463 valid 3.7182974815368652
EPOCH 58:
  batch 1000 loss: 3.670038174152374
LOSS train 3.670038174152374 valid 3.7215347290039062
EPOCH 59:
  batch 1000 loss: 3.682146823644638
LOSS train 3.682146823644638 valid 3.716172933578491
EPOCH 60:
  batch 1000 loss: 3.689182497382164
LOSS train 3.689182497382164 valid 3.7217118740081787
EPOCH 61:
  batch 1000 loss: 3.6890166021585467
LOSS train 3.6890166021585467 valid 3.7286300659179688
EPOCH 62:
  batch 1000 loss: 3.6894600831270217
LOSS train 3.6894600831270217 valid 3.71616792678833
EPOCH 63:
  batch 1000 loss: 3.672103131890297
LOSS train 3.672103131890297 valid 3.708069324493408
EPOCH 64:
  batch 1000 loss: 3.6832498601675034
LOSS train 3.6832498601675034 valid 3.7049217224121094
EPOCH 65:
  batch 1000 loss: 3.687999439239502
LOSS train 3.687999439239502 valid 3.711418628692627
EPOCH 66:
  batch 1000 loss: 3.6992756675481795
LOSS train 3.6992756675481795 valid 3.7094340324401855
EPOCH 67:
  batch 1000 loss: 3.6861667120456696
LOSS train 3.6861667120456696 valid 3.71455717086792
EPOCH 68:
  batch 1000 loss: 3.6645809562206266
LOSS train 3.6645809562206266 valid 3.712116241455078
EPOCH 69:
  batch 1000 loss: 3.6560640938282014
LOSS train 3.6560640938282014 valid 3.705479860305786
EPOCH 70:
  batch 1000 loss: 3.68305272936821
LOSS train 3.68305272936821 valid 3.6943318843841553
EPOCH 71:
  batch 1000 loss: 3.677383119702339
LOSS train 3.677383119702339 valid 3.693735122680664
EPOCH 72:
  batch 1000 loss: 3.6715314073562624
LOSS train 3.6715314073562624 valid 3.7057087421417236
EPOCH 73:
  batch 1000 loss: 3.6478721718788147
LOSS train 3.6478721718788147 valid 3.701582431793213
EPOCH 74:
  batch 1000 loss: 3.6567743566036226
LOSS train 3.6567743566036226 valid 3.688408374786377
EPOCH 75:
  batch 1000 loss: 3.6858581693172456
LOSS train 3.6858581693172456 valid 3.6922519207000732
EPOCH 76:
  batch 1000 loss: 3.6645330682992934
LOSS train 3.6645330682992934 valid 3.6871705055236816
EPOCH 77:
  batch 1000 loss: 3.652859233379364
LOSS train 3.652859233379364 valid 3.690744400024414
EPOCH 78:
  batch 1000 loss: 3.6448007822036743
LOSS train 3.6448007822036743 valid 3.681105136871338
EPOCH 79:
  batch 1000 loss: 3.6585477283000944
LOSS train 3.6585477283000944 valid 3.7186405658721924
EPOCH 80:
  batch 1000 loss: 3.6656144449710846
LOSS train 3.6656144449710846 valid 3.6902248859405518
EPOCH 81:
  batch 1000 loss: 3.6648839726448057
LOSS train 3.6648839726448057 valid 3.678025245666504
EPOCH 82:
  batch 1000 loss: 3.6647711254358293
LOSS train 3.6647711254358293 valid 3.680157423019409
EPOCH 83:
  batch 1000 loss: 3.6490433671474456
LOSS train 3.6490433671474456 valid 3.6922109127044678
EPOCH 84:
  batch 1000 loss: 3.667724872469902
LOSS train 3.667724872469902 valid 3.692871332168579
EPOCH 85:
  batch 1000 loss: 3.646866366505623
LOSS train 3.646866366505623 valid 3.676891803741455
EPOCH 86:
  batch 1000 loss: 3.6546304367780684
LOSS train 3.6546304367780684 valid 3.6829967498779297
EPOCH 87:
  batch 1000 loss: 3.648256915450096
LOSS train 3.648256915450096 valid 3.681992530822754
EPOCH 88:
  batch 1000 loss: 3.6332662569284437
LOSS train 3.6332662569284437 valid 3.679769277572632
EPOCH 89:
  batch 1000 loss: 3.6460122047662735
LOSS train 3.6460122047662735 valid 3.676020383834839
EPOCH 90:
  batch 1000 loss: 3.6369342696666718
LOSS train 3.6369342696666718 valid 3.6969447135925293
EPOCH 91:
  batch 1000 loss: 3.6571648507118226
LOSS train 3.6571648507118226 valid 3.6763839721679688
EPOCH 92:
  batch 1000 loss: 3.6606173655986787
LOSS train 3.6606173655986787 valid 3.685668706893921
EPOCH 93:
  batch 1000 loss: 3.64097906434536
LOSS train 3.64097906434536 valid 3.6717147827148438
EPOCH 94:
  batch 1000 loss: 3.6593822472095487
LOSS train 3.6593822472095487 valid 3.6756162643432617
EPOCH 95:
  batch 1000 loss: 3.6570871980190276
LOSS train 3.6570871980190276 valid 3.675596237182617
EPOCH 96:
  batch 1000 loss: 3.645722892284393
LOSS train 3.645722892284393 valid 3.682964324951172
EPOCH 97:
  batch 1000 loss: 3.640856010079384
LOSS train 3.640856010079384 valid 3.6644539833068848
EPOCH 98:
  batch 1000 loss: 3.659443659424782
LOSS train 3.659443659424782 valid 3.665275812149048
EPOCH 99:
  batch 1000 loss: 3.644827087879181
LOSS train 3.644827087879181 valid 3.666483163833618
EPOCH 100:
  batch 1000 loss: 3.6629650897979738
LOSS train 3.6629650897979738 valid 3.683398485183716
EPOCH 101:
  batch 1000 loss: 3.6511538960933687
LOSS train 3.6511538960933687 valid 3.6607630252838135
EPOCH 102:
  batch 1000 loss: 3.6482958936691285
LOSS train 3.6482958936691285 valid 3.6612985134124756
EPOCH 103:
  batch 1000 loss: 3.6361618604660033
LOSS train 3.6361618604660033 valid 3.688180446624756
EPOCH 104:
  batch 1000 loss: 3.6512267920970918
LOSS train 3.6512267920970918 valid 3.6680891513824463
EPOCH 105:
  batch 1000 loss: 3.6388751183748247
LOSS train 3.6388751183748247 valid 3.6758861541748047
EPOCH 106:
  batch 1000 loss: 3.622017813205719
LOSS train 3.622017813205719 valid 3.6870477199554443
EPOCH 107:
  batch 1000 loss: 3.6284982676506043
LOSS train 3.6284982676506043 valid 3.660174608230591
EPOCH 108:
  batch 1000 loss: 3.64852236700058
LOSS train 3.64852236700058 valid 3.655808448791504
EPOCH 109:
  batch 1000 loss: 3.64752147936821
LOSS train 3.64752147936821 valid 3.654630422592163
EPOCH 110:
  batch 1000 loss: 3.640852760076523
LOSS train 3.640852760076523 valid 3.661003589630127
EPOCH 111:
  batch 1000 loss: 3.6124857552051544
LOSS train 3.6124857552051544 valid 3.69315242767334
EPOCH 112:
  batch 1000 loss: 3.631789978981018
LOSS train 3.631789978981018 valid 3.659884452819824
EPOCH 113:
  batch 1000 loss: 3.6599756121635436
LOSS train 3.6599756121635436 valid 3.667447328567505
EPOCH 114:
  batch 1000 loss: 3.633162351846695
LOSS train 3.633162351846695 valid 3.649200201034546
EPOCH 115:
  batch 1000 loss: 3.6451258336305616
LOSS train 3.6451258336305616 valid 3.6469368934631348
EPOCH 116:
  batch 1000 loss: 3.65057794547081
LOSS train 3.65057794547081 valid 3.6555912494659424
EPOCH 117:
  batch 1000 loss: 3.630134580373764
LOSS train 3.630134580373764 valid 3.66048002243042
EPOCH 118:
  batch 1000 loss: 3.6401687384843826
LOSS train 3.6401687384843826 valid 3.6556589603424072
EPOCH 119:
  batch 1000 loss: 3.6316854518651964
LOSS train 3.6316854518651964 valid 3.6555089950561523
EPOCH 120:
  batch 1000 loss: 3.6188952343463896
LOSS train 3.6188952343463896 valid 3.6491408348083496
EPOCH 121:
  batch 1000 loss: 3.641228544831276
Epoch 00121: reducing learning rate of group 0 to 2.5000e-04.
LOSS train 3.641228544831276 valid 3.665527820587158
EPOCH 122:
  batch 1000 loss: 3.609428491473198
LOSS train 3.609428491473198 valid 3.6319522857666016
EPOCH 123:
  batch 1000 loss: 3.5926273847818373
LOSS train 3.5926273847818373 valid 3.628760814666748
EPOCH 124:
  batch 1000 loss: 3.596434345126152
LOSS train 3.596434345126152 valid 3.626554250717163
EPOCH 125:
  batch 1000 loss: 3.606625102639198
LOSS train 3.606625102639198 valid 3.625143051147461
EPOCH 126:
  batch 1000 loss: 3.6279486546516417
LOSS train 3.6279486546516417 valid 3.626216411590576
EPOCH 127:
  batch 1000 loss: 3.592155970811844
LOSS train 3.592155970811844 valid 3.633714199066162
EPOCH 128:
  batch 1000 loss: 3.6120867290496825
LOSS train 3.6120867290496825 valid 3.6309804916381836
EPOCH 129:
  batch 1000 loss: 3.613888984680176
LOSS train 3.613888984680176 valid 3.6312310695648193
EPOCH 130:
  batch 1000 loss: 3.608900822639465
LOSS train 3.608900822639465 valid 3.623443126678467
EPOCH 131:
  batch 1000 loss: 3.592695905327797
LOSS train 3.592695905327797 valid 3.6245217323303223
EPOCH 132:
  batch 1000 loss: 3.616372169852257
LOSS train 3.616372169852257 valid 3.623610019683838
EPOCH 133:
  batch 1000 loss: 3.6148045971393583
LOSS train 3.6148045971393583 valid 3.6242570877075195
EPOCH 134:
  batch 1000 loss: 3.5964835951328276
LOSS train 3.5964835951328276 valid 3.6233818531036377
EPOCH 135:
  batch 1000 loss: 3.586987609386444
LOSS train 3.586987609386444 valid 3.6221139430999756
EPOCH 136:
  batch 1000 loss: 3.602902978658676
LOSS train 3.602902978658676 valid 3.6248998641967773
EPOCH 137:
  batch 1000 loss: 3.6073217091560363
LOSS train 3.6073217091560363 valid 3.622649669647217
EPOCH 138:
  batch 1000 loss: 3.5859492207765578
LOSS train 3.5859492207765578 valid 3.6144044399261475
EPOCH 139:
  batch 1000 loss: 3.5963393914699555
LOSS train 3.5963393914699555 valid 3.617743730545044
EPOCH 140:
  batch 1000 loss: 3.607416820764542
LOSS train 3.607416820764542 valid 3.6198360919952393
EPOCH 141:
  batch 1000 loss: 3.5797191042900085
LOSS train 3.5797191042900085 valid 3.613682508468628
EPOCH 142:
  batch 1000 loss: 3.606906035423279
LOSS train 3.606906035423279 valid 3.6158008575439453
EPOCH 143:
  batch 1000 loss: 3.5965241956710816
LOSS train 3.5965241956710816 valid 3.6182398796081543
EPOCH 144:
  batch 1000 loss: 3.5764608215093614
LOSS train 3.5764608215093614 valid 3.6153876781463623
EPOCH 145:
  batch 1000 loss: 3.5937142589092255
LOSS train 3.5937142589092255 valid 3.6211934089660645
EPOCH 146:
  batch 1000 loss: 3.610458895802498
LOSS train 3.610458895802498 valid 3.624122142791748
EPOCH 147:
  batch 1000 loss: 3.5967062003612518
Epoch 00147: reducing learning rate of group 0 to 1.2500e-04.
LOSS train 3.5967062003612518 valid 3.619616985321045
EPOCH 148:
  batch 1000 loss: 3.5753866579532625
LOSS train 3.5753866579532625 valid 3.6084461212158203
EPOCH 149:
  batch 1000 loss: 3.584250063419342
LOSS train 3.584250063419342 valid 3.6056556701660156
EPOCH 150:
  batch 1000 loss: 3.5696268610954283
LOSS train 3.5696268610954283 valid 3.6061205863952637
EPOCH 151:
  batch 1000 loss: 3.567494506716728
LOSS train 3.567494506716728 valid 3.6042394638061523
EPOCH 152:
  batch 1000 loss: 3.5819539527893065
LOSS train 3.5819539527893065 valid 3.6031699180603027
EPOCH 153:
  batch 1000 loss: 3.5615754576921463
LOSS train 3.5615754576921463 valid 3.606163501739502
EPOCH 154:
  batch 1000 loss: 3.5562795559167864
LOSS train 3.5562795559167864 valid 3.6028034687042236
EPOCH 155:
  batch 1000 loss: 3.5873780658245087
LOSS train 3.5873780658245087 valid 3.6038131713867188
EPOCH 156:
  batch 1000 loss: 3.5813872909545896
LOSS train 3.5813872909545896 valid 3.6018550395965576
EPOCH 157:
  batch 1000 loss: 3.575822223782539
LOSS train 3.575822223782539 valid 3.6057639122009277
EPOCH 158:
  batch 1000 loss: 3.568980208158493
LOSS train 3.568980208158493 valid 3.601043224334717
EPOCH 159:
  batch 1000 loss: 3.5701873133182525
LOSS train 3.5701873133182525 valid 3.601776123046875
EPOCH 160:
  batch 1000 loss: 3.568616388440132
LOSS train 3.568616388440132 valid 3.601590633392334
EPOCH 161:
  batch 1000 loss: 3.56897406744957
LOSS train 3.56897406744957 valid 3.6029791831970215
EPOCH 162:
  batch 1000 loss: 3.570382037639618
LOSS train 3.570382037639618 valid 3.6016287803649902
EPOCH 163:
  batch 1000 loss: 3.566829397559166
LOSS train 3.566829397559166 valid 3.6028242111206055
EPOCH 164:
  batch 1000 loss: 3.572336595058441
LOSS train 3.572336595058441 valid 3.5994670391082764
EPOCH 165:
  batch 1000 loss: 3.568894280076027
LOSS train 3.568894280076027 valid 3.6008896827697754
EPOCH 166:
  batch 1000 loss: 3.5902353465557098
LOSS train 3.5902353465557098 valid 3.598172664642334
EPOCH 167:
  batch 1000 loss: 3.5803680860996248
LOSS train 3.5803680860996248 valid 3.5980677604675293
EPOCH 168:
  batch 1000 loss: 3.5748345872163774
LOSS train 3.5748345872163774 valid 3.597627878189087
EPOCH 169:
  batch 1000 loss: 3.560283568263054
LOSS train 3.560283568263054 valid 3.59904408454895
EPOCH 170:
  batch 1000 loss: 3.5584975724220276
LOSS train 3.5584975724220276 valid 3.5961458683013916
EPOCH 171:
  batch 1000 loss: 3.5698720952272414
LOSS train 3.5698720952272414 valid 3.598414421081543
EPOCH 172:
  batch 1000 loss: 3.562178628921509
LOSS train 3.562178628921509 valid 3.598201036453247
EPOCH 173:
  batch 1000 loss: 3.585976072669029
LOSS train 3.585976072669029 valid 3.6028850078582764
EPOCH 174:
  batch 1000 loss: 3.576051081776619
LOSS train 3.576051081776619 valid 3.5979068279266357
EPOCH 175:
  batch 1000 loss: 3.5718932409286497
LOSS train 3.5718932409286497 valid 3.597810745239258
EPOCH 176:
  batch 1000 loss: 3.576879129886627
Epoch 00176: reducing learning rate of group 0 to 6.2500e-05.
LOSS train 3.576879129886627 valid 3.5961766242980957
EPOCH 177:
  batch 1000 loss: 3.585837115883827
LOSS train 3.585837115883827 valid 3.5931589603424072
EPOCH 178:
  batch 1000 loss: 3.5676868878602983
LOSS train 3.5676868878602983 valid 3.595106840133667
EPOCH 179:
  batch 1000 loss: 3.5617980867624284
LOSS train 3.5617980867624284 valid 3.5922417640686035
EPOCH 180:
  batch 1000 loss: 3.563017294168472
LOSS train 3.563017294168472 valid 3.5926194190979004
EPOCH 181:
  batch 1000 loss: 3.5514540150165557
LOSS train 3.5514540150165557 valid 3.5914878845214844
EPOCH 182:
  batch 1000 loss: 3.559837141990662
LOSS train 3.559837141990662 valid 3.5916895866394043
EPOCH 183:
  batch 1000 loss: 3.5595814687013627
LOSS train 3.5595814687013627 valid 3.591881275177002
EPOCH 184:
  batch 1000 loss: 3.5627620297670366
LOSS train 3.5627620297670366 valid 3.5908126831054688
EPOCH 185:
  batch 1000 loss: 3.5662751282453535
LOSS train 3.5662751282453535 valid 3.5911755561828613
EPOCH 186:
  batch 1000 loss: 3.5708483867645264
LOSS train 3.5708483867645264 valid 3.5884382724761963
EPOCH 187:
  batch 1000 loss: 3.57557107257843
LOSS train 3.57557107257843 valid 3.5887346267700195
EPOCH 188:
  batch 1000 loss: 3.569901129245758
LOSS train 3.569901129245758 valid 3.590646743774414
EPOCH 189:
  batch 1000 loss: 3.5600679763555525
LOSS train 3.5600679763555525 valid 3.589639663696289
EPOCH 190:
  batch 1000 loss: 3.546597515821457
LOSS train 3.546597515821457 valid 3.592210292816162
EPOCH 191:
  batch 1000 loss: 3.5729029680490494
LOSS train 3.5729029680490494 valid 3.5885627269744873
EPOCH 192:
  batch 1000 loss: 3.562489671230316
Epoch 00192: reducing learning rate of group 0 to 3.1250e-05.
LOSS train 3.562489671230316 valid 3.5903773307800293
EPOCH 193:
  batch 1000 loss: 3.529557616233826
LOSS train 3.529557616233826 valid 3.5881271362304688
EPOCH 194:
  batch 1000 loss: 3.565010134100914
LOSS train 3.565010134100914 valid 3.5888121128082275
EPOCH 195:
  batch 1000 loss: 3.539281373500824
LOSS train 3.539281373500824 valid 3.588125228881836
EPOCH 196:
  batch 1000 loss: 3.5396158121824266
LOSS train 3.5396158121824266 valid 3.5879619121551514
EPOCH 197:
  batch 1000 loss: 3.5707766680717468
LOSS train 3.5707766680717468 valid 3.588324785232544
EPOCH 198:
  batch 1000 loss: 3.5600527770519257
LOSS train 3.5600527770519257 valid 3.587662696838379
EPOCH 199:
  batch 1000 loss: 3.5467403178215027
LOSS train 3.5467403178215027 valid 3.5884170532226562
EPOCH 200:
  batch 1000 loss: 3.5497040289640425
LOSS train 3.5497040289640425 valid 3.587585210800171
EPOCH 201:
  batch 1000 loss: 3.5629966109991074
LOSS train 3.5629966109991074 valid 3.587585210800171
EPOCH 202:
  batch 1000 loss: 3.558714570045471
LOSS train 3.558714570045471 valid 3.586951971054077
EPOCH 203:
  batch 1000 loss: 3.551070048570633
LOSS train 3.551070048570633 valid 3.5853724479675293
EPOCH 204:
  batch 1000 loss: 3.5715918765068055
LOSS train 3.5715918765068055 valid 3.5847527980804443
EPOCH 205:
  batch 1000 loss: 3.5549636985063553
LOSS train 3.5549636985063553 valid 3.5851337909698486
EPOCH 206:
  batch 1000 loss: 3.5496727312803267
LOSS train 3.5496727312803267 valid 3.5873680114746094
EPOCH 207:
  batch 1000 loss: 3.560221118569374
LOSS train 3.560221118569374 valid 3.5875837802886963
EPOCH 208:
  batch 1000 loss: 3.5479862184524538
LOSS train 3.5479862184524538 valid 3.5864689350128174
EPOCH 209:
  batch 1000 loss: 3.567357768535614
LOSS train 3.567357768535614 valid 3.5851383209228516
EPOCH 210:
  batch 1000 loss: 3.568114879131317
Epoch 00210: reducing learning rate of group 0 to 1.5625e-05.
LOSS train 3.568114879131317 valid 3.588498830795288
EPOCH 211:
  batch 1000 loss: 3.5496218975782394
LOSS train 3.5496218975782394 valid 3.5860772132873535
EPOCH 212:
  batch 1000 loss: 3.555084378242493
LOSS train 3.555084378242493 valid 3.58711314201355
EPOCH 213:
  batch 1000 loss: 3.5494736905097963
LOSS train 3.5494736905097963 valid 3.5864241123199463
EPOCH 214:
  batch 1000 loss: 3.535710457801819
LOSS train 3.535710457801819 valid 3.585667848587036
EPOCH 215:
  batch 1000 loss: 3.5346411383152008
LOSS train 3.5346411383152008 valid 3.5862247943878174
EPOCH 216:
  batch 1000 loss: 3.5633290882110598
Epoch 00216: reducing learning rate of group 0 to 7.8125e-06.
LOSS train 3.5633290882110598 valid 3.5864827632904053
EPOCH 217:
  batch 1000 loss: 3.5421757150888444
LOSS train 3.5421757150888444 valid 3.583249092102051
EPOCH 218:
  batch 1000 loss: 3.556202709078789
LOSS train 3.556202709078789 valid 3.585188865661621
EPOCH 219:
  batch 1000 loss: 3.5398703902959823
LOSS train 3.5398703902959823 valid 3.584948778152466
EPOCH 220:
  batch 1000 loss: 3.5430027639865873
LOSS train 3.5430027639865873 valid 3.5836234092712402
EPOCH 221:
  batch 1000 loss: 3.549561624646187
LOSS train 3.549561624646187 valid 3.585505723953247
EPOCH 222:
  batch 1000 loss: 3.5568030531406403
LOSS train 3.5568030531406403 valid 3.583115816116333
EPOCH 223:
  batch 1000 loss: 3.571793248295784
Epoch 00223: reducing learning rate of group 0 to 3.9063e-06.
LOSS train 3.571793248295784 valid 3.5852324962615967
EPOCH 224:
  batch 1000 loss: 3.554092253088951
LOSS train 3.554092253088951 valid 3.5827579498291016
EPOCH 225:
  batch 1000 loss: 3.546147633671761
LOSS train 3.546147633671761 valid 3.583455801010132
EPOCH 226:
  batch 1000 loss: 3.529546924352646
LOSS train 3.529546924352646 valid 3.5847361087799072
EPOCH 227:
  batch 1000 loss: 3.5422013771533964
LOSS train 3.5422013771533964 valid 3.585972547531128
EPOCH 228:
  batch 1000 loss: 3.5330991351604464
LOSS train 3.5330991351604464 valid 3.584691047668457
EPOCH 229:
  batch 1000 loss: 3.5551112306118013
LOSS train 3.5551112306118013 valid 3.585653781890869
EPOCH 230:
  batch 1000 loss: 3.535892108917236
Epoch 00230: reducing learning rate of group 0 to 1.9531e-06.
LOSS train 3.535892108917236 valid 3.5827839374542236
EPOCH 231:
  batch 1000 loss: 3.5719431161880495
LOSS train 3.5719431161880495 valid 3.5847787857055664
EPOCH 232:
  batch 1000 loss: 3.529360344648361
LOSS train 3.529360344648361 valid 3.583167552947998
EPOCH 233:
  batch 1000 loss: 3.543408432006836
LOSS train 3.543408432006836 valid 3.5857527256011963
EPOCH 234:
  batch 1000 loss: 3.5400620045661926
LOSS train 3.5400620045661926 valid 3.5852363109588623
EPOCH 235:
  batch 1000 loss: 3.5627285504341124
LOSS train 3.5627285504341124 valid 3.585263252258301
EPOCH 236:
  batch 1000 loss: 3.5619548473358154
Epoch 00236: reducing learning rate of group 0 to 9.7656e-07.
LOSS train 3.5619548473358154 valid 3.582411527633667
EPOCH 237:
  batch 1000 loss: 3.553973766565323
LOSS train 3.553973766565323 valid 3.5848798751831055
EPOCH 238:
  batch 1000 loss: 3.5477323944568635
LOSS train 3.5477323944568635 valid 3.5853073596954346
EPOCH 239:
  batch 1000 loss: 3.5268892357349397
LOSS train 3.5268892357349397 valid 3.5853750705718994
EPOCH 240:
  batch 1000 loss: 3.547603502750397
LOSS train 3.547603502750397 valid 3.5822391510009766
EPOCH 241:
  batch 1000 loss: 3.52070366191864
LOSS train 3.52070366191864 valid 3.585148572921753
EPOCH 242:
  batch 1000 loss: 3.5541059670448303
LOSS train 3.5541059670448303 valid 3.582955837249756
EPOCH 243:
  batch 1000 loss: 3.556849452972412
LOSS train 3.556849452972412 valid 3.5851986408233643
EPOCH 244:
  batch 1000 loss: 3.538704897880554
LOSS train 3.538704897880554 valid 3.585639238357544
EPOCH 245:
  batch 1000 loss: 3.540974112868309
LOSS train 3.540974112868309 valid 3.585313081741333
EPOCH 246:
  batch 1000 loss: 3.5406127661466598
Epoch 00246: reducing learning rate of group 0 to 4.8828e-07.
LOSS train 3.5406127661466598 valid 3.585275411605835
EPOCH 247:
  batch 1000 loss: 3.5491606199741366
LOSS train 3.5491606199741366 valid 3.5858349800109863
EPOCH 248:
  batch 1000 loss: 3.555555436372757
LOSS train 3.555555436372757 valid 3.5847418308258057
EPOCH 249:
  batch 1000 loss: 3.5598709886074067
LOSS train 3.5598709886074067 valid 3.5851352214813232
EPOCH 250:
  batch 1000 loss: 3.5541573942899705
LOSS train 3.5541573942899705 valid 3.5823757648468018
EPOCH 251:
  batch 1000 loss: 3.5403966596126555
LOSS train 3.5403966596126555 valid 3.5848846435546875
EPOCH 252:
  batch 1000 loss: 3.560536835551262
Epoch 00252: reducing learning rate of group 0 to 2.4414e-07.
LOSS train 3.560536835551262 valid 3.5852065086364746
EPOCH 253:
  batch 1000 loss: 3.5294303002357483
LOSS train 3.5294303002357483 valid 3.5849688053131104
EPOCH 254:
  batch 1000 loss: 3.5321744059324263
LOSS train 3.5321744059324263 valid 3.58450984954834
EPOCH 255:
  batch 1000 loss: 3.5631765491962435
LOSS train 3.5631765491962435 valid 3.5829617977142334
EPOCH 256:
  batch 1000 loss: 3.5451992973089217
LOSS train 3.5451992973089217 valid 3.585218906402588
EPOCH 257:
  batch 1000 loss: 3.5574486939907075
LOSS train 3.5574486939907075 valid 3.585207462310791
EPOCH 258:
  batch 1000 loss: 3.5338903298377993
Epoch 00258: reducing learning rate of group 0 to 1.2207e-07.
LOSS train 3.5338903298377993 valid 3.585291624069214
EPOCH 259:
  batch 1000 loss: 3.534741080284119
LOSS train 3.534741080284119 valid 3.5843088626861572
EPOCH 260:
  batch 1000 loss: 3.5209595181941986
LOSS train 3.5209595181941986 valid 3.5847535133361816
EPOCH 261:
  batch 1000 loss: 3.5469580928087234
LOSS train 3.5469580928087234 valid 3.585094928741455
EPOCH 262:
  batch 1000 loss: 3.560274789214134
LOSS train 3.560274789214134 valid 3.584749460220337
EPOCH 263:
  batch 1000 loss: 3.54127365732193
LOSS train 3.54127365732193 valid 3.5847601890563965
EPOCH 264:
  batch 1000 loss: 3.561047923088074
Epoch 00264: reducing learning rate of group 0 to 6.1035e-08.
LOSS train 3.561047923088074 valid 3.5853383541107178
EPOCH 265:
  batch 1000 loss: 3.5435792143344877
LOSS train 3.5435792143344877 valid 3.584775447845459
EPOCH 266:
  batch 1000 loss: 3.562805104255676
LOSS train 3.562805104255676 valid 3.584550619125366
EPOCH 267:
  batch 1000 loss: 3.55845549094677
LOSS train 3.55845549094677 valid 3.584433078765869
EPOCH 268:
  batch 1000 loss: 3.538429932832718
LOSS train 3.538429932832718 valid 3.5848605632781982
EPOCH 269:
  batch 1000 loss: 3.551534594774246
LOSS train 3.551534594774246 valid 3.5852184295654297
EPOCH 270:
  batch 1000 loss: 3.5524206211566924
Epoch 00270: reducing learning rate of group 0 to 3.0518e-08.
LOSS train 3.5524206211566924 valid 3.582551956176758
EPOCH 271:
  batch 1000 loss: 3.558517026424408
LOSS train 3.558517026424408 valid 3.5856499671936035
EPOCH 272:
  batch 1000 loss: 3.545172202348709
LOSS train 3.545172202348709 valid 3.5828001499176025
EPOCH 273:
  batch 1000 loss: 3.538706817150116
LOSS train 3.538706817150116 valid 3.5845372676849365
EPOCH 274:
  batch 1000 loss: 3.5471044793128965
LOSS train 3.5471044793128965 valid 3.5823163986206055
EPOCH 275:
  batch 1000 loss: 3.536860290527344
LOSS train 3.536860290527344 valid 3.584822654724121
EPOCH 276:
  batch 1000 loss: 3.5426491525173187
Epoch 00276: reducing learning rate of group 0 to 1.5259e-08.
LOSS train 3.5426491525173187 valid 3.582831382751465
EPOCH 277:
  batch 1000 loss: 3.5426521060466767
LOSS train 3.5426521060466767 valid 3.5847835540771484
EPOCH 278:
  batch 1000 loss: 3.5327832913398742
LOSS train 3.5327832913398742 valid 3.585160970687866
EPOCH 279:
  batch 1000 loss: 3.5365625438690187
LOSS train 3.5365625438690187 valid 3.5846877098083496
EPOCH 280:
  batch 1000 loss: 3.5830398094654083
LOSS train 3.5830398094654083 valid 3.585071563720703
EPOCH 281:
  batch 1000 loss: 3.5338996510505676
LOSS train 3.5338996510505676 valid 3.5831875801086426
EPOCH 282:
  batch 1000 loss: 3.55603633248806
LOSS train 3.55603633248806 valid 3.5859124660491943
EPOCH 283:
  batch 1000 loss: 3.5539684886932372
LOSS train 3.5539684886932372 valid 3.584859609603882
EPOCH 284:
  batch 1000 loss: 3.5427499506473543
LOSS train 3.5427499506473543 valid 3.582916259765625
EPOCH 285:
  batch 1000 loss: 3.5473916685581206
LOSS train 3.5473916685581206 valid 3.585087776184082
EPOCH 286:
  batch 1000 loss: 3.551692740082741
LOSS train 3.551692740082741 valid 3.5849416255950928
EPOCH 287:
  batch 1000 loss: 3.5493800488710403
LOSS train 3.5493800488710403 valid 3.5830509662628174
EPOCH 288:
  batch 1000 loss: 3.5333981692790983
LOSS train 3.5333981692790983 valid 3.584738254547119
EPOCH 289:
  batch 1000 loss: 3.5536914172172547
LOSS train 3.5536914172172547 valid 3.5835018157958984
EPOCH 290:
  batch 1000 loss: 3.5647365612983704
LOSS train 3.5647365612983704 valid 3.585010290145874
EPOCH 291:
  batch 1000 loss: 3.5465932018756865
LOSS train 3.5465932018756865 valid 3.5852885246276855
EPOCH 292:
  batch 1000 loss: 3.547314342021942
LOSS train 3.547314342021942 valid 3.585142135620117
EPOCH 293:
  batch 1000 loss: 3.5440090960264206
LOSS train 3.5440090960264206 valid 3.585202693939209
EPOCH 294:
  batch 1000 loss: 3.5445174053907396
LOSS train 3.5445174053907396 valid 3.5851669311523438
EPOCH 295:
  batch 1000 loss: 3.565111432671547
LOSS train 3.565111432671547 valid 3.5854127407073975
EPOCH 296:
  batch 1000 loss: 3.5674336981773376
LOSS train 3.5674336981773376 valid 3.5843613147735596
EPOCH 297:
  batch 1000 loss: 3.5535847065448762
LOSS train 3.5535847065448762 valid 3.5848140716552734
EPOCH 298:
  batch 1000 loss: 3.5538117604255675
LOSS train 3.5538117604255675 valid 3.5849437713623047
EPOCH 299:
  batch 1000 loss: 3.569897809267044
LOSS train 3.569897809267044 valid 3.583143949508667
EPOCH 300:
  batch 1000 loss: 3.5690159277915954
LOSS train 3.5690159277915954 valid 3.585160732269287
EPOCH 301:
  batch 1000 loss: 3.530673496365547
LOSS train 3.530673496365547 valid 3.582484006881714
EPOCH 302:
  batch 1000 loss: 3.5387059817314146
LOSS train 3.5387059817314146 valid 3.5855801105499268
EPOCH 303:
  batch 1000 loss: 3.537304834127426
LOSS train 3.537304834127426 valid 3.5847580432891846
EPOCH 304:
  batch 1000 loss: 3.525885073900223
LOSS train 3.525885073900223 valid 3.5849742889404297
EPOCH 305:
  batch 1000 loss: 3.5430437598228455
LOSS train 3.5430437598228455 valid 3.584541082382202
EPOCH 306:
  batch 1000 loss: 3.546685166120529
LOSS train 3.546685166120529 valid 3.5848100185394287
EPOCH 307:
  batch 1000 loss: 3.5612008550167085
LOSS train 3.5612008550167085 valid 3.5845420360565186
EPOCH 308:
  batch 1000 loss: 3.5532371562719347
LOSS train 3.5532371562719347 valid 3.584998846054077
EPOCH 309:
  batch 1000 loss: 3.5521069251298902
LOSS train 3.5521069251298902 valid 3.585130453109741
EPOCH 310:
  batch 1000 loss: 3.55430118393898
LOSS train 3.55430118393898 valid 3.584456443786621
EPOCH 311:
  batch 1000 loss: 3.5660736265182496
LOSS train 3.5660736265182496 valid 3.5851950645446777
EPOCH 312:
  batch 1000 loss: 3.5603071535825728
LOSS train 3.5603071535825728 valid 3.5847253799438477
EPOCH 313:
  batch 1000 loss: 3.544770998001099
LOSS train 3.544770998001099 valid 3.5846920013427734
EPOCH 314:
  batch 1000 loss: 3.553030920743942
LOSS train 3.553030920743942 valid 3.585299253463745
EPOCH 315:
  batch 1000 loss: 3.550066132068634
LOSS train 3.550066132068634 valid 3.5850374698638916
EPOCH 316:
  batch 1000 loss: 3.5448374874591826
LOSS train 3.5448374874591826 valid 3.5845329761505127
EPOCH 317:
  batch 1000 loss: 3.5610745463371276
LOSS train 3.5610745463371276 valid 3.5831849575042725
EPOCH 318:
  batch 1000 loss: 3.530968101024628
LOSS train 3.530968101024628 valid 3.5845892429351807
EPOCH 319:
  batch 1000 loss: 3.5435010825395583
LOSS train 3.5435010825395583 valid 3.585592746734619
EPOCH 320:
  batch 1000 loss: 3.5376902148723604
LOSS train 3.5376902148723604 valid 3.5846197605133057
EPOCH 321:
  batch 1000 loss: 3.548263652563095
LOSS train 3.548263652563095 valid 3.584455728530884
EPOCH 322:
  batch 1000 loss: 3.557652207016945
LOSS train 3.557652207016945 valid 3.5844974517822266
EPOCH 323:
  batch 1000 loss: 3.5441601243019103
LOSS train 3.5441601243019103 valid 3.583167552947998
EPOCH 324:
  batch 1000 loss: 3.540742713570595
LOSS train 3.540742713570595 valid 3.583068370819092
EPOCH 325:
  batch 1000 loss: 3.541268156528473
LOSS train 3.541268156528473 valid 3.5826220512390137
EPOCH 326:
  batch 1000 loss: 3.542674250602722
LOSS train 3.542674250602722 valid 3.5827014446258545
EPOCH 327:
  batch 1000 loss: 3.553652668237686
LOSS train 3.553652668237686 valid 3.585157871246338
EPOCH 328:
  batch 1000 loss: 3.5436142089366913
LOSS train 3.5436142089366913 valid 3.5842654705047607
EPOCH 329:
  batch 1000 loss: 3.5457925040721894
LOSS train 3.5457925040721894 valid 3.5845561027526855
EPOCH 330:
  batch 1000 loss: 3.557921352148056
LOSS train 3.557921352148056 valid 3.5851337909698486
EPOCH 331:
  batch 1000 loss: 3.5537049067020416
LOSS train 3.5537049067020416 valid 3.584514856338501
EPOCH 332:
  batch 1000 loss: 3.55573748922348
LOSS train 3.55573748922348 valid 3.585256338119507
EPOCH 333:
  batch 1000 loss: 3.55590903878212
LOSS train 3.55590903878212 valid 3.5826449394226074
EPOCH 334:
  batch 1000 loss: 3.5452512065172197
LOSS train 3.5452512065172197 valid 3.5830671787261963
EPOCH 335:
  batch 1000 loss: 3.557816608786583
LOSS train 3.557816608786583 valid 3.5830628871917725
EPOCH 336:
  batch 1000 loss: 3.5540471976995467
LOSS train 3.5540471976995467 valid 3.5845775604248047
EPOCH 337:
  batch 1000 loss: 3.5472501149177553
LOSS train 3.5472501149177553 valid 3.583012342453003
EPOCH 338:
  batch 1000 loss: 3.546418124437332
LOSS train 3.546418124437332 valid 3.585252523422241
EPOCH 339:
  batch 1000 loss: 3.547605174541473
LOSS train 3.547605174541473 valid 3.5854978561401367
EPOCH 340:
  batch 1000 loss: 3.547571738362312
LOSS train 3.547571738362312 valid 3.5830726623535156
EPOCH 341:
  batch 1000 loss: 3.5607762598991393
LOSS train 3.5607762598991393 valid 3.582566738128662
EPOCH 342:
  batch 1000 loss: 3.563500496029854
LOSS train 3.563500496029854 valid 3.5846927165985107
EPOCH 343:
  batch 1000 loss: 3.558409243822098
LOSS train 3.558409243822098 valid 3.585651397705078
EPOCH 344:
  batch 1000 loss: 3.550813947677612
LOSS train 3.550813947677612 valid 3.5850186347961426
EPOCH 345:
  batch 1000 loss: 3.5635053045749663
LOSS train 3.5635053045749663 valid 3.5831267833709717
EPOCH 346:
  batch 1000 loss: 3.5461249210834502
LOSS train 3.5461249210834502 valid 3.5848731994628906
EPOCH 347:
  batch 1000 loss: 3.5373108024597166
LOSS train 3.5373108024597166 valid 3.5849978923797607
EPOCH 348:
  batch 1000 loss: 3.5465304358005523
LOSS train 3.5465304358005523 valid 3.585381031036377
EPOCH 349:
  batch 1000 loss: 3.561000989675522
LOSS train 3.561000989675522 valid 3.5844876766204834
EPOCH 350:
  batch 1000 loss: 3.5539032635688783
LOSS train 3.5539032635688783 valid 3.5849838256835938
EPOCH 351:
  batch 1000 loss: 3.5655757584571837
LOSS train 3.5655757584571837 valid 3.58535099029541
EPOCH 352:
  batch 1000 loss: 3.5874838967323304
LOSS train 3.5874838967323304 valid 3.5846798419952393
EPOCH 353:
  batch 1000 loss: 3.5368425513505937
LOSS train 3.5368425513505937 valid 3.5851800441741943
EPOCH 354:
  batch 1000 loss: 3.543245652079582
LOSS train 3.543245652079582 valid 3.5845513343811035
EPOCH 355:
  batch 1000 loss: 3.5424392161369322
LOSS train 3.5424392161369322 valid 3.582857608795166
EPOCH 356:
  batch 1000 loss: 3.560423300027847
LOSS train 3.560423300027847 valid 3.585434913635254
EPOCH 357:
  batch 1000 loss: 3.55986430311203
LOSS train 3.55986430311203 valid 3.5850181579589844
EPOCH 358:
  batch 1000 loss: 3.5398273475170137
LOSS train 3.5398273475170137 valid 3.5848636627197266
EPOCH 359:
  batch 1000 loss: 3.545326222062111
LOSS train 3.545326222062111 valid 3.5852415561676025
EPOCH 360:
  batch 1000 loss: 3.54055898809433
LOSS train 3.54055898809433 valid 3.5850701332092285
EPOCH 361:
  batch 1000 loss: 3.526495422840118
LOSS train 3.526495422840118 valid 3.5854644775390625
EPOCH 362:
  batch 1000 loss: 3.5462684586048128
LOSS train 3.5462684586048128 valid 3.584989309310913
EPOCH 363:
  batch 1000 loss: 3.5568211715221407
LOSS train 3.5568211715221407 valid 3.5855164527893066
EPOCH 364:
  batch 1000 loss: 3.5536836886405947
LOSS train 3.5536836886405947 valid 3.585134267807007
EPOCH 365:
  batch 1000 loss: 3.549088236808777
LOSS train 3.549088236808777 valid 3.583089590072632
EPOCH 366:
  batch 1000 loss: 3.5622504301071167
LOSS train 3.5622504301071167 valid 3.584667205810547
EPOCH 367:
  batch 1000 loss: 3.5351017323732377
LOSS train 3.5351017323732377 valid 3.58497953414917
EPOCH 368:
  batch 1000 loss: 3.5629890077114106
LOSS train 3.5629890077114106 valid 3.5846800804138184
EPOCH 369:
  batch 1000 loss: 3.5501392060518264
LOSS train 3.5501392060518264 valid 3.584547996520996
EPOCH 370:
  batch 1000 loss: 3.5658406720161437
LOSS train 3.5658406720161437 valid 3.5848069190979004
EPOCH 371:
  batch 1000 loss: 3.5474089510440825
LOSS train 3.5474089510440825 valid 3.584792375564575
EPOCH 372:
  batch 1000 loss: 3.5523057676553726
LOSS train 3.5523057676553726 valid 3.584718704223633
EPOCH 373:
  batch 1000 loss: 3.5499709341526033
LOSS train 3.5499709341526033 valid 3.5856409072875977
EPOCH 374:
  batch 1000 loss: 3.5442376198768617
LOSS train 3.5442376198768617 valid 3.5849156379699707
EPOCH 375:
  batch 1000 loss: 3.5307371385097506
LOSS train 3.5307371385097506 valid 3.5843935012817383
EPOCH 376:
  batch 1000 loss: 3.553091217160225
LOSS train 3.553091217160225 valid 3.5827651023864746
EPOCH 377:
  batch 1000 loss: 3.542188937187195
LOSS train 3.542188937187195 valid 3.584368944168091
EPOCH 378:
  batch 1000 loss: 3.5437357794046402
LOSS train 3.5437357794046402 valid 3.585031270980835
EPOCH 379:
  batch 1000 loss: 3.564206578016281
LOSS train 3.564206578016281 valid 3.5823402404785156
EPOCH 380:
  batch 1000 loss: 3.5502555660009385
LOSS train 3.5502555660009385 valid 3.5846545696258545
EPOCH 381:
  batch 1000 loss: 3.5514502135515214
LOSS train 3.5514502135515214 valid 3.584881067276001
EPOCH 382:
  batch 1000 loss: 3.541177630662918
LOSS train 3.541177630662918 valid 3.5851569175720215
EPOCH 383:
  batch 1000 loss: 3.550257109642029
LOSS train 3.550257109642029 valid 3.584963321685791
EPOCH 384:
  batch 1000 loss: 3.543228717803955
LOSS train 3.543228717803955 valid 3.582789897918701
EPOCH 385:
  batch 1000 loss: 3.545701375246048
LOSS train 3.545701375246048 valid 3.585660934448242
EPOCH 386:
  batch 1000 loss: 3.5637369626760482
LOSS train 3.5637369626760482 valid 3.583648681640625
EPOCH 387:
  batch 1000 loss: 3.546490010380745
LOSS train 3.546490010380745 valid 3.584699869155884
EPOCH 388:
  batch 1000 loss: 3.5548087553977967
LOSS train 3.5548087553977967 valid 3.585665464401245
EPOCH 389:
  batch 1000 loss: 3.5456554963588713
LOSS train 3.5456554963588713 valid 3.585813522338867
EPOCH 390:
  batch 1000 loss: 3.557747767686844
LOSS train 3.557747767686844 valid 3.585156202316284
EPOCH 391:
  batch 1000 loss: 3.5254056527614592
LOSS train 3.5254056527614592 valid 3.584778070449829
EPOCH 392:
  batch 1000 loss: 3.536945005893707
LOSS train 3.536945005893707 valid 3.5848920345306396
EPOCH 393:
  batch 1000 loss: 3.5614279276132583
LOSS train 3.5614279276132583 valid 3.5849125385284424
EPOCH 394:
  batch 1000 loss: 3.545998599052429
LOSS train 3.545998599052429 valid 3.582547426223755
EPOCH 395:
  batch 1000 loss: 3.544703424692154
LOSS train 3.544703424692154 valid 3.5851340293884277
EPOCH 396:
  batch 1000 loss: 3.5543067502975463
LOSS train 3.5543067502975463 valid 3.584756851196289
EPOCH 397:
  batch 1000 loss: 3.542726381778717
LOSS train 3.542726381778717 valid 3.585029125213623
EPOCH 398:
  batch 1000 loss: 3.553637404799461
LOSS train 3.553637404799461 valid 3.5852203369140625
EPOCH 399:
  batch 1000 loss: 3.549265728712082
LOSS train 3.549265728712082 valid 3.5847482681274414
EPOCH 400:
  batch 1000 loss: 3.5533923413753508
LOSS train 3.5533923413753508 valid 3.5846669673919678
EPOCH 401:
  batch 1000 loss: 3.549141075134277
LOSS train 3.549141075134277 valid 3.585156202316284
EPOCH 402:
  batch 1000 loss: 3.5532973939180375
LOSS train 3.5532973939180375 valid 3.5851950645446777
EPOCH 403:
  batch 1000 loss: 3.5600710361003878
LOSS train 3.5600710361003878 valid 3.582444190979004
EPOCH 404:
  batch 1000 loss: 3.5352311260700224
LOSS train 3.5352311260700224 valid 3.5830020904541016
EPOCH 405:
  batch 1000 loss: 3.5519987037181853
LOSS train 3.5519987037181853 valid 3.584825277328491
EPOCH 406:
  batch 1000 loss: 3.525766379952431
LOSS train 3.525766379952431 valid 3.583102226257324
EPOCH 407:
  batch 1000 loss: 3.5339011880159377
LOSS train 3.5339011880159377 valid 3.584735631942749
EPOCH 408:
  batch 1000 loss: 3.553639506816864
LOSS train 3.553639506816864 valid 3.58563494682312
EPOCH 409:
  batch 1000 loss: 3.5504721145629885
LOSS train 3.5504721145629885 valid 3.584772825241089
EPOCH 410:
  batch 1000 loss: 3.5475438418388365
LOSS train 3.5475438418388365 valid 3.5852842330932617
EPOCH 411:
  batch 1000 loss: 3.558281368494034
LOSS train 3.558281368494034 valid 3.584778308868408
EPOCH 412:
  batch 1000 loss: 3.5643086183071135
LOSS train 3.5643086183071135 valid 3.584332227706909
EPOCH 413:
  batch 1000 loss: 3.5505857162475585
LOSS train 3.5505857162475585 valid 3.5824828147888184
EPOCH 414:
  batch 1000 loss: 3.559777855038643
LOSS train 3.559777855038643 valid 3.585193157196045
EPOCH 415:
  batch 1000 loss: 3.5480518733263016
LOSS train 3.5480518733263016 valid 3.5858025550842285
EPOCH 416:
  batch 1000 loss: 3.558711171388626
LOSS train 3.558711171388626 valid 3.5843605995178223
EPOCH 417:
  batch 1000 loss: 3.562090801239014
LOSS train 3.562090801239014 valid 3.585174083709717
EPOCH 418:
  batch 1000 loss: 3.545275869131088
LOSS train 3.545275869131088 valid 3.584805727005005
EPOCH 419:
  batch 1000 loss: 3.5621952147483826
LOSS train 3.5621952147483826 valid 3.5828170776367188
EPOCH 420:
  batch 1000 loss: 3.5363816845417024
LOSS train 3.5363816845417024 valid 3.584432363510132
EPOCH 421:
  batch 1000 loss: 3.538909432411194
LOSS train 3.538909432411194 valid 3.5844781398773193
EPOCH 422:
  batch 1000 loss: 3.5715169072151185
LOSS train 3.5715169072151185 valid 3.583223819732666
EPOCH 423:
  batch 1000 loss: 3.5472236654758453
LOSS train 3.5472236654758453 valid 3.5852622985839844
EPOCH 424:
  batch 1000 loss: 3.5528350496292114
LOSS train 3.5528350496292114 valid 3.5851025581359863
EPOCH 425:
  batch 1000 loss: 3.540249664902687
LOSS train 3.540249664902687 valid 3.58278226852417
EPOCH 426:
  batch 1000 loss: 3.5375389238595965
LOSS train 3.5375389238595965 valid 3.5828440189361572
EPOCH 427:
  batch 1000 loss: 3.548725862264633
LOSS train 3.548725862264633 valid 3.5824718475341797
EPOCH 428:
  batch 1000 loss: 3.55064011824131
LOSS train 3.55064011824131 valid 3.5847084522247314
EPOCH 429:
  batch 1000 loss: 3.549969284415245
LOSS train 3.549969284415245 valid 3.585416555404663
EPOCH 430:
  batch 1000 loss: 3.552632398366928
LOSS train 3.552632398366928 valid 3.5826916694641113
EPOCH 431:
  batch 1000 loss: 3.5407258695364
LOSS train 3.5407258695364 valid 3.584683656692505
EPOCH 432:
  batch 1000 loss: 3.5642867794036865
LOSS train 3.5642867794036865 valid 3.5846521854400635
EPOCH 433:
  batch 1000 loss: 3.5587562804222106
LOSS train 3.5587562804222106 valid 3.5826146602630615
EPOCH 434:
  batch 1000 loss: 3.5562600079774858
LOSS train 3.5562600079774858 valid 3.5847158432006836
EPOCH 435:
  batch 1000 loss: 3.5456213755607604
LOSS train 3.5456213755607604 valid 3.5824644565582275
EPOCH 436:
  batch 1000 loss: 3.54708340549469
LOSS train 3.54708340549469 valid 3.585005283355713
EPOCH 437:
  batch 1000 loss: 3.55454246032238
LOSS train 3.55454246032238 valid 3.5848987102508545
EPOCH 438:
  batch 1000 loss: 3.557730789899826
LOSS train 3.557730789899826 valid 3.5851633548736572
EPOCH 439:
  batch 1000 loss: 3.548503481864929
LOSS train 3.548503481864929 valid 3.585254669189453
EPOCH 440:
  batch 1000 loss: 3.548392266750336
LOSS train 3.548392266750336 valid 3.585153579711914
EPOCH 441:
  batch 1000 loss: 3.550331235527992
LOSS train 3.550331235527992 valid 3.585904836654663
EPOCH 442:
  batch 1000 loss: 3.5457046645879746
LOSS train 3.5457046645879746 valid 3.584778308868408
EPOCH 443:
  batch 1000 loss: 3.5340447068214416
LOSS train 3.5340447068214416 valid 3.5844783782958984
EPOCH 444:
  batch 1000 loss: 3.5522113367319106
LOSS train 3.5522113367319106 valid 3.5852465629577637
EPOCH 445:
  batch 1000 loss: 3.552155210733414
LOSS train 3.552155210733414 valid 3.5828983783721924
EPOCH 446:
  batch 1000 loss: 3.5480490958690645
LOSS train 3.5480490958690645 valid 3.5852913856506348
EPOCH 447:
  batch 1000 loss: 3.562911105155945
LOSS train 3.562911105155945 valid 3.5842223167419434
EPOCH 448:
  batch 1000 loss: 3.551126425743103
LOSS train 3.551126425743103 valid 3.5848348140716553
EPOCH 449:
  batch 1000 loss: 3.56281666970253
LOSS train 3.56281666970253 valid 3.5841634273529053
EPOCH 450:
  batch 1000 loss: 3.5644509353637694
LOSS train 3.5644509353637694 valid 3.584482431411743
EPOCH 451:
  batch 1000 loss: 3.5405117540359496
LOSS train 3.5405117540359496 valid 3.585167407989502
EPOCH 452:
  batch 1000 loss: 3.5492774255275727
LOSS train 3.5492774255275727 valid 3.5837275981903076
EPOCH 453:
  batch 1000 loss: 3.562311057686806
LOSS train 3.562311057686806 valid 3.5831642150878906
EPOCH 454:
  batch 1000 loss: 3.554464301943779
LOSS train 3.554464301943779 valid 3.5850777626037598
EPOCH 455:
  batch 1000 loss: 3.5381369963884355
LOSS train 3.5381369963884355 valid 3.5845742225646973
EPOCH 456:
  batch 1000 loss: 3.5573392279148104
LOSS train 3.5573392279148104 valid 3.585270881652832
EPOCH 457:
  batch 1000 loss: 3.5482236790657042
LOSS train 3.5482236790657042 valid 3.584416627883911
EPOCH 458:
  batch 1000 loss: 3.5596180136203768
LOSS train 3.5596180136203768 valid 3.5852720737457275
EPOCH 459:
  batch 1000 loss: 3.544812354564667
LOSS train 3.544812354564667 valid 3.5860214233398438
EPOCH 460:
  batch 1000 loss: 3.548241951584816
LOSS train 3.548241951584816 valid 3.5826900005340576
EPOCH 461:
  batch 1000 loss: 3.533989311814308
LOSS train 3.533989311814308 valid 3.5849082469940186
EPOCH 462:
  batch 1000 loss: 3.5425285785198213
LOSS train 3.5425285785198213 valid 3.584486961364746
EPOCH 463:
  batch 1000 loss: 3.5458866782188414
LOSS train 3.5458866782188414 valid 3.585202693939209
EPOCH 464:
  batch 1000 loss: 3.542378841638565
LOSS train 3.542378841638565 valid 3.5852243900299072
EPOCH 465:
  batch 1000 loss: 3.553730197429657
LOSS train 3.553730197429657 valid 3.5851337909698486
EPOCH 466:
  batch 1000 loss: 3.5406800466775894
LOSS train 3.5406800466775894 valid 3.584965229034424
EPOCH 467:
  batch 1000 loss: 3.570318035364151
LOSS train 3.570318035364151 valid 3.584772825241089
EPOCH 468:
  batch 1000 loss: 3.558785905838013
LOSS train 3.558785905838013 valid 3.584798812866211
EPOCH 469:
  batch 1000 loss: 3.5553924561738968
LOSS train 3.5553924561738968 valid 3.5852019786834717
EPOCH 470:
  batch 1000 loss: 3.5488147258758547
LOSS train 3.5488147258758547 valid 3.584294557571411
EPOCH 471:
  batch 1000 loss: 3.540047010064125
LOSS train 3.540047010064125 valid 3.584690570831299
EPOCH 472:
  batch 1000 loss: 3.5543957926034926
LOSS train 3.5543957926034926 valid 3.5848066806793213
EPOCH 473:
  batch 1000 loss: 3.5427127500772477
LOSS train 3.5427127500772477 valid 3.5849411487579346
EPOCH 474:
  batch 1000 loss: 3.5440523790121077
LOSS train 3.5440523790121077 valid 3.5852205753326416
EPOCH 475:
  batch 1000 loss: 3.5535762877464294
LOSS train 3.5535762877464294 valid 3.584458589553833
EPOCH 476:
  batch 1000 loss: 3.545672982931137
LOSS train 3.545672982931137 valid 3.584643602371216
EPOCH 477:
  batch 1000 loss: 3.5438819687366485
LOSS train 3.5438819687366485 valid 3.5845437049865723
EPOCH 478:
  batch 1000 loss: 3.552026867866516
LOSS train 3.552026867866516 valid 3.584747314453125
EPOCH 479:
  batch 1000 loss: 3.562223989009857
LOSS train 3.562223989009857 valid 3.584739923477173
EPOCH 480:
  batch 1000 loss: 3.5486289172172545
LOSS train 3.5486289172172545 valid 3.582620859146118
EPOCH 481:
  batch 1000 loss: 3.542875317335129
LOSS train 3.542875317335129 valid 3.5846664905548096
EPOCH 482:
  batch 1000 loss: 3.543407361626625
LOSS train 3.543407361626625 valid 3.585268497467041
EPOCH 483:
  batch 1000 loss: 3.557237273097038
LOSS train 3.557237273097038 valid 3.5845282077789307
EPOCH 484:
  batch 1000 loss: 3.5500521367788314
LOSS train 3.5500521367788314 valid 3.5846426486968994
EPOCH 485:
  batch 1000 loss: 3.5288276971578596
LOSS train 3.5288276971578596 valid 3.582427740097046
EPOCH 486:
  batch 1000 loss: 3.546426867723465
LOSS train 3.546426867723465 valid 3.584742784500122
EPOCH 487:
  batch 1000 loss: 3.541309564590454
LOSS train 3.541309564590454 valid 3.585517406463623
EPOCH 488:
  batch 1000 loss: 3.5415576974153518
LOSS train 3.5415576974153518 valid 3.5825419425964355
EPOCH 489:
  batch 1000 loss: 3.5417241933345793
LOSS train 3.5417241933345793 valid 3.5854885578155518
EPOCH 490:
  batch 1000 loss: 3.5556692280769346
LOSS train 3.5556692280769346 valid 3.584918737411499
EPOCH 491:
  batch 1000 loss: 3.5604461134672163
LOSS train 3.5604461134672163 valid 3.584786891937256
EPOCH 492:
  batch 1000 loss: 3.5586980364322662
LOSS train 3.5586980364322662 valid 3.584718704223633
EPOCH 493:
  batch 1000 loss: 3.5494667189121247
LOSS train 3.5494667189121247 valid 3.5858242511749268
EPOCH 494:
  batch 1000 loss: 3.535050100684166
LOSS train 3.535050100684166 valid 3.5846290588378906
EPOCH 495:
  batch 1000 loss: 3.5495162284374238
LOSS train 3.5495162284374238 valid 3.584545135498047
EPOCH 496:
  batch 1000 loss: 3.547984772443771
LOSS train 3.547984772443771 valid 3.584700584411621
EPOCH 497:
  batch 1000 loss: 3.576127872943878
LOSS train 3.576127872943878 valid 3.5849876403808594
EPOCH 498:
  batch 1000 loss: 3.54800887799263
LOSS train 3.54800887799263 valid 3.5852439403533936
EPOCH 499:
  batch 1000 loss: 3.5622836483716966
LOSS train 3.5622836483716966 valid 3.5846920013427734
EPOCH 500:
  batch 1000 loss: 3.543574541091919
LOSS train 3.543574541091919 valid 3.5854527950286865
