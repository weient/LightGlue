nohup: ignoring input
EPOCH 1:
  batch 1000 loss: 8.84120197200775
LOSS train 8.84120197200775 valid 6.935505390167236
EPOCH 2:
  batch 1000 loss: 6.443386277914048
LOSS train 6.443386277914048 valid 5.806211471557617
EPOCH 3:
  batch 1000 loss: 5.807527281522751
LOSS train 5.807527281522751 valid 5.711485862731934
EPOCH 4:
  batch 1000 loss: 5.431244907855987
LOSS train 5.431244907855987 valid 6.079891681671143
EPOCH 5:
  batch 1000 loss: 5.377629573345184
LOSS train 5.377629573345184 valid 5.101670265197754
EPOCH 6:
  batch 1000 loss: 5.013123718976974
LOSS train 5.013123718976974 valid 4.833468914031982
EPOCH 7:
  batch 1000 loss: 4.830105768203735
LOSS train 4.830105768203735 valid 4.898090362548828
EPOCH 8:
  batch 1000 loss: 4.616302665233612
LOSS train 4.616302665233612 valid 4.659685134887695
EPOCH 9:
  batch 1000 loss: 4.404661571264267
LOSS train 4.404661571264267 valid 4.3697428703308105
EPOCH 10:
  batch 1000 loss: 4.26159445977211
LOSS train 4.26159445977211 valid 4.300982475280762
EPOCH 11:
  batch 1000 loss: 4.2000364427566526
LOSS train 4.2000364427566526 valid 4.183950901031494
EPOCH 12:
  batch 1000 loss: 4.1561642467975615
LOSS train 4.1561642467975615 valid 4.164693355560303
EPOCH 13:
  batch 1000 loss: 4.097220158338547
LOSS train 4.097220158338547 valid 4.557070732116699
EPOCH 14:
  batch 1000 loss: 4.052467492341996
LOSS train 4.052467492341996 valid 4.091058731079102
EPOCH 15:
  batch 1000 loss: 3.9884052658081055
LOSS train 3.9884052658081055 valid 4.029090881347656
EPOCH 16:
  batch 1000 loss: 4.07568834233284
LOSS train 4.07568834233284 valid 3.994730234146118
EPOCH 17:
  batch 1000 loss: 3.992945271253586
LOSS train 3.992945271253586 valid 3.926281452178955
EPOCH 18:
  batch 1000 loss: 3.9385976097583772
LOSS train 3.9385976097583772 valid 4.036025524139404
EPOCH 19:
  batch 1000 loss: 3.9095250089168547
LOSS train 3.9095250089168547 valid 3.933354377746582
EPOCH 20:
  batch 1000 loss: 3.9262255740165712
LOSS train 3.9262255740165712 valid 3.932502031326294
EPOCH 21:
  batch 1000 loss: 3.944787933111191
LOSS train 3.944787933111191 valid 3.904649496078491
EPOCH 22:
  batch 1000 loss: 3.9311707696914673
LOSS train 3.9311707696914673 valid 4.139057159423828
EPOCH 23:
  batch 1000 loss: 3.90489999961853
LOSS train 3.90489999961853 valid 3.931226968765259
EPOCH 24:
  batch 1000 loss: 3.889315655231476
LOSS train 3.889315655231476 valid 4.096909523010254
EPOCH 25:
  batch 1000 loss: 3.8275687506198883
LOSS train 3.8275687506198883 valid 3.8919918537139893
EPOCH 26:
  batch 1000 loss: 3.83504634976387
LOSS train 3.83504634976387 valid 3.894835948944092
EPOCH 27:
  batch 1000 loss: 3.8044790625572205
LOSS train 3.8044790625572205 valid 3.9405064582824707
EPOCH 28:
  batch 1000 loss: 3.8080223948955534
LOSS train 3.8080223948955534 valid 3.9228622913360596
EPOCH 29:
  batch 1000 loss: 3.8017116458415985
LOSS train 3.8017116458415985 valid 3.9489920139312744
EPOCH 30:
  batch 1000 loss: 3.783748921394348
LOSS train 3.783748921394348 valid 3.7876312732696533
EPOCH 31:
  batch 1000 loss: 3.7678828089237215
LOSS train 3.7678828089237215 valid 3.852285146713257
EPOCH 32:
  batch 1000 loss: 3.795227913856506
LOSS train 3.795227913856506 valid 3.924060821533203
EPOCH 33:
  batch 1000 loss: 3.8079179847240447
LOSS train 3.8079179847240447 valid 4.059639930725098
EPOCH 34:
  batch 1000 loss: 3.835663644552231
LOSS train 3.835663644552231 valid 3.7946279048919678
EPOCH 35:
  batch 1000 loss: 3.7606736607551574
LOSS train 3.7606736607551574 valid 3.858377695083618
EPOCH 36:
  batch 1000 loss: 3.775666064500809
Epoch 00036: reducing learning rate of group 0 to 5.0000e-04.
LOSS train 3.775666064500809 valid 3.924783229827881
EPOCH 37:
  batch 1000 loss: 3.7258530139923094
LOSS train 3.7258530139923094 valid 3.7276203632354736
EPOCH 38:
  batch 1000 loss: 3.6755373108386995
LOSS train 3.6755373108386995 valid 3.734816789627075
EPOCH 39:
  batch 1000 loss: 3.705525580406189
LOSS train 3.705525580406189 valid 3.7206501960754395
EPOCH 40:
  batch 1000 loss: 3.6973345596790312
LOSS train 3.6973345596790312 valid 3.721273899078369
EPOCH 41:
  batch 1000 loss: 3.6789909207820894
LOSS train 3.6789909207820894 valid 3.7120213508605957
EPOCH 42:
  batch 1000 loss: 3.669875556707382
LOSS train 3.669875556707382 valid 3.7227511405944824
EPOCH 43:
  batch 1000 loss: 3.691606001853943
LOSS train 3.691606001853943 valid 3.74660062789917
EPOCH 44:
  batch 1000 loss: 3.663379104375839
LOSS train 3.663379104375839 valid 3.724665880203247
EPOCH 45:
  batch 1000 loss: 3.675028132200241
LOSS train 3.675028132200241 valid 3.7099709510803223
EPOCH 46:
  batch 1000 loss: 3.6967759175300596
LOSS train 3.6967759175300596 valid 3.714555263519287
EPOCH 47:
  batch 1000 loss: 3.6520825908184054
LOSS train 3.6520825908184054 valid 3.71924090385437
EPOCH 48:
  batch 1000 loss: 3.668308756828308
LOSS train 3.668308756828308 valid 3.6848623752593994
EPOCH 49:
  batch 1000 loss: 3.6816585385799407
LOSS train 3.6816585385799407 valid 3.6876275539398193
EPOCH 50:
  batch 1000 loss: 3.650320570707321
LOSS train 3.650320570707321 valid 3.7092125415802
EPOCH 51:
  batch 1000 loss: 3.645649634361267
LOSS train 3.645649634361267 valid 3.68188738822937
EPOCH 52:
  batch 1000 loss: 3.6771897139549257
LOSS train 3.6771897139549257 valid 3.686479091644287
EPOCH 53:
  batch 1000 loss: 3.656047981262207
LOSS train 3.656047981262207 valid 3.6765568256378174
EPOCH 54:
  batch 1000 loss: 3.6390158586502075
LOSS train 3.6390158586502075 valid 3.6953442096710205
EPOCH 55:
  batch 1000 loss: 3.6279187552928924
LOSS train 3.6279187552928924 valid 3.6708993911743164
EPOCH 56:
  batch 1000 loss: 3.60119939994812
LOSS train 3.60119939994812 valid 3.677556037902832
EPOCH 57:
  batch 1000 loss: 3.635171737194061
LOSS train 3.635171737194061 valid 3.6657543182373047
EPOCH 58:
  batch 1000 loss: 3.602375766038895
LOSS train 3.602375766038895 valid 3.683881998062134
EPOCH 59:
  batch 1000 loss: 3.6157386934757234
LOSS train 3.6157386934757234 valid 3.668335437774658
EPOCH 60:
  batch 1000 loss: 3.628727206707001
LOSS train 3.628727206707001 valid 3.6993229389190674
EPOCH 61:
  batch 1000 loss: 3.6267192680835723
LOSS train 3.6267192680835723 valid 3.6962339878082275
EPOCH 62:
  batch 1000 loss: 3.624322087287903
LOSS train 3.624322087287903 valid 3.677462577819824
EPOCH 63:
  batch 1000 loss: 3.6184252994060517
LOSS train 3.6184252994060517 valid 3.660526752471924
EPOCH 64:
  batch 1000 loss: 3.6139654269218444
LOSS train 3.6139654269218444 valid 3.6619668006896973
EPOCH 65:
  batch 1000 loss: 3.623590368747711
LOSS train 3.623590368747711 valid 3.660369873046875
EPOCH 66:
  batch 1000 loss: 3.6455129327774047
LOSS train 3.6455129327774047 valid 3.6481754779815674
EPOCH 67:
  batch 1000 loss: 3.6094139511585235
LOSS train 3.6094139511585235 valid 3.657236099243164
EPOCH 68:
  batch 1000 loss: 3.6018562281131743
LOSS train 3.6018562281131743 valid 3.6677892208099365
EPOCH 69:
  batch 1000 loss: 3.577841767549515
LOSS train 3.577841767549515 valid 3.66218638420105
EPOCH 70:
  batch 1000 loss: 3.6236865487098693
LOSS train 3.6236865487098693 valid 3.6402103900909424
EPOCH 71:
  batch 1000 loss: 3.6095470421314237
LOSS train 3.6095470421314237 valid 3.6445586681365967
EPOCH 72:
  batch 1000 loss: 3.617422371864319
LOSS train 3.617422371864319 valid 3.7713937759399414
EPOCH 73:
  batch 1000 loss: 3.584779505252838
LOSS train 3.584779505252838 valid 3.6763386726379395
EPOCH 74:
  batch 1000 loss: 3.6247123453617096
LOSS train 3.6247123453617096 valid 3.635488748550415
EPOCH 75:
  batch 1000 loss: 3.61144474029541
LOSS train 3.61144474029541 valid 3.661259651184082
EPOCH 76:
  batch 1000 loss: 3.599222306251526
LOSS train 3.599222306251526 valid 3.637852907180786
EPOCH 77:
  batch 1000 loss: 3.5922745289802553
LOSS train 3.5922745289802553 valid 3.6536195278167725
EPOCH 78:
  batch 1000 loss: 3.5824130628108977
LOSS train 3.5824130628108977 valid 3.639559268951416
EPOCH 79:
  batch 1000 loss: 3.5889304864406584
LOSS train 3.5889304864406584 valid 3.647895097732544
EPOCH 80:
  batch 1000 loss: 3.5984572002887725
Epoch 00080: reducing learning rate of group 0 to 2.5000e-04.
LOSS train 3.5984572002887725 valid 3.6467554569244385
EPOCH 81:
  batch 1000 loss: 3.564577480792999
LOSS train 3.564577480792999 valid 3.6078195571899414
EPOCH 82:
  batch 1000 loss: 3.5733996443748475
LOSS train 3.5733996443748475 valid 3.604051351547241
EPOCH 83:
  batch 1000 loss: 3.538200227022171
LOSS train 3.538200227022171 valid 3.6112334728240967
EPOCH 84:
  batch 1000 loss: 3.5774871520996094
LOSS train 3.5774871520996094 valid 3.6137897968292236
EPOCH 85:
  batch 1000 loss: 3.5461922018527985
LOSS train 3.5461922018527985 valid 3.6015729904174805
EPOCH 86:
  batch 1000 loss: 3.560527287244797
LOSS train 3.560527287244797 valid 3.6137850284576416
EPOCH 87:
  batch 1000 loss: 3.5601709632873537
LOSS train 3.5601709632873537 valid 3.6083693504333496
EPOCH 88:
  batch 1000 loss: 3.5429162232875826
LOSS train 3.5429162232875826 valid 3.6026899814605713
EPOCH 89:
  batch 1000 loss: 3.539300410747528
LOSS train 3.539300410747528 valid 3.604093551635742
EPOCH 90:
  batch 1000 loss: 3.536413683652878
LOSS train 3.536413683652878 valid 3.6988301277160645
EPOCH 91:
  batch 1000 loss: 3.5691370623111727
LOSS train 3.5691370623111727 valid 3.600393056869507
EPOCH 92:
  batch 1000 loss: 3.5537091262340548
LOSS train 3.5537091262340548 valid 3.6010260581970215
EPOCH 93:
  batch 1000 loss: 3.536382602453232
LOSS train 3.536382602453232 valid 3.5970590114593506
EPOCH 94:
  batch 1000 loss: 3.5615914959907533
LOSS train 3.5615914959907533 valid 3.6018781661987305
EPOCH 95:
  batch 1000 loss: 3.5593051335811614
LOSS train 3.5593051335811614 valid 3.618656635284424
EPOCH 96:
  batch 1000 loss: 3.543267698287964
LOSS train 3.543267698287964 valid 3.6054577827453613
EPOCH 97:
  batch 1000 loss: 3.544089243173599
LOSS train 3.544089243173599 valid 3.5959064960479736
EPOCH 98:
  batch 1000 loss: 3.5673597123622893
LOSS train 3.5673597123622893 valid 3.596673011779785
EPOCH 99:
  batch 1000 loss: 3.54467160153389
LOSS train 3.54467160153389 valid 3.602102756500244
EPOCH 100:
  batch 1000 loss: 3.565473040819168
LOSS train 3.565473040819168 valid 3.648829936981201
EPOCH 101:
  batch 1000 loss: 3.556147791147232
LOSS train 3.556147791147232 valid 3.590456247329712
EPOCH 102:
  batch 1000 loss: 3.5504311602115632
LOSS train 3.5504311602115632 valid 3.5993988513946533
EPOCH 103:
  batch 1000 loss: 3.5391824429035186
LOSS train 3.5391824429035186 valid 3.614642858505249
EPOCH 104:
  batch 1000 loss: 3.5574778048992157
LOSS train 3.5574778048992157 valid 3.61094331741333
EPOCH 105:
  batch 1000 loss: 3.55023032283783
LOSS train 3.55023032283783 valid 3.5973010063171387
EPOCH 106:
  batch 1000 loss: 3.526777960062027
LOSS train 3.526777960062027 valid 3.5956387519836426
EPOCH 107:
  batch 1000 loss: 3.522488624095917
Epoch 00107: reducing learning rate of group 0 to 1.2500e-04.
LOSS train 3.522488624095917 valid 3.5949673652648926
EPOCH 108:
  batch 1000 loss: 3.5382579729557038
LOSS train 3.5382579729557038 valid 3.572808265686035
EPOCH 109:
  batch 1000 loss: 3.528472026348114
LOSS train 3.528472026348114 valid 3.5719833374023438
EPOCH 110:
  batch 1000 loss: 3.5241694197654723
LOSS train 3.5241694197654723 valid 3.575313091278076
EPOCH 111:
  batch 1000 loss: 3.500177439689636
LOSS train 3.500177439689636 valid 3.5798091888427734
EPOCH 112:
  batch 1000 loss: 3.528303386211395
LOSS train 3.528303386211395 valid 3.5719730854034424
EPOCH 113:
  batch 1000 loss: 3.5460540895462036
LOSS train 3.5460540895462036 valid 3.577401638031006
EPOCH 114:
  batch 1000 loss: 3.5204192128181457
LOSS train 3.5204192128181457 valid 3.5731558799743652
EPOCH 115:
  batch 1000 loss: 3.529236773014069
LOSS train 3.529236773014069 valid 3.5677876472473145
EPOCH 116:
  batch 1000 loss: 3.5328821775913237
LOSS train 3.5328821775913237 valid 3.5675506591796875
EPOCH 117:
  batch 1000 loss: 3.5184845654964447
LOSS train 3.5184845654964447 valid 3.56716251373291
EPOCH 118:
  batch 1000 loss: 3.522923805952072
LOSS train 3.522923805952072 valid 3.5678787231445312
EPOCH 119:
  batch 1000 loss: 3.511241669893265
LOSS train 3.511241669893265 valid 3.569030523300171
EPOCH 120:
  batch 1000 loss: 3.503399398088455
LOSS train 3.503399398088455 valid 3.5665416717529297
EPOCH 121:
  batch 1000 loss: 3.5226908655166627
LOSS train 3.5226908655166627 valid 3.5702998638153076
EPOCH 122:
  batch 1000 loss: 3.5124374101161955
LOSS train 3.5124374101161955 valid 3.57216739654541
EPOCH 123:
  batch 1000 loss: 3.5084310493469237
LOSS train 3.5084310493469237 valid 3.563767433166504
EPOCH 124:
  batch 1000 loss: 3.5077523205280303
LOSS train 3.5077523205280303 valid 3.5654067993164062
EPOCH 125:
  batch 1000 loss: 3.5198735957145693
LOSS train 3.5198735957145693 valid 3.5627055168151855
EPOCH 126:
  batch 1000 loss: 3.53203632235527
LOSS train 3.53203632235527 valid 3.567833423614502
EPOCH 127:
  batch 1000 loss: 3.500755471944809
LOSS train 3.500755471944809 valid 3.5671238899230957
EPOCH 128:
  batch 1000 loss: 3.5167642798423766
LOSS train 3.5167642798423766 valid 3.565507650375366
EPOCH 129:
  batch 1000 loss: 3.5261634011268614
LOSS train 3.5261634011268614 valid 3.566216468811035
EPOCH 130:
  batch 1000 loss: 3.5286105551719666
LOSS train 3.5286105551719666 valid 3.562556266784668
EPOCH 131:
  batch 1000 loss: 3.5062739050388334
Epoch 00131: reducing learning rate of group 0 to 6.2500e-05.
LOSS train 3.5062739050388334 valid 3.5632541179656982
EPOCH 132:
  batch 1000 loss: 3.5250208563804626
LOSS train 3.5250208563804626 valid 3.557708740234375
EPOCH 133:
  batch 1000 loss: 3.5192974100112915
LOSS train 3.5192974100112915 valid 3.556528329849243
EPOCH 134:
  batch 1000 loss: 3.5033813512325285
LOSS train 3.5033813512325285 valid 3.5590639114379883
EPOCH 135:
  batch 1000 loss: 3.495414075613022
LOSS train 3.495414075613022 valid 3.5570263862609863
EPOCH 136:
  batch 1000 loss: 3.511458214998245
LOSS train 3.511458214998245 valid 3.5572562217712402
EPOCH 137:
  batch 1000 loss: 3.520896891593933
LOSS train 3.520896891593933 valid 3.556380033493042
EPOCH 138:
  batch 1000 loss: 3.497515603065491
LOSS train 3.497515603065491 valid 3.5547070503234863
EPOCH 139:
  batch 1000 loss: 3.5086752576828
LOSS train 3.5086752576828 valid 3.5544521808624268
EPOCH 140:
  batch 1000 loss: 3.520832332611084
LOSS train 3.520832332611084 valid 3.554969549179077
EPOCH 141:
  batch 1000 loss: 3.4852281746864318
LOSS train 3.4852281746864318 valid 3.5532422065734863
EPOCH 142:
  batch 1000 loss: 3.5106483278274534
LOSS train 3.5106483278274534 valid 3.5544216632843018
EPOCH 143:
  batch 1000 loss: 3.508691013097763
LOSS train 3.508691013097763 valid 3.5568630695343018
EPOCH 144:
  batch 1000 loss: 3.492068629026413
LOSS train 3.492068629026413 valid 3.555866241455078
EPOCH 145:
  batch 1000 loss: 3.5043688590526583
LOSS train 3.5043688590526583 valid 3.556647300720215
EPOCH 146:
  batch 1000 loss: 3.5222581479549406
LOSS train 3.5222581479549406 valid 3.5548384189605713
EPOCH 147:
  batch 1000 loss: 3.5104381422996522
Epoch 00147: reducing learning rate of group 0 to 3.1250e-05.
LOSS train 3.5104381422996522 valid 3.5533089637756348
EPOCH 148:
  batch 1000 loss: 3.4881465599536896
LOSS train 3.4881465599536896 valid 3.5514793395996094
EPOCH 149:
  batch 1000 loss: 3.5022543590068818
LOSS train 3.5022543590068818 valid 3.550811290740967
EPOCH 150:
  batch 1000 loss: 3.492057311296463
LOSS train 3.492057311296463 valid 3.551903486251831
EPOCH 151:
  batch 1000 loss: 3.4882296385765077
LOSS train 3.4882296385765077 valid 3.5497395992279053
EPOCH 152:
  batch 1000 loss: 3.5057169559001924
LOSS train 3.5057169559001924 valid 3.55045223236084
EPOCH 153:
  batch 1000 loss: 3.486661212682724
LOSS train 3.486661212682724 valid 3.5514063835144043
EPOCH 154:
  batch 1000 loss: 3.485522003650665
LOSS train 3.485522003650665 valid 3.550933361053467
EPOCH 155:
  batch 1000 loss: 3.5071707201004028
LOSS train 3.5071707201004028 valid 3.5506839752197266
EPOCH 156:
  batch 1000 loss: 3.506413157463074
LOSS train 3.506413157463074 valid 3.5506529808044434
EPOCH 157:
  batch 1000 loss: 3.499717851161957
Epoch 00157: reducing learning rate of group 0 to 1.5625e-05.
LOSS train 3.499717851161957 valid 3.552043914794922
EPOCH 158:
  batch 1000 loss: 3.4848187499046324
LOSS train 3.4848187499046324 valid 3.5500974655151367
EPOCH 159:
  batch 1000 loss: 3.4974959568977355
LOSS train 3.4974959568977355 valid 3.550661563873291
EPOCH 160:
  batch 1000 loss: 3.4983070986270906
LOSS train 3.4983070986270906 valid 3.5506174564361572
EPOCH 161:
  batch 1000 loss: 3.4922375993728636
LOSS train 3.4922375993728636 valid 3.550438165664673
EPOCH 162:
  batch 1000 loss: 3.4871874113082884
LOSS train 3.4871874113082884 valid 3.5500636100769043
EPOCH 163:
  batch 1000 loss: 3.492518572807312
Epoch 00163: reducing learning rate of group 0 to 7.8125e-06.
LOSS train 3.492518572807312 valid 3.5496644973754883
EPOCH 164:
  batch 1000 loss: 3.4940697815418242
LOSS train 3.4940697815418242 valid 3.5494155883789062
EPOCH 165:
  batch 1000 loss: 3.4899286880493166
LOSS train 3.4899286880493166 valid 3.5497565269470215
EPOCH 166:
  batch 1000 loss: 3.5095999615192413
LOSS train 3.5095999615192413 valid 3.5502402782440186
EPOCH 167:
  batch 1000 loss: 3.501693818807602
LOSS train 3.501693818807602 valid 3.550865888595581
EPOCH 168:
  batch 1000 loss: 3.4945630960464475
LOSS train 3.4945630960464475 valid 3.5503015518188477
EPOCH 169:
  batch 1000 loss: 3.4840062832832337
Epoch 00169: reducing learning rate of group 0 to 3.9063e-06.
LOSS train 3.4840062832832337 valid 3.5502421855926514
EPOCH 170:
  batch 1000 loss: 3.4846006348133085
LOSS train 3.4846006348133085 valid 3.549525022506714
EPOCH 171:
  batch 1000 loss: 3.491962965250015
LOSS train 3.491962965250015 valid 3.550187110900879
EPOCH 172:
  batch 1000 loss: 3.487703846693039
LOSS train 3.487703846693039 valid 3.5493216514587402
EPOCH 173:
  batch 1000 loss: 3.5080950474739074
LOSS train 3.5080950474739074 valid 3.549546957015991
EPOCH 174:
  batch 1000 loss: 3.5023254010677336
LOSS train 3.5023254010677336 valid 3.549656867980957
EPOCH 175:
  batch 1000 loss: 3.4965684344768526
LOSS train 3.4965684344768526 valid 3.550605297088623
EPOCH 176:
  batch 1000 loss: 3.5020146827697753
LOSS train 3.5020146827697753 valid 3.5498363971710205
EPOCH 177:
  batch 1000 loss: 3.513255277633667
LOSS train 3.513255277633667 valid 3.5487143993377686
EPOCH 178:
  batch 1000 loss: 3.4936549096107483
LOSS train 3.4936549096107483 valid 3.5497312545776367
EPOCH 179:
  batch 1000 loss: 3.494108423471451
LOSS train 3.494108423471451 valid 3.549769401550293
EPOCH 180:
  batch 1000 loss: 3.49259503698349
LOSS train 3.49259503698349 valid 3.550018548965454
EPOCH 181:
  batch 1000 loss: 3.483264554977417
LOSS train 3.483264554977417 valid 3.550539493560791
EPOCH 182:
  batch 1000 loss: 3.4930811173915863
LOSS train 3.4930811173915863 valid 3.550043821334839
EPOCH 183:
  batch 1000 loss: 3.4923383257389067
Epoch 00183: reducing learning rate of group 0 to 1.9531e-06.
LOSS train 3.4923383257389067 valid 3.550563097000122
EPOCH 184:
  batch 1000 loss: 3.496039644241333
LOSS train 3.496039644241333 valid 3.5497219562530518
EPOCH 185:
  batch 1000 loss: 3.4956824803352355
LOSS train 3.4956824803352355 valid 3.550495147705078
EPOCH 186:
  batch 1000 loss: 3.502047625541687
LOSS train 3.502047625541687 valid 3.549577236175537
EPOCH 187:
  batch 1000 loss: 3.511373232603073
LOSS train 3.511373232603073 valid 3.550142526626587
EPOCH 188:
  batch 1000 loss: 3.5071914374828337
LOSS train 3.5071914374828337 valid 3.548999786376953
EPOCH 189:
  batch 1000 loss: 3.4923558845520017
Epoch 00189: reducing learning rate of group 0 to 9.7656e-07.
LOSS train 3.4923558845520017 valid 3.5491373538970947
EPOCH 190:
  batch 1000 loss: 3.4821268229484557
LOSS train 3.4821268229484557 valid 3.549509048461914
EPOCH 191:
  batch 1000 loss: 3.504212940454483
LOSS train 3.504212940454483 valid 3.5490756034851074
EPOCH 192:
  batch 1000 loss: 3.4990719344615937
LOSS train 3.4990719344615937 valid 3.550245523452759
EPOCH 193:
  batch 1000 loss: 3.4662260019779207
LOSS train 3.4662260019779207 valid 3.5495176315307617
EPOCH 194:
  batch 1000 loss: 3.50313130569458
LOSS train 3.50313130569458 valid 3.548473596572876
EPOCH 195:
  batch 1000 loss: 3.4781531653404234
Epoch 00195: reducing learning rate of group 0 to 4.8828e-07.
LOSS train 3.4781531653404234 valid 3.549532413482666
EPOCH 196:
  batch 1000 loss: 3.4777197477817534
LOSS train 3.4777197477817534 valid 3.549530506134033
EPOCH 197:
  batch 1000 loss: 3.508930879354477
LOSS train 3.508930879354477 valid 3.549755096435547
EPOCH 198:
  batch 1000 loss: 3.4984993216991422
LOSS train 3.4984993216991422 valid 3.5491418838500977
EPOCH 199:
  batch 1000 loss: 3.4865961279869078
LOSS train 3.4865961279869078 valid 3.5491979122161865
EPOCH 200:
  batch 1000 loss: 3.4854685146808624
LOSS train 3.4854685146808624 valid 3.549360752105713
EPOCH 201:
  batch 1000 loss: 3.5011144263744356
Epoch 00201: reducing learning rate of group 0 to 2.4414e-07.
LOSS train 3.5011144263744356 valid 3.5491178035736084
EPOCH 202:
  batch 1000 loss: 3.494175920009613
LOSS train 3.494175920009613 valid 3.5495073795318604
EPOCH 203:
  batch 1000 loss: 3.487658182621002
LOSS train 3.487658182621002 valid 3.5498101711273193
EPOCH 204:
  batch 1000 loss: 3.506930153846741
LOSS train 3.506930153846741 valid 3.549704074859619
EPOCH 205:
  batch 1000 loss: 3.491687762260437
LOSS train 3.491687762260437 valid 3.5491979122161865
EPOCH 206:
  batch 1000 loss: 3.490368682146072
LOSS train 3.490368682146072 valid 3.549037456512451
EPOCH 207:
  batch 1000 loss: 3.499534686088562
Epoch 00207: reducing learning rate of group 0 to 1.2207e-07.
LOSS train 3.499534686088562 valid 3.5491857528686523
EPOCH 208:
  batch 1000 loss: 3.4900913276672365
LOSS train 3.4900913276672365 valid 3.549501419067383
EPOCH 209:
  batch 1000 loss: 3.504294699907303
LOSS train 3.504294699907303 valid 3.549285888671875
EPOCH 210:
  batch 1000 loss: 3.504584934234619
LOSS train 3.504584934234619 valid 3.5491278171539307
EPOCH 211:
  batch 1000 loss: 3.494097943544388
LOSS train 3.494097943544388 valid 3.5493297576904297
EPOCH 212:
  batch 1000 loss: 3.4941474549770355
LOSS train 3.4941474549770355 valid 3.5494048595428467
EPOCH 213:
  batch 1000 loss: 3.4942537124156954
Epoch 00213: reducing learning rate of group 0 to 6.1035e-08.
LOSS train 3.4942537124156954 valid 3.5499179363250732
EPOCH 214:
  batch 1000 loss: 3.4800248193740844
LOSS train 3.4800248193740844 valid 3.54978084564209
EPOCH 215:
  batch 1000 loss: 3.4762339498996733
LOSS train 3.4762339498996733 valid 3.549882173538208
EPOCH 216:
  batch 1000 loss: 3.5057960433959963
LOSS train 3.5057960433959963 valid 3.549140691757202
EPOCH 217:
  batch 1000 loss: 3.4783285961151122
LOSS train 3.4783285961151122 valid 3.549201250076294
EPOCH 218:
  batch 1000 loss: 3.497620859146118
LOSS train 3.497620859146118 valid 3.549426555633545
EPOCH 219:
  batch 1000 loss: 3.476963693380356
Epoch 00219: reducing learning rate of group 0 to 3.0518e-08.
LOSS train 3.476963693380356 valid 3.5497543811798096
EPOCH 220:
  batch 1000 loss: 3.48444696354866
LOSS train 3.48444696354866 valid 3.5492005348205566
EPOCH 221:
  batch 1000 loss: 3.4898278427124025
LOSS train 3.4898278427124025 valid 3.5493812561035156
EPOCH 222:
  batch 1000 loss: 3.496485109806061
LOSS train 3.496485109806061 valid 3.5491747856140137
EPOCH 223:
  batch 1000 loss: 3.5121768980026244
LOSS train 3.5121768980026244 valid 3.5499653816223145
EPOCH 224:
  batch 1000 loss: 3.496672671556473
LOSS train 3.496672671556473 valid 3.5497779846191406
EPOCH 225:
  batch 1000 loss: 3.4901122341156006
Epoch 00225: reducing learning rate of group 0 to 1.5259e-08.
LOSS train 3.4901122341156006 valid 3.5497844219207764
EPOCH 226:
  batch 1000 loss: 3.4715043666362764
LOSS train 3.4715043666362764 valid 3.5488555431365967
EPOCH 227:
  batch 1000 loss: 3.4858691272735594
LOSS train 3.4858691272735594 valid 3.549443244934082
EPOCH 228:
  batch 1000 loss: 3.4745982234477997
LOSS train 3.4745982234477997 valid 3.5491526126861572
EPOCH 229:
  batch 1000 loss: 3.49511950302124
LOSS train 3.49511950302124 valid 3.549947738647461
EPOCH 230:
  batch 1000 loss: 3.479675728559494
LOSS train 3.479675728559494 valid 3.550114870071411
EPOCH 231:
  batch 1000 loss: 3.5137263939380645
LOSS train 3.5137263939380645 valid 3.549450397491455
EPOCH 232:
  batch 1000 loss: 3.469236126422882
LOSS train 3.469236126422882 valid 3.55012845993042
EPOCH 233:
  batch 1000 loss: 3.487538415670395
LOSS train 3.487538415670395 valid 3.5500357151031494
EPOCH 234:
  batch 1000 loss: 3.4821264357566832
LOSS train 3.4821264357566832 valid 3.5497958660125732
EPOCH 235:
  batch 1000 loss: 3.5060798048973085
LOSS train 3.5060798048973085 valid 3.5491859912872314
EPOCH 236:
  batch 1000 loss: 3.5047502689361574
LOSS train 3.5047502689361574 valid 3.5495336055755615
EPOCH 237:
  batch 1000 loss: 3.4965674214363096
LOSS train 3.4965674214363096 valid 3.5490074157714844
EPOCH 238:
  batch 1000 loss: 3.498513463973999
LOSS train 3.498513463973999 valid 3.5501599311828613
EPOCH 239:
  batch 1000 loss: 3.473043088674545
LOSS train 3.473043088674545 valid 3.549860954284668
EPOCH 240:
  batch 1000 loss: 3.493726546764374
LOSS train 3.493726546764374 valid 3.549135208129883
EPOCH 241:
  batch 1000 loss: 3.467764565229416
LOSS train 3.467764565229416 valid 3.5494565963745117
EPOCH 242:
  batch 1000 loss: 3.5009941346645355
LOSS train 3.5009941346645355 valid 3.5487005710601807
EPOCH 243:
  batch 1000 loss: 3.4987018094062807
LOSS train 3.4987018094062807 valid 3.549461603164673
EPOCH 244:
  batch 1000 loss: 3.4836427087783814
LOSS train 3.4836427087783814 valid 3.549091100692749
EPOCH 245:
  batch 1000 loss: 3.483387303829193
LOSS train 3.483387303829193 valid 3.5489437580108643
EPOCH 246:
  batch 1000 loss: 3.489113072633743
LOSS train 3.489113072633743 valid 3.549882411956787
EPOCH 247:
  batch 1000 loss: 3.492470250606537
LOSS train 3.492470250606537 valid 3.550122022628784
EPOCH 248:
  batch 1000 loss: 3.503897619962692
LOSS train 3.503897619962692 valid 3.549384832382202
EPOCH 249:
  batch 1000 loss: 3.503653847455978
LOSS train 3.503653847455978 valid 3.549133062362671
EPOCH 250:
  batch 1000 loss: 3.5019485065937044
LOSS train 3.5019485065937044 valid 3.548887252807617
EPOCH 251:
  batch 1000 loss: 3.486969247817993
LOSS train 3.486969247817993 valid 3.549793243408203
EPOCH 252:
  batch 1000 loss: 3.5055593304634094
LOSS train 3.5055593304634094 valid 3.5491411685943604
EPOCH 253:
  batch 1000 loss: 3.4761380760669707
LOSS train 3.4761380760669707 valid 3.5494468212127686
EPOCH 254:
  batch 1000 loss: 3.47796080827713
LOSS train 3.47796080827713 valid 3.5491201877593994
EPOCH 255:
  batch 1000 loss: 3.503432642221451
LOSS train 3.503432642221451 valid 3.5491223335266113
EPOCH 256:
  batch 1000 loss: 3.4938450298309327
LOSS train 3.4938450298309327 valid 3.5490775108337402
EPOCH 257:
  batch 1000 loss: 3.5007743554115294
LOSS train 3.5007743554115294 valid 3.5497376918792725
EPOCH 258:
  batch 1000 loss: 3.4778347465991972
LOSS train 3.4778347465991972 valid 3.5498123168945312
EPOCH 259:
  batch 1000 loss: 3.4821286528110504
LOSS train 3.4821286528110504 valid 3.5501139163970947
EPOCH 260:
  batch 1000 loss: 3.4664757509231565
LOSS train 3.4664757509231565 valid 3.5487051010131836
EPOCH 261:
  batch 1000 loss: 3.490578191995621
LOSS train 3.490578191995621 valid 3.549406051635742
EPOCH 262:
  batch 1000 loss: 3.5069818093776703
LOSS train 3.5069818093776703 valid 3.549079656600952
EPOCH 263:
  batch 1000 loss: 3.485935226678848
LOSS train 3.485935226678848 valid 3.5497002601623535
EPOCH 264:
  batch 1000 loss: 3.505099886894226
LOSS train 3.505099886894226 valid 3.5493693351745605
EPOCH 265:
  batch 1000 loss: 3.49367773771286
LOSS train 3.49367773771286 valid 3.5497288703918457
EPOCH 266:
  batch 1000 loss: 3.509524180173874
LOSS train 3.509524180173874 valid 3.5497570037841797
EPOCH 267:
  batch 1000 loss: 3.5046874294281007
LOSS train 3.5046874294281007 valid 3.5494093894958496
EPOCH 268:
  batch 1000 loss: 3.480565484523773
LOSS train 3.480565484523773 valid 3.549424409866333
EPOCH 269:
  batch 1000 loss: 3.4973834528923033
LOSS train 3.4973834528923033 valid 3.5491206645965576
EPOCH 270:
  batch 1000 loss: 3.4974216389656068
LOSS train 3.4974216389656068 valid 3.549304723739624
EPOCH 271:
  batch 1000 loss: 3.5020227317810058
LOSS train 3.5020227317810058 valid 3.5498361587524414
EPOCH 272:
  batch 1000 loss: 3.481781471967697
LOSS train 3.481781471967697 valid 3.5492026805877686
EPOCH 273:
  batch 1000 loss: 3.4824390189647674
LOSS train 3.4824390189647674 valid 3.5492913722991943
EPOCH 274:
  batch 1000 loss: 3.4907508409023285
LOSS train 3.4907508409023285 valid 3.548844337463379
EPOCH 275:
  batch 1000 loss: 3.4848257427215574
LOSS train 3.4848257427215574 valid 3.549567222595215
EPOCH 276:
  batch 1000 loss: 3.487444305181503
LOSS train 3.487444305181503 valid 3.5491673946380615
EPOCH 277:
  batch 1000 loss: 3.486931823968887
LOSS train 3.486931823968887 valid 3.5491230487823486
EPOCH 278:
  batch 1000 loss: 3.476821362018585
LOSS train 3.476821362018585 valid 3.549140453338623
EPOCH 279:
  batch 1000 loss: 3.4807389273643494
LOSS train 3.4807389273643494 valid 3.5494017601013184
EPOCH 280:
  batch 1000 loss: 3.5265407524108885
LOSS train 3.5265407524108885 valid 3.5494937896728516
EPOCH 281:
  batch 1000 loss: 3.477712121248245
LOSS train 3.477712121248245 valid 3.5488390922546387
EPOCH 282:
  batch 1000 loss: 3.4999669110774994
LOSS train 3.4999669110774994 valid 3.549147844314575
EPOCH 283:
  batch 1000 loss: 3.500311651468277
LOSS train 3.500311651468277 valid 3.549109935760498
EPOCH 284:
  batch 1000 loss: 3.487544811010361
LOSS train 3.487544811010361 valid 3.5494225025177
EPOCH 285:
  batch 1000 loss: 3.4896820406913758
LOSS train 3.4896820406913758 valid 3.549185037612915
EPOCH 286:
  batch 1000 loss: 3.498374885559082
LOSS train 3.498374885559082 valid 3.5497186183929443
EPOCH 287:
  batch 1000 loss: 3.496703538656235
LOSS train 3.496703538656235 valid 3.5500621795654297
EPOCH 288:
  batch 1000 loss: 3.480465815782547
LOSS train 3.480465815782547 valid 3.5493781566619873
EPOCH 289:
  batch 1000 loss: 3.501363948345184
LOSS train 3.501363948345184 valid 3.549191951751709
EPOCH 290:
  batch 1000 loss: 3.5123646392822265
LOSS train 3.5123646392822265 valid 3.5502521991729736
EPOCH 291:
  batch 1000 loss: 3.488920227050781
LOSS train 3.488920227050781 valid 3.548898220062256
EPOCH 292:
  batch 1000 loss: 3.498390060186386
LOSS train 3.498390060186386 valid 3.549774408340454
EPOCH 293:
  batch 1000 loss: 3.493384883880615
LOSS train 3.493384883880615 valid 3.549184560775757
EPOCH 294:
  batch 1000 loss: 3.4892549114227296
LOSS train 3.4892549114227296 valid 3.550168752670288
EPOCH 295:
  batch 1000 loss: 3.5100741460323333
LOSS train 3.5100741460323333 valid 3.5490365028381348
EPOCH 296:
  batch 1000 loss: 3.507626913547516
LOSS train 3.507626913547516 valid 3.549535036087036
EPOCH 297:
  batch 1000 loss: 3.4969166026115417
LOSS train 3.4969166026115417 valid 3.5490949153900146
EPOCH 298:
  batch 1000 loss: 3.5007924225330354
LOSS train 3.5007924225330354 valid 3.54892635345459
EPOCH 299:
  batch 1000 loss: 3.5179383010864256
LOSS train 3.5179383010864256 valid 3.549607992172241
EPOCH 300:
  batch 1000 loss: 3.51051242518425
LOSS train 3.51051242518425 valid 3.5494470596313477
EPOCH 301:
  batch 1000 loss: 3.472334816455841
LOSS train 3.472334816455841 valid 3.549750804901123
EPOCH 302:
  batch 1000 loss: 3.4807517161369326
LOSS train 3.4807517161369326 valid 3.5491433143615723
EPOCH 303:
  batch 1000 loss: 3.4790091426372527
LOSS train 3.4790091426372527 valid 3.5500845909118652
EPOCH 304:
  batch 1000 loss: 3.474391080379486
LOSS train 3.474391080379486 valid 3.5491278171539307
EPOCH 305:
  batch 1000 loss: 3.4917300057411196
LOSS train 3.4917300057411196 valid 3.549110174179077
EPOCH 306:
  batch 1000 loss: 3.4930193238258362
LOSS train 3.4930193238258362 valid 3.549100160598755
EPOCH 307:
  batch 1000 loss: 3.5088393399715425
LOSS train 3.5088393399715425 valid 3.5497255325317383
EPOCH 308:
  batch 1000 loss: 3.4986240108013154
LOSS train 3.4986240108013154 valid 3.5487864017486572
EPOCH 309:
  batch 1000 loss: 3.496342132091522
LOSS train 3.496342132091522 valid 3.5491089820861816
EPOCH 310:
  batch 1000 loss: 3.497867882013321
LOSS train 3.497867882013321 valid 3.5485401153564453
EPOCH 311:
  batch 1000 loss: 3.509668095111847
LOSS train 3.509668095111847 valid 3.549654483795166
EPOCH 312:
  batch 1000 loss: 3.506064306259155
LOSS train 3.506064306259155 valid 3.5503056049346924
EPOCH 313:
  batch 1000 loss: 3.489503180027008
LOSS train 3.489503180027008 valid 3.5492937564849854
EPOCH 314:
  batch 1000 loss: 3.500248429298401
LOSS train 3.500248429298401 valid 3.550347328186035
EPOCH 315:
  batch 1000 loss: 3.4954076051712035
LOSS train 3.4954076051712035 valid 3.5486695766448975
EPOCH 316:
  batch 1000 loss: 3.492547883272171
LOSS train 3.492547883272171 valid 3.54938006401062
EPOCH 317:
  batch 1000 loss: 3.506111614942551
LOSS train 3.506111614942551 valid 3.549466848373413
EPOCH 318:
  batch 1000 loss: 3.4814761641025544
LOSS train 3.4814761641025544 valid 3.5490798950195312
EPOCH 319:
  batch 1000 loss: 3.4850439467430117
LOSS train 3.4850439467430117 valid 3.5498270988464355
EPOCH 320:
  batch 1000 loss: 3.484853716611862
LOSS train 3.484853716611862 valid 3.549738883972168
EPOCH 321:
  batch 1000 loss: 3.4910057101249694
LOSS train 3.4910057101249694 valid 3.5494320392608643
EPOCH 322:
  batch 1000 loss: 3.5011083545684816
LOSS train 3.5011083545684816 valid 3.5488972663879395
EPOCH 323:
  batch 1000 loss: 3.4912587792873384
LOSS train 3.4912587792873384 valid 3.5486862659454346
EPOCH 324:
  batch 1000 loss: 3.4854261045455934
LOSS train 3.4854261045455934 valid 3.5498406887054443
EPOCH 325:
  batch 1000 loss: 3.489499284505844
LOSS train 3.489499284505844 valid 3.549788236618042
EPOCH 326:
  batch 1000 loss: 3.4888962042331695
LOSS train 3.4888962042331695 valid 3.5490219593048096
EPOCH 327:
  batch 1000 loss: 3.495449238061905
LOSS train 3.495449238061905 valid 3.5487148761749268
EPOCH 328:
  batch 1000 loss: 3.489273887872696
LOSS train 3.489273887872696 valid 3.549774408340454
EPOCH 329:
  batch 1000 loss: 3.49552200460434
LOSS train 3.49552200460434 valid 3.5503764152526855
EPOCH 330:
  batch 1000 loss: 3.5024775943756103
LOSS train 3.5024775943756103 valid 3.5497562885284424
EPOCH 331:
  batch 1000 loss: 3.5018302421569825
LOSS train 3.5018302421569825 valid 3.549529552459717
EPOCH 332:
  batch 1000 loss: 3.5012707242965697
LOSS train 3.5012707242965697 valid 3.5504109859466553
EPOCH 333:
  batch 1000 loss: 3.503064667224884
LOSS train 3.503064667224884 valid 3.5494906902313232
EPOCH 334:
  batch 1000 loss: 3.487241889953613
LOSS train 3.487241889953613 valid 3.5497701168060303
EPOCH 335:
  batch 1000 loss: 3.5032351768016814
LOSS train 3.5032351768016814 valid 3.5498201847076416
EPOCH 336:
  batch 1000 loss: 3.5062129168510436
LOSS train 3.5062129168510436 valid 3.5491795539855957
EPOCH 337:
  batch 1000 loss: 3.4895649054050444
LOSS train 3.4895649054050444 valid 3.550110340118408
EPOCH 338:
  batch 1000 loss: 3.488282522201538
LOSS train 3.488282522201538 valid 3.5486080646514893
EPOCH 339:
  batch 1000 loss: 3.490323127269745
LOSS train 3.490323127269745 valid 3.5491530895233154
EPOCH 340:
  batch 1000 loss: 3.4910715889930723
LOSS train 3.4910715889930723 valid 3.5497403144836426
EPOCH 341:
  batch 1000 loss: 3.5047942428588867
LOSS train 3.5047942428588867 valid 3.5490529537200928
EPOCH 342:
  batch 1000 loss: 3.507121589899063
LOSS train 3.507121589899063 valid 3.5501701831817627
EPOCH 343:
  batch 1000 loss: 3.5010880329608915
LOSS train 3.5010880329608915 valid 3.548736333847046
EPOCH 344:
  batch 1000 loss: 3.496373689413071
LOSS train 3.496373689413071 valid 3.54874849319458
EPOCH 345:
  batch 1000 loss: 3.502527734041214
LOSS train 3.502527734041214 valid 3.549211025238037
EPOCH 346:
  batch 1000 loss: 3.491592421770096
LOSS train 3.491592421770096 valid 3.549112558364868
EPOCH 347:
  batch 1000 loss: 3.4826622529029847
LOSS train 3.4826622529029847 valid 3.549081802368164
EPOCH 348:
  batch 1000 loss: 3.494376937150955
LOSS train 3.494376937150955 valid 3.550191879272461
EPOCH 349:
  batch 1000 loss: 3.508611842632294
LOSS train 3.508611842632294 valid 3.5487732887268066
EPOCH 350:
  batch 1000 loss: 3.497192263841629
LOSS train 3.497192263841629 valid 3.548948287963867
EPOCH 351:
  batch 1000 loss: 3.5107261209487914
LOSS train 3.5107261209487914 valid 3.5490994453430176
EPOCH 352:
  batch 1000 loss: 3.5274391570091246
LOSS train 3.5274391570091246 valid 3.5497043132781982
EPOCH 353:
  batch 1000 loss: 3.487791078090668
LOSS train 3.487791078090668 valid 3.549132823944092
EPOCH 354:
  batch 1000 loss: 3.490960991382599
LOSS train 3.490960991382599 valid 3.5490686893463135
EPOCH 355:
  batch 1000 loss: 3.4872549295425417
LOSS train 3.4872549295425417 valid 3.549769878387451
EPOCH 356:
  batch 1000 loss: 3.5065799350738525
LOSS train 3.5065799350738525 valid 3.5497562885284424
EPOCH 357:
  batch 1000 loss: 3.5055600430965423
LOSS train 3.5055600430965423 valid 3.549152135848999
EPOCH 358:
  batch 1000 loss: 3.487537475347519
LOSS train 3.487537475347519 valid 3.549081802368164
EPOCH 359:
  batch 1000 loss: 3.4903030378818514
LOSS train 3.4903030378818514 valid 3.549440622329712
EPOCH 360:
  batch 1000 loss: 3.4855300748348235
LOSS train 3.4855300748348235 valid 3.5493972301483154
EPOCH 361:
  batch 1000 loss: 3.471061557292938
LOSS train 3.471061557292938 valid 3.5508291721343994
EPOCH 362:
  batch 1000 loss: 3.489184940099716
LOSS train 3.489184940099716 valid 3.549300193786621
EPOCH 363:
  batch 1000 loss: 3.49909863114357
LOSS train 3.49909863114357 valid 3.5498321056365967
EPOCH 364:
  batch 1000 loss: 3.501218560218811
LOSS train 3.501218560218811 valid 3.550503730773926
EPOCH 365:
  batch 1000 loss: 3.499160638809204
LOSS train 3.499160638809204 valid 3.5503759384155273
EPOCH 366:
  batch 1000 loss: 3.504110825538635
LOSS train 3.504110825538635 valid 3.5498228073120117
EPOCH 367:
  batch 1000 loss: 3.483342371940613
LOSS train 3.483342371940613 valid 3.549386978149414
EPOCH 368:
  batch 1000 loss: 3.5099464678764343
LOSS train 3.5099464678764343 valid 3.5498926639556885
EPOCH 369:
  batch 1000 loss: 3.499949944734573
LOSS train 3.499949944734573 valid 3.549966812133789
EPOCH 370:
  batch 1000 loss: 3.507651615858078
LOSS train 3.507651615858078 valid 3.5490925312042236
EPOCH 371:
  batch 1000 loss: 3.4938480134010317
LOSS train 3.4938480134010317 valid 3.549402952194214
EPOCH 372:
  batch 1000 loss: 3.4969014251232147
LOSS train 3.4969014251232147 valid 3.5498080253601074
EPOCH 373:
  batch 1000 loss: 3.49227144408226
LOSS train 3.49227144408226 valid 3.5493507385253906
EPOCH 374:
  batch 1000 loss: 3.489024480581284
LOSS train 3.489024480581284 valid 3.549443244934082
EPOCH 375:
  batch 1000 loss: 3.4723361477851866
LOSS train 3.4723361477851866 valid 3.5501439571380615
EPOCH 376:
  batch 1000 loss: 3.4982392885684965
LOSS train 3.4982392885684965 valid 3.5501081943511963
EPOCH 377:
  batch 1000 loss: 3.4860000574588774
LOSS train 3.4860000574588774 valid 3.550159454345703
EPOCH 378:
  batch 1000 loss: 3.486515045642853
LOSS train 3.486515045642853 valid 3.549384117126465
EPOCH 379:
  batch 1000 loss: 3.5059510161876677
LOSS train 3.5059510161876677 valid 3.549380302429199
EPOCH 380:
  batch 1000 loss: 3.4967804329395293
LOSS train 3.4967804329395293 valid 3.548802137374878
EPOCH 381:
  batch 1000 loss: 3.4927178540229797
LOSS train 3.4927178540229797 valid 3.5494723320007324
EPOCH 382:
  batch 1000 loss: 3.484716957807541
LOSS train 3.484716957807541 valid 3.549077033996582
EPOCH 383:
  batch 1000 loss: 3.4921896388530733
LOSS train 3.4921896388530733 valid 3.5496408939361572
EPOCH 384:
  batch 1000 loss: 3.4861238558292387
LOSS train 3.4861238558292387 valid 3.5504066944122314
EPOCH 385:
  batch 1000 loss: 3.4938481705188753
LOSS train 3.4938481705188753 valid 3.5490775108337402
EPOCH 386:
  batch 1000 loss: 3.507716012954712
LOSS train 3.507716012954712 valid 3.549764633178711
EPOCH 387:
  batch 1000 loss: 3.4966315076351164
LOSS train 3.4966315076351164 valid 3.549703598022461
EPOCH 388:
  batch 1000 loss: 3.497565096139908
LOSS train 3.497565096139908 valid 3.5490334033966064
EPOCH 389:
  batch 1000 loss: 3.4888122260570524
LOSS train 3.4888122260570524 valid 3.549391746520996
EPOCH 390:
  batch 1000 loss: 3.500862636089325
LOSS train 3.500862636089325 valid 3.5492022037506104
EPOCH 391:
  batch 1000 loss: 3.4744539942741395
LOSS train 3.4744539942741395 valid 3.549325466156006
EPOCH 392:
  batch 1000 loss: 3.4878487179279327
LOSS train 3.4878487179279327 valid 3.549791097640991
EPOCH 393:
  batch 1000 loss: 3.5055821647644043
LOSS train 3.5055821647644043 valid 3.5498087406158447
EPOCH 394:
  batch 1000 loss: 3.4906877546310424
LOSS train 3.4906877546310424 valid 3.549165964126587
EPOCH 395:
  batch 1000 loss: 3.487151146411896
LOSS train 3.487151146411896 valid 3.549515962600708
EPOCH 396:
  batch 1000 loss: 3.4937269546985625
LOSS train 3.4937269546985625 valid 3.550450563430786
EPOCH 397:
  batch 1000 loss: 3.481881826162338
LOSS train 3.481881826162338 valid 3.548880100250244
EPOCH 398:
  batch 1000 loss: 3.4995526044368743
LOSS train 3.4995526044368743 valid 3.5491926670074463
EPOCH 399:
  batch 1000 loss: 3.4914452359676362
LOSS train 3.4914452359676362 valid 3.5491509437561035
EPOCH 400:
  batch 1000 loss: 3.497154018163681
LOSS train 3.497154018163681 valid 3.5492238998413086
EPOCH 401:
  batch 1000 loss: 3.4895501470565797
LOSS train 3.4895501470565797 valid 3.549870729446411
EPOCH 402:
  batch 1000 loss: 3.4955570323467255
LOSS train 3.4955570323467255 valid 3.5496394634246826
EPOCH 403:
  batch 1000 loss: 3.5008398003578187
LOSS train 3.5008398003578187 valid 3.5499520301818848
EPOCH 404:
  batch 1000 loss: 3.477320716381073
LOSS train 3.477320716381073 valid 3.549656629562378
EPOCH 405:
  batch 1000 loss: 3.4945740966796874
LOSS train 3.4945740966796874 valid 3.5495357513427734
EPOCH 406:
  batch 1000 loss: 3.4724469134807587
LOSS train 3.4724469134807587 valid 3.549074649810791
EPOCH 407:
  batch 1000 loss: 3.4800053253173826
LOSS train 3.4800053253173826 valid 3.5501160621643066
EPOCH 408:
  batch 1000 loss: 3.493652266263962
LOSS train 3.493652266263962 valid 3.5490517616271973
EPOCH 409:
  batch 1000 loss: 3.4948551630973816
LOSS train 3.4948551630973816 valid 3.549112319946289
EPOCH 410:
  batch 1000 loss: 3.4913609845638276
LOSS train 3.4913609845638276 valid 3.5498545169830322
EPOCH 411:
  batch 1000 loss: 3.502978589773178
LOSS train 3.502978589773178 valid 3.5494112968444824
EPOCH 412:
  batch 1000 loss: 3.510007703781128
LOSS train 3.510007703781128 valid 3.549448013305664
EPOCH 413:
  batch 1000 loss: 3.497595831155777
LOSS train 3.497595831155777 valid 3.5499746799468994
EPOCH 414:
  batch 1000 loss: 3.5028318104743956
LOSS train 3.5028318104743956 valid 3.549346923828125
EPOCH 415:
  batch 1000 loss: 3.4956102361679076
LOSS train 3.4956102361679076 valid 3.549081802368164
EPOCH 416:
  batch 1000 loss: 3.503550246953964
LOSS train 3.503550246953964 valid 3.5498974323272705
EPOCH 417:
  batch 1000 loss: 3.5095697495937346
LOSS train 3.5095697495937346 valid 3.549830913543701
EPOCH 418:
  batch 1000 loss: 3.485785796403885
LOSS train 3.485785796403885 valid 3.5499908924102783
EPOCH 419:
  batch 1000 loss: 3.505365398645401
LOSS train 3.505365398645401 valid 3.5490970611572266
EPOCH 420:
  batch 1000 loss: 3.483700469017029
LOSS train 3.483700469017029 valid 3.5492632389068604
EPOCH 421:
  batch 1000 loss: 3.4851236238479615
LOSS train 3.4851236238479615 valid 3.5490028858184814
EPOCH 422:
  batch 1000 loss: 3.5128528707027433
LOSS train 3.5128528707027433 valid 3.5491490364074707
EPOCH 423:
  batch 1000 loss: 3.4938260474205016
LOSS train 3.4938260474205016 valid 3.549130439758301
EPOCH 424:
  batch 1000 loss: 3.493677547931671
LOSS train 3.493677547931671 valid 3.5488390922546387
EPOCH 425:
  batch 1000 loss: 3.489506716489792
LOSS train 3.489506716489792 valid 3.5497138500213623
EPOCH 426:
  batch 1000 loss: 3.4815571389198303
LOSS train 3.4815571389198303 valid 3.549805164337158
EPOCH 427:
  batch 1000 loss: 3.494045931816101
LOSS train 3.494045931816101 valid 3.54982852935791
EPOCH 428:
  batch 1000 loss: 3.49947270154953
LOSS train 3.49947270154953 valid 3.5506765842437744
EPOCH 429:
  batch 1000 loss: 3.4964657068252563
LOSS train 3.4964657068252563 valid 3.548719882965088
EPOCH 430:
  batch 1000 loss: 3.4957732701301576
LOSS train 3.4957732701301576 valid 3.5493857860565186
EPOCH 431:
  batch 1000 loss: 3.484971868753433
LOSS train 3.484971868753433 valid 3.550168752670288
EPOCH 432:
  batch 1000 loss: 3.5081560368537903
LOSS train 3.5081560368537903 valid 3.549064874649048
EPOCH 433:
  batch 1000 loss: 3.5063788001537324
LOSS train 3.5063788001537324 valid 3.549485206604004
EPOCH 434:
  batch 1000 loss: 3.5045667304992674
LOSS train 3.5045667304992674 valid 3.548520565032959
EPOCH 435:
  batch 1000 loss: 3.4884522874355315
LOSS train 3.4884522874355315 valid 3.548354148864746
EPOCH 436:
  batch 1000 loss: 3.4914044318199156
LOSS train 3.4914044318199156 valid 3.549044370651245
EPOCH 437:
  batch 1000 loss: 3.496583104848862
LOSS train 3.496583104848862 valid 3.5491092205047607
EPOCH 438:
  batch 1000 loss: 3.5021813595294953
LOSS train 3.5021813595294953 valid 3.5490870475769043
EPOCH 439:
  batch 1000 loss: 3.4964162759780884
LOSS train 3.4964162759780884 valid 3.548992395401001
EPOCH 440:
  batch 1000 loss: 3.4955300076007845
LOSS train 3.4955300076007845 valid 3.548872470855713
EPOCH 441:
  batch 1000 loss: 3.493599050283432
LOSS train 3.493599050283432 valid 3.549748420715332
EPOCH 442:
  batch 1000 loss: 3.489842043161392
LOSS train 3.489842043161392 valid 3.5496463775634766
EPOCH 443:
  batch 1000 loss: 3.478461875677109
LOSS train 3.478461875677109 valid 3.5495715141296387
EPOCH 444:
  batch 1000 loss: 3.4909597642421724
LOSS train 3.4909597642421724 valid 3.54909086227417
EPOCH 445:
  batch 1000 loss: 3.4927443594932557
LOSS train 3.4927443594932557 valid 3.5498239994049072
EPOCH 446:
  batch 1000 loss: 3.490579022169113
LOSS train 3.490579022169113 valid 3.5499634742736816
EPOCH 447:
  batch 1000 loss: 3.5057212784290313
LOSS train 3.5057212784290313 valid 3.5490994453430176
EPOCH 448:
  batch 1000 loss: 3.4953517639636993
LOSS train 3.4953517639636993 valid 3.5491414070129395
EPOCH 449:
  batch 1000 loss: 3.505187919616699
LOSS train 3.505187919616699 valid 3.5494937896728516
EPOCH 450:
  batch 1000 loss: 3.5092998180389405
LOSS train 3.5092998180389405 valid 3.5489847660064697
EPOCH 451:
  batch 1000 loss: 3.487778369188309
LOSS train 3.487778369188309 valid 3.549750804901123
EPOCH 452:
  batch 1000 loss: 3.4902848517894745
LOSS train 3.4902848517894745 valid 3.549058675765991
EPOCH 453:
  batch 1000 loss: 3.504987416267395
LOSS train 3.504987416267395 valid 3.549224853515625
EPOCH 454:
  batch 1000 loss: 3.498095263004303
LOSS train 3.498095263004303 valid 3.549882173538208
EPOCH 455:
  batch 1000 loss: 3.483003359794617
LOSS train 3.483003359794617 valid 3.5499722957611084
EPOCH 456:
  batch 1000 loss: 3.5052175602912903
LOSS train 3.5052175602912903 valid 3.5494580268859863
EPOCH 457:
  batch 1000 loss: 3.4922134578227997
LOSS train 3.4922134578227997 valid 3.5490217208862305
EPOCH 458:
  batch 1000 loss: 3.5005419187545774
LOSS train 3.5005419187545774 valid 3.549956798553467
EPOCH 459:
  batch 1000 loss: 3.4892015116214754
LOSS train 3.4892015116214754 valid 3.5488991737365723
EPOCH 460:
  batch 1000 loss: 3.4934413938522337
LOSS train 3.4934413938522337 valid 3.5497593879699707
EPOCH 461:
  batch 1000 loss: 3.4816392078399656
LOSS train 3.4816392078399656 valid 3.54909610748291
EPOCH 462:
  batch 1000 loss: 3.4837630259990693
LOSS train 3.4837630259990693 valid 3.549412965774536
EPOCH 463:
  batch 1000 loss: 3.4873531954288484
LOSS train 3.4873531954288484 valid 3.549755096435547
EPOCH 464:
  batch 1000 loss: 3.4840284411907194
LOSS train 3.4840284411907194 valid 3.5497775077819824
EPOCH 465:
  batch 1000 loss: 3.497130982398987
LOSS train 3.497130982398987 valid 3.5493292808532715
EPOCH 466:
  batch 1000 loss: 3.488183954954147
LOSS train 3.488183954954147 valid 3.550039052963257
EPOCH 467:
  batch 1000 loss: 3.5166899564266205
LOSS train 3.5166899564266205 valid 3.5501480102539062
EPOCH 468:
  batch 1000 loss: 3.5013126451969145
LOSS train 3.5013126451969145 valid 3.549617052078247
EPOCH 469:
  batch 1000 loss: 3.504452210187912
LOSS train 3.504452210187912 valid 3.549692153930664
EPOCH 470:
  batch 1000 loss: 3.4906576952934265
LOSS train 3.4906576952934265 valid 3.550283670425415
EPOCH 471:
  batch 1000 loss: 3.4821186926364898
LOSS train 3.4821186926364898 valid 3.549880027770996
EPOCH 472:
  batch 1000 loss: 3.5024973776340484
LOSS train 3.5024973776340484 valid 3.5492324829101562
EPOCH 473:
  batch 1000 loss: 3.4880131573677065
LOSS train 3.4880131573677065 valid 3.5491814613342285
EPOCH 474:
  batch 1000 loss: 3.482128622293472
LOSS train 3.482128622293472 valid 3.549304485321045
EPOCH 475:
  batch 1000 loss: 3.4965071325302124
LOSS train 3.4965071325302124 valid 3.549804925918579
EPOCH 476:
  batch 1000 loss: 3.4897521307468415
LOSS train 3.4897521307468415 valid 3.5494675636291504
EPOCH 477:
  batch 1000 loss: 3.489384612560272
LOSS train 3.489384612560272 valid 3.549311876296997
EPOCH 478:
  batch 1000 loss: 3.50052063703537
LOSS train 3.50052063703537 valid 3.549787759780884
EPOCH 479:
  batch 1000 loss: 3.5079193234443666
LOSS train 3.5079193234443666 valid 3.5497195720672607
EPOCH 480:
  batch 1000 loss: 3.493693167209625
LOSS train 3.493693167209625 valid 3.548858404159546
EPOCH 481:
  batch 1000 loss: 3.4868860495090486
LOSS train 3.4868860495090486 valid 3.5496327877044678
EPOCH 482:
  batch 1000 loss: 3.4872371015548707
LOSS train 3.4872371015548707 valid 3.5491321086883545
EPOCH 483:
  batch 1000 loss: 3.500589355945587
LOSS train 3.500589355945587 valid 3.5497896671295166
EPOCH 484:
  batch 1000 loss: 3.4956012363433837
LOSS train 3.4956012363433837 valid 3.5490753650665283
EPOCH 485:
  batch 1000 loss: 3.47981054353714
LOSS train 3.47981054353714 valid 3.549649477005005
EPOCH 486:
  batch 1000 loss: 3.488821252822876
LOSS train 3.488821252822876 valid 3.550405740737915
EPOCH 487:
  batch 1000 loss: 3.489334637403488
LOSS train 3.489334637403488 valid 3.54903244972229
EPOCH 488:
  batch 1000 loss: 3.4867151839733124
LOSS train 3.4867151839733124 valid 3.5499417781829834
EPOCH 489:
  batch 1000 loss: 3.4914326057434084
LOSS train 3.4914326057434084 valid 3.5491220951080322
EPOCH 490:
  batch 1000 loss: 3.4961356346607206
LOSS train 3.4961356346607206 valid 3.5497848987579346
EPOCH 491:
  batch 1000 loss: 3.5052017941474913
LOSS train 3.5052017941474913 valid 3.5496978759765625
EPOCH 492:
  batch 1000 loss: 3.5030190987586973
LOSS train 3.5030190987586973 valid 3.5490434169769287
EPOCH 493:
  batch 1000 loss: 3.4958210532665253
LOSS train 3.4958210532665253 valid 3.549758195877075
EPOCH 494:
  batch 1000 loss: 3.4783534440994264
LOSS train 3.4783534440994264 valid 3.549851417541504
EPOCH 495:
  batch 1000 loss: 3.48985667014122
LOSS train 3.48985667014122 valid 3.5491724014282227
EPOCH 496:
  batch 1000 loss: 3.490622675418854
LOSS train 3.490622675418854 valid 3.5497701168060303
EPOCH 497:
  batch 1000 loss: 3.5178641834259032
LOSS train 3.5178641834259032 valid 3.5494096279144287
EPOCH 498:
  batch 1000 loss: 3.4927721672058105
LOSS train 3.4927721672058105 valid 3.5494377613067627
EPOCH 499:
  batch 1000 loss: 3.5123929703235626
LOSS train 3.5123929703235626 valid 3.5493993759155273
EPOCH 500:
  batch 1000 loss: 3.491171740293503
LOSS train 3.491171740293503 valid 3.5498030185699463
