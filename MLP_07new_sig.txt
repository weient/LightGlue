nohup: ignoring input
EPOCH 1:
  batch 1000 loss: 6.2160995638370515
LOSS train 6.2160995638370515 valid 5.169179439544678
EPOCH 2:
  batch 1000 loss: 5.013288785219192
LOSS train 5.013288785219192 valid 4.8709492683410645
EPOCH 3:
  batch 1000 loss: 4.786116605997085
LOSS train 4.786116605997085 valid 4.659016132354736
EPOCH 4:
  batch 1000 loss: 4.5474012525081635
LOSS train 4.5474012525081635 valid 4.477088928222656
EPOCH 5:
  batch 1000 loss: 4.402555773258209
LOSS train 4.402555773258209 valid 4.361095428466797
EPOCH 6:
  batch 1000 loss: 4.28329177069664
LOSS train 4.28329177069664 valid 4.262076377868652
EPOCH 7:
  batch 1000 loss: 4.229368235111236
LOSS train 4.229368235111236 valid 4.217376232147217
EPOCH 8:
  batch 1000 loss: 4.148581289768219
LOSS train 4.148581289768219 valid 4.151259899139404
EPOCH 9:
  batch 1000 loss: 4.116926608800888
LOSS train 4.116926608800888 valid 4.100326061248779
EPOCH 10:
  batch 1000 loss: 4.072977089643478
LOSS train 4.072977089643478 valid 4.079363822937012
EPOCH 11:
  batch 1000 loss: 4.03298908829689
LOSS train 4.03298908829689 valid 4.031534671783447
EPOCH 12:
  batch 1000 loss: 4.0069114742279055
LOSS train 4.0069114742279055 valid 4.03119421005249
EPOCH 13:
  batch 1000 loss: 3.9893198959827423
LOSS train 3.9893198959827423 valid 3.995544672012329
EPOCH 14:
  batch 1000 loss: 3.9474987139701843
LOSS train 3.9474987139701843 valid 4.000234603881836
EPOCH 15:
  batch 1000 loss: 3.922758292198181
LOSS train 3.922758292198181 valid 3.9621477127075195
EPOCH 16:
  batch 1000 loss: 3.9366813259124758
LOSS train 3.9366813259124758 valid 3.943298101425171
EPOCH 17:
  batch 1000 loss: 3.9363004455566406
LOSS train 3.9363004455566406 valid 3.914041042327881
EPOCH 18:
  batch 1000 loss: 3.899747995376587
LOSS train 3.899747995376587 valid 3.938150644302368
EPOCH 19:
  batch 1000 loss: 3.873063662528992
LOSS train 3.873063662528992 valid 3.9109115600585938
EPOCH 20:
  batch 1000 loss: 3.8715069966316222
LOSS train 3.8715069966316222 valid 3.8952951431274414
EPOCH 21:
  batch 1000 loss: 3.8936386811733246
LOSS train 3.8936386811733246 valid 3.887861728668213
EPOCH 22:
  batch 1000 loss: 3.85691805934906
LOSS train 3.85691805934906 valid 3.924372911453247
EPOCH 23:
  batch 1000 loss: 3.85829224729538
LOSS train 3.85829224729538 valid 3.8736698627471924
EPOCH 24:
  batch 1000 loss: 3.8507218823432923
LOSS train 3.8507218823432923 valid 3.8697938919067383
EPOCH 25:
  batch 1000 loss: 3.83098295879364
LOSS train 3.83098295879364 valid 3.862151622772217
EPOCH 26:
  batch 1000 loss: 3.842604320049286
LOSS train 3.842604320049286 valid 3.8737998008728027
EPOCH 27:
  batch 1000 loss: 3.8277263317108154
LOSS train 3.8277263317108154 valid 3.8655409812927246
EPOCH 28:
  batch 1000 loss: 3.8224053242206573
LOSS train 3.8224053242206573 valid 3.84802508354187
EPOCH 29:
  batch 1000 loss: 3.800705278754234
LOSS train 3.800705278754234 valid 3.89109468460083
EPOCH 30:
  batch 1000 loss: 3.7922078741788865
LOSS train 3.7922078741788865 valid 3.8253064155578613
EPOCH 31:
  batch 1000 loss: 3.79335267329216
LOSS train 3.79335267329216 valid 3.8356945514678955
EPOCH 32:
  batch 1000 loss: 3.825810090780258
LOSS train 3.825810090780258 valid 3.847844362258911
EPOCH 33:
  batch 1000 loss: 3.7848438255786894
LOSS train 3.7848438255786894 valid 3.8101649284362793
EPOCH 34:
  batch 1000 loss: 3.7910241665840148
LOSS train 3.7910241665840148 valid 3.8024868965148926
EPOCH 35:
  batch 1000 loss: 3.780893187761307
LOSS train 3.780893187761307 valid 3.804070472717285
EPOCH 36:
  batch 1000 loss: 3.7833395416736604
LOSS train 3.7833395416736604 valid 3.8030481338500977
EPOCH 37:
  batch 1000 loss: 3.798972269773483
LOSS train 3.798972269773483 valid 3.7983951568603516
EPOCH 38:
  batch 1000 loss: 3.7452088372707366
LOSS train 3.7452088372707366 valid 3.786705732345581
EPOCH 39:
  batch 1000 loss: 3.7695745124816895
LOSS train 3.7695745124816895 valid 3.7996387481689453
EPOCH 40:
  batch 1000 loss: 3.7831660310029984
LOSS train 3.7831660310029984 valid 3.785912275314331
EPOCH 41:
  batch 1000 loss: 3.763258824586868
LOSS train 3.763258824586868 valid 3.772986888885498
EPOCH 42:
  batch 1000 loss: 3.7468324925899505
LOSS train 3.7468324925899505 valid 3.7920053005218506
EPOCH 43:
  batch 1000 loss: 3.786803252696991
LOSS train 3.786803252696991 valid 3.770272731781006
EPOCH 44:
  batch 1000 loss: 3.742536161184311
LOSS train 3.742536161184311 valid 3.7627410888671875
EPOCH 45:
  batch 1000 loss: 3.755612113118172
LOSS train 3.755612113118172 valid 3.7868988513946533
EPOCH 46:
  batch 1000 loss: 3.7636496949195863
LOSS train 3.7636496949195863 valid 3.8050849437713623
EPOCH 47:
  batch 1000 loss: 3.7395332437753677
LOSS train 3.7395332437753677 valid 3.768002986907959
EPOCH 48:
  batch 1000 loss: 3.7438823120594025
LOSS train 3.7438823120594025 valid 3.766096353530884
EPOCH 49:
  batch 1000 loss: 3.7603652231693268
LOSS train 3.7603652231693268 valid 3.7702629566192627
EPOCH 50:
  batch 1000 loss: 3.727041034579277
Epoch 00050: reducing learning rate of group 0 to 5.0000e-04.
LOSS train 3.727041034579277 valid 3.7718539237976074
EPOCH 51:
  batch 1000 loss: 3.6933834201097486
LOSS train 3.6933834201097486 valid 3.7129833698272705
EPOCH 52:
  batch 1000 loss: 3.7107917915582656
LOSS train 3.7107917915582656 valid 3.7222821712493896
EPOCH 53:
  batch 1000 loss: 3.6845482177734374
LOSS train 3.6845482177734374 valid 3.7066283226013184
EPOCH 54:
  batch 1000 loss: 3.673281177639961
LOSS train 3.673281177639961 valid 3.7165780067443848
EPOCH 55:
  batch 1000 loss: 3.6722361640930177
LOSS train 3.6722361640930177 valid 3.708001136779785
EPOCH 56:
  batch 1000 loss: 3.6592388998270033
LOSS train 3.6592388998270033 valid 3.715759038925171
EPOCH 57:
  batch 1000 loss: 3.6896313843727113
LOSS train 3.6896313843727113 valid 3.7076520919799805
EPOCH 58:
  batch 1000 loss: 3.650721343755722
LOSS train 3.650721343755722 valid 3.7017414569854736
EPOCH 59:
  batch 1000 loss: 3.6625945088863374
LOSS train 3.6625945088863374 valid 3.702767848968506
EPOCH 60:
  batch 1000 loss: 3.6703660333156587
LOSS train 3.6703660333156587 valid 3.706400156021118
EPOCH 61:
  batch 1000 loss: 3.6717074568271637
LOSS train 3.6717074568271637 valid 3.7107412815093994
EPOCH 62:
  batch 1000 loss: 3.6743585207462313
LOSS train 3.6743585207462313 valid 3.707531690597534
EPOCH 63:
  batch 1000 loss: 3.6640245312452318
LOSS train 3.6640245312452318 valid 3.7019119262695312
EPOCH 64:
  batch 1000 loss: 3.663605292916298
LOSS train 3.663605292916298 valid 3.6956787109375
EPOCH 65:
  batch 1000 loss: 3.6695179762840273
LOSS train 3.6695179762840273 valid 3.699425458908081
EPOCH 66:
  batch 1000 loss: 3.68879156935215
LOSS train 3.68879156935215 valid 3.6980044841766357
EPOCH 67:
  batch 1000 loss: 3.6736634709835054
LOSS train 3.6736634709835054 valid 3.7015936374664307
EPOCH 68:
  batch 1000 loss: 3.6437049988508226
LOSS train 3.6437049988508226 valid 3.6903398036956787
EPOCH 69:
  batch 1000 loss: 3.6351915942430497
LOSS train 3.6351915942430497 valid 3.692504644393921
EPOCH 70:
  batch 1000 loss: 3.6618172842264176
LOSS train 3.6618172842264176 valid 3.677584171295166
EPOCH 71:
  batch 1000 loss: 3.6587701369524
LOSS train 3.6587701369524 valid 3.68100905418396
EPOCH 72:
  batch 1000 loss: 3.6540001147985457
LOSS train 3.6540001147985457 valid 3.6893563270568848
EPOCH 73:
  batch 1000 loss: 3.630802736401558
LOSS train 3.630802736401558 valid 3.6770431995391846
EPOCH 74:
  batch 1000 loss: 3.6344753098487854
LOSS train 3.6344753098487854 valid 3.676452159881592
EPOCH 75:
  batch 1000 loss: 3.664693832397461
LOSS train 3.664693832397461 valid 3.676821231842041
EPOCH 76:
  batch 1000 loss: 3.6430765063762665
LOSS train 3.6430765063762665 valid 3.6691575050354004
EPOCH 77:
  batch 1000 loss: 3.6321791961193086
LOSS train 3.6321791961193086 valid 3.6787631511688232
EPOCH 78:
  batch 1000 loss: 3.6266480420827865
LOSS train 3.6266480420827865 valid 3.6756579875946045
EPOCH 79:
  batch 1000 loss: 3.6406589555740356
LOSS train 3.6406589555740356 valid 3.682664394378662
EPOCH 80:
  batch 1000 loss: 3.6456671862602232
LOSS train 3.6456671862602232 valid 3.6719768047332764
EPOCH 81:
  batch 1000 loss: 3.6458812675476073
LOSS train 3.6458812675476073 valid 3.6701033115386963
EPOCH 82:
  batch 1000 loss: 3.645792443037033
LOSS train 3.645792443037033 valid 3.6677494049072266
EPOCH 83:
  batch 1000 loss: 3.6325267083644865
LOSS train 3.6325267083644865 valid 3.669363260269165
EPOCH 84:
  batch 1000 loss: 3.6450293743610382
LOSS train 3.6450293743610382 valid 3.669970750808716
EPOCH 85:
  batch 1000 loss: 3.6272918487787247
LOSS train 3.6272918487787247 valid 3.6630165576934814
EPOCH 86:
  batch 1000 loss: 3.6385640033483506
LOSS train 3.6385640033483506 valid 3.664888620376587
EPOCH 87:
  batch 1000 loss: 3.629384479403496
LOSS train 3.629384479403496 valid 3.6677160263061523
EPOCH 88:
  batch 1000 loss: 3.616677940607071
LOSS train 3.616677940607071 valid 3.659233808517456
EPOCH 89:
  batch 1000 loss: 3.630346580028534
LOSS train 3.630346580028534 valid 3.6738810539245605
EPOCH 90:
  batch 1000 loss: 3.61807071018219
LOSS train 3.61807071018219 valid 3.663722276687622
EPOCH 91:
  batch 1000 loss: 3.6409480508565903
LOSS train 3.6409480508565903 valid 3.6635773181915283
EPOCH 92:
  batch 1000 loss: 3.6417525413036347
LOSS train 3.6417525413036347 valid 3.6544885635375977
EPOCH 93:
  batch 1000 loss: 3.61880340051651
LOSS train 3.61880340051651 valid 3.65799617767334
EPOCH 94:
  batch 1000 loss: 3.6385892577171326
LOSS train 3.6385892577171326 valid 3.6661453247070312
EPOCH 95:
  batch 1000 loss: 3.6389318680763245
LOSS train 3.6389318680763245 valid 3.650362253189087
EPOCH 96:
  batch 1000 loss: 3.6220659942626954
LOSS train 3.6220659942626954 valid 3.6615030765533447
EPOCH 97:
  batch 1000 loss: 3.6238484551906587
LOSS train 3.6238484551906587 valid 3.6617367267608643
EPOCH 98:
  batch 1000 loss: 3.6445145285129548
LOSS train 3.6445145285129548 valid 3.654891014099121
EPOCH 99:
  batch 1000 loss: 3.6315339368581774
LOSS train 3.6315339368581774 valid 3.6501386165618896
EPOCH 100:
  batch 1000 loss: 3.638236989974976
LOSS train 3.638236989974976 valid 3.6626570224761963
EPOCH 101:
  batch 1000 loss: 3.6293900451660157
LOSS train 3.6293900451660157 valid 3.6447818279266357
EPOCH 102:
  batch 1000 loss: 3.6335002276897432
LOSS train 3.6335002276897432 valid 3.6569747924804688
EPOCH 103:
  batch 1000 loss: 3.6200288763046267
LOSS train 3.6200288763046267 valid 3.657709836959839
EPOCH 104:
  batch 1000 loss: 3.628759190559387
LOSS train 3.628759190559387 valid 3.654144525527954
EPOCH 105:
  batch 1000 loss: 3.6229873567819597
LOSS train 3.6229873567819597 valid 3.6618521213531494
EPOCH 106:
  batch 1000 loss: 3.5978674285411834
LOSS train 3.5978674285411834 valid 3.6490941047668457
EPOCH 107:
  batch 1000 loss: 3.6043159663677216
Epoch 00107: reducing learning rate of group 0 to 2.5000e-04.
LOSS train 3.6043159663677216 valid 3.6518850326538086
EPOCH 108:
  batch 1000 loss: 3.611387406826019
LOSS train 3.611387406826019 valid 3.6227614879608154
EPOCH 109:
  batch 1000 loss: 3.6029293413162233
LOSS train 3.6029293413162233 valid 3.6243629455566406
EPOCH 110:
  batch 1000 loss: 3.600697991847992
LOSS train 3.600697991847992 valid 3.6221230030059814
EPOCH 111:
  batch 1000 loss: 3.5708912115097045
LOSS train 3.5708912115097045 valid 3.637800931930542
EPOCH 112:
  batch 1000 loss: 3.5954417773485186
LOSS train 3.5954417773485186 valid 3.6227829456329346
EPOCH 113:
  batch 1000 loss: 3.621228095293045
LOSS train 3.621228095293045 valid 3.6313791275024414
EPOCH 114:
  batch 1000 loss: 3.5896680114269257
LOSS train 3.5896680114269257 valid 3.6198482513427734
EPOCH 115:
  batch 1000 loss: 3.604805963277817
LOSS train 3.604805963277817 valid 3.6201348304748535
EPOCH 116:
  batch 1000 loss: 3.610288165330887
LOSS train 3.610288165330887 valid 3.6201319694519043
EPOCH 117:
  batch 1000 loss: 3.589044753193855
LOSS train 3.589044753193855 valid 3.6193535327911377
EPOCH 118:
  batch 1000 loss: 3.594178850889206
LOSS train 3.594178850889206 valid 3.616007089614868
EPOCH 119:
  batch 1000 loss: 3.5833721152544022
LOSS train 3.5833721152544022 valid 3.6166574954986572
EPOCH 120:
  batch 1000 loss: 3.574556066989899
LOSS train 3.574556066989899 valid 3.6144282817840576
EPOCH 121:
  batch 1000 loss: 3.5963520963191984
LOSS train 3.5963520963191984 valid 3.619389295578003
EPOCH 122:
  batch 1000 loss: 3.5819945018291475
LOSS train 3.5819945018291475 valid 3.6152968406677246
EPOCH 123:
  batch 1000 loss: 3.566434720158577
LOSS train 3.566434720158577 valid 3.6149349212646484
EPOCH 124:
  batch 1000 loss: 3.5746916472911834
LOSS train 3.5746916472911834 valid 3.6098039150238037
EPOCH 125:
  batch 1000 loss: 3.583983652353287
LOSS train 3.583983652353287 valid 3.608063220977783
EPOCH 126:
  batch 1000 loss: 3.603264747619629
LOSS train 3.603264747619629 valid 3.6112403869628906
EPOCH 127:
  batch 1000 loss: 3.570945718050003
LOSS train 3.570945718050003 valid 3.6141366958618164
EPOCH 128:
  batch 1000 loss: 3.5879008758068083
LOSS train 3.5879008758068083 valid 3.6125941276550293
EPOCH 129:
  batch 1000 loss: 3.592061125278473
LOSS train 3.592061125278473 valid 3.610011339187622
EPOCH 130:
  batch 1000 loss: 3.5904129960536957
LOSS train 3.5904129960536957 valid 3.611760139465332
EPOCH 131:
  batch 1000 loss: 3.5758627784252166
Epoch 00131: reducing learning rate of group 0 to 1.2500e-04.
LOSS train 3.5758627784252166 valid 3.610288619995117
EPOCH 132:
  batch 1000 loss: 3.589479362607002
LOSS train 3.589479362607002 valid 3.600280284881592
EPOCH 133:
  batch 1000 loss: 3.588029944181442
LOSS train 3.588029944181442 valid 3.5986692905426025
EPOCH 134:
  batch 1000 loss: 3.5687071170806886
LOSS train 3.5687071170806886 valid 3.597536087036133
EPOCH 135:
  batch 1000 loss: 3.5610186893939972
LOSS train 3.5610186893939972 valid 3.599837064743042
EPOCH 136:
  batch 1000 loss: 3.5734985119104383
LOSS train 3.5734985119104383 valid 3.6015524864196777
EPOCH 137:
  batch 1000 loss: 3.5807372903823853
LOSS train 3.5807372903823853 valid 3.6018283367156982
EPOCH 138:
  batch 1000 loss: 3.557359452724457
LOSS train 3.557359452724457 valid 3.597093343734741
EPOCH 139:
  batch 1000 loss: 3.564788294315338
LOSS train 3.564788294315338 valid 3.5964572429656982
EPOCH 140:
  batch 1000 loss: 3.5775578738451004
LOSS train 3.5775578738451004 valid 3.5983314514160156
EPOCH 141:
  batch 1000 loss: 3.5514478127956393
LOSS train 3.5514478127956393 valid 3.5932552814483643
EPOCH 142:
  batch 1000 loss: 3.5788152327537537
LOSS train 3.5788152327537537 valid 3.5959060192108154
EPOCH 143:
  batch 1000 loss: 3.570792031645775
LOSS train 3.570792031645775 valid 3.5969672203063965
EPOCH 144:
  batch 1000 loss: 3.5494909399747847
LOSS train 3.5494909399747847 valid 3.59741473197937
EPOCH 145:
  batch 1000 loss: 3.5673012974262237
LOSS train 3.5673012974262237 valid 3.5972158908843994
EPOCH 146:
  batch 1000 loss: 3.5854923642873766
LOSS train 3.5854923642873766 valid 3.5991835594177246
EPOCH 147:
  batch 1000 loss: 3.5723913736343382
Epoch 00147: reducing learning rate of group 0 to 6.2500e-05.
LOSS train 3.5723913736343382 valid 3.5946273803710938
EPOCH 148:
  batch 1000 loss: 3.5537939602136612
LOSS train 3.5537939602136612 valid 3.5922038555145264
EPOCH 149:
  batch 1000 loss: 3.5595036935806275
LOSS train 3.5595036935806275 valid 3.590816020965576
EPOCH 150:
  batch 1000 loss: 3.552158832550049
LOSS train 3.552158832550049 valid 3.5905425548553467
EPOCH 151:
  batch 1000 loss: 3.5474658888578414
LOSS train 3.5474658888578414 valid 3.589682102203369
EPOCH 152:
  batch 1000 loss: 3.5592894432544706
LOSS train 3.5592894432544706 valid 3.5914058685302734
EPOCH 153:
  batch 1000 loss: 3.5454508041143415
LOSS train 3.5454508041143415 valid 3.5899498462677
EPOCH 154:
  batch 1000 loss: 3.5377987179756163
LOSS train 3.5377987179756163 valid 3.5908429622650146
EPOCH 155:
  batch 1000 loss: 3.572503278851509
LOSS train 3.572503278851509 valid 3.591592788696289
EPOCH 156:
  batch 1000 loss: 3.5640423805713652
LOSS train 3.5640423805713652 valid 3.590562582015991
EPOCH 157:
  batch 1000 loss: 3.5591341294050216
Epoch 00157: reducing learning rate of group 0 to 3.1250e-05.
LOSS train 3.5591341294050216 valid 3.5910933017730713
EPOCH 158:
  batch 1000 loss: 3.5502803041934965
LOSS train 3.5502803041934965 valid 3.5865285396575928
EPOCH 159:
  batch 1000 loss: 3.551669294953346
LOSS train 3.551669294953346 valid 3.587009906768799
EPOCH 160:
  batch 1000 loss: 3.548790158390999
LOSS train 3.548790158390999 valid 3.5877609252929688
EPOCH 161:
  batch 1000 loss: 3.5481486679315566
LOSS train 3.5481486679315566 valid 3.5878288745880127
EPOCH 162:
  batch 1000 loss: 3.549614628314972
LOSS train 3.549614628314972 valid 3.5878560543060303
EPOCH 163:
  batch 1000 loss: 3.548891764163971
LOSS train 3.548891764163971 valid 3.587599277496338
EPOCH 164:
  batch 1000 loss: 3.5517821469306945
Epoch 00164: reducing learning rate of group 0 to 1.5625e-05.
LOSS train 3.5517821469306945 valid 3.5881614685058594
EPOCH 165:
  batch 1000 loss: 3.54549637055397
LOSS train 3.54549637055397 valid 3.586648464202881
EPOCH 166:
  batch 1000 loss: 3.5682141370773315
LOSS train 3.5682141370773315 valid 3.586244583129883
EPOCH 167:
  batch 1000 loss: 3.559968246459961
LOSS train 3.559968246459961 valid 3.5876119136810303
EPOCH 168:
  batch 1000 loss: 3.555906416416168
LOSS train 3.555906416416168 valid 3.586956262588501
EPOCH 169:
  batch 1000 loss: 3.5425507823228837
LOSS train 3.5425507823228837 valid 3.5865025520324707
EPOCH 170:
  batch 1000 loss: 3.543208331823349
Epoch 00170: reducing learning rate of group 0 to 7.8125e-06.
LOSS train 3.543208331823349 valid 3.5870394706726074
EPOCH 171:
  batch 1000 loss: 3.5487278336286545
LOSS train 3.5487278336286545 valid 3.5862700939178467
EPOCH 172:
  batch 1000 loss: 3.540995980143547
LOSS train 3.540995980143547 valid 3.585597515106201
EPOCH 173:
  batch 1000 loss: 3.564655904054642
LOSS train 3.564655904054642 valid 3.586108922958374
EPOCH 174:
  batch 1000 loss: 3.560239047050476
LOSS train 3.560239047050476 valid 3.585192918777466
EPOCH 175:
  batch 1000 loss: 3.5541153160333634
LOSS train 3.5541153160333634 valid 3.586458444595337
EPOCH 176:
  batch 1000 loss: 3.557065438747406
LOSS train 3.557065438747406 valid 3.585197925567627
EPOCH 177:
  batch 1000 loss: 3.570218551516533
LOSS train 3.570218551516533 valid 3.5848801136016846
EPOCH 178:
  batch 1000 loss: 3.55284627532959
LOSS train 3.55284627532959 valid 3.584920883178711
EPOCH 179:
  batch 1000 loss: 3.54856161403656
LOSS train 3.54856161403656 valid 3.5858945846557617
EPOCH 180:
  batch 1000 loss: 3.549983354091644
Epoch 00180: reducing learning rate of group 0 to 3.9063e-06.
LOSS train 3.549983354091644 valid 3.586339235305786
EPOCH 181:
  batch 1000 loss: 3.5415421240329743
LOSS train 3.5415421240329743 valid 3.5854883193969727
EPOCH 182:
  batch 1000 loss: 3.545232965230942
LOSS train 3.545232965230942 valid 3.585627794265747
EPOCH 183:
  batch 1000 loss: 3.5467540389299392
LOSS train 3.5467540389299392 valid 3.585221529006958
EPOCH 184:
  batch 1000 loss: 3.5510976585149767
LOSS train 3.5510976585149767 valid 3.585719585418701
EPOCH 185:
  batch 1000 loss: 3.554671983838081
LOSS train 3.554671983838081 valid 3.584928512573242
EPOCH 186:
  batch 1000 loss: 3.559140626192093
Epoch 00186: reducing learning rate of group 0 to 1.9531e-06.
LOSS train 3.559140626192093 valid 3.5867068767547607
EPOCH 187:
  batch 1000 loss: 3.563019200563431
LOSS train 3.563019200563431 valid 3.584991216659546
EPOCH 188:
  batch 1000 loss: 3.5552580418586732
LOSS train 3.5552580418586732 valid 3.584674835205078
EPOCH 189:
  batch 1000 loss: 3.5487051438093187
LOSS train 3.5487051438093187 valid 3.5843019485473633
EPOCH 190:
  batch 1000 loss: 3.5326228647232054
LOSS train 3.5326228647232054 valid 3.5855612754821777
EPOCH 191:
  batch 1000 loss: 3.558210435628891
LOSS train 3.558210435628891 valid 3.5855979919433594
EPOCH 192:
  batch 1000 loss: 3.5510332020521163
LOSS train 3.5510332020521163 valid 3.5848679542541504
EPOCH 193:
  batch 1000 loss: 3.5198724714517593
LOSS train 3.5198724714517593 valid 3.5860249996185303
EPOCH 194:
  batch 1000 loss: 3.5553065314292907
LOSS train 3.5553065314292907 valid 3.5859944820404053
EPOCH 195:
  batch 1000 loss: 3.528433045387268
Epoch 00195: reducing learning rate of group 0 to 9.7656e-07.
LOSS train 3.528433045387268 valid 3.584592580795288
EPOCH 196:
  batch 1000 loss: 3.5348642508983614
LOSS train 3.5348642508983614 valid 3.585301399230957
EPOCH 197:
  batch 1000 loss: 3.559137863278389
LOSS train 3.559137863278389 valid 3.585413694381714
EPOCH 198:
  batch 1000 loss: 3.551571631193161
LOSS train 3.551571631193161 valid 3.5854575634002686
EPOCH 199:
  batch 1000 loss: 3.54056328356266
LOSS train 3.54056328356266 valid 3.585472822189331
EPOCH 200:
  batch 1000 loss: 3.5431170954704285
LOSS train 3.5431170954704285 valid 3.586439847946167
EPOCH 201:
  batch 1000 loss: 3.5532416216135023
Epoch 00201: reducing learning rate of group 0 to 4.8828e-07.
LOSS train 3.5532416216135023 valid 3.5848400592803955
EPOCH 202:
  batch 1000 loss: 3.548782259464264
LOSS train 3.548782259464264 valid 3.5869693756103516
EPOCH 203:
  batch 1000 loss: 3.5393749836683273
LOSS train 3.5393749836683273 valid 3.584737777709961
EPOCH 204:
  batch 1000 loss: 3.5624779767990113
LOSS train 3.5624779767990113 valid 3.5858631134033203
EPOCH 205:
  batch 1000 loss: 3.54720809006691
LOSS train 3.54720809006691 valid 3.5856285095214844
EPOCH 206:
  batch 1000 loss: 3.54194914162159
LOSS train 3.54194914162159 valid 3.5845260620117188
EPOCH 207:
  batch 1000 loss: 3.5543317111730577
Epoch 00207: reducing learning rate of group 0 to 2.4414e-07.
LOSS train 3.5543317111730577 valid 3.5855231285095215
EPOCH 208:
  batch 1000 loss: 3.5410531122684477
LOSS train 3.5410531122684477 valid 3.5851428508758545
EPOCH 209:
  batch 1000 loss: 3.559403862118721
LOSS train 3.559403862118721 valid 3.5854568481445312
EPOCH 210:
  batch 1000 loss: 3.5605496364831923
LOSS train 3.5605496364831923 valid 3.585056781768799
EPOCH 211:
  batch 1000 loss: 3.542136022806168
LOSS train 3.542136022806168 valid 3.5852432250976562
EPOCH 212:
  batch 1000 loss: 3.5477767078876496
LOSS train 3.5477767078876496 valid 3.5861711502075195
EPOCH 213:
  batch 1000 loss: 3.541386239051819
Epoch 00213: reducing learning rate of group 0 to 1.2207e-07.
LOSS train 3.541386239051819 valid 3.5854742527008057
EPOCH 214:
  batch 1000 loss: 3.5328640151023865
LOSS train 3.5328640151023865 valid 3.5856990814208984
EPOCH 215:
  batch 1000 loss: 3.528190682172775
LOSS train 3.528190682172775 valid 3.585669994354248
EPOCH 216:
  batch 1000 loss: 3.5592291513681413
LOSS train 3.5592291513681413 valid 3.5856921672821045
EPOCH 217:
  batch 1000 loss: 3.5405693118572237
LOSS train 3.5405693118572237 valid 3.5848822593688965
EPOCH 218:
  batch 1000 loss: 3.552451130390167
LOSS train 3.552451130390167 valid 3.5854344367980957
EPOCH 219:
  batch 1000 loss: 3.534655075073242
Epoch 00219: reducing learning rate of group 0 to 6.1035e-08.
LOSS train 3.534655075073242 valid 3.585789680480957
EPOCH 220:
  batch 1000 loss: 3.5403300161361693
LOSS train 3.5403300161361693 valid 3.584995746612549
EPOCH 221:
  batch 1000 loss: 3.54337197637558
LOSS train 3.54337197637558 valid 3.5853917598724365
EPOCH 222:
  batch 1000 loss: 3.5554644474983217
LOSS train 3.5554644474983217 valid 3.586411952972412
EPOCH 223:
  batch 1000 loss: 3.5688251913785933
LOSS train 3.5688251913785933 valid 3.5855624675750732
EPOCH 224:
  batch 1000 loss: 3.5487538186311722
LOSS train 3.5487538186311722 valid 3.5859405994415283
EPOCH 225:
  batch 1000 loss: 3.5421852548122406
Epoch 00225: reducing learning rate of group 0 to 3.0518e-08.
LOSS train 3.5421852548122406 valid 3.5856611728668213
EPOCH 226:
  batch 1000 loss: 3.528771211385727
LOSS train 3.528771211385727 valid 3.5857059955596924
EPOCH 227:
  batch 1000 loss: 3.5428779455423354
LOSS train 3.5428779455423354 valid 3.584996461868286
EPOCH 228:
  batch 1000 loss: 3.5296742671728136
LOSS train 3.5296742671728136 valid 3.585850954055786
EPOCH 229:
  batch 1000 loss: 3.5530437639951704
LOSS train 3.5530437639951704 valid 3.585487127304077
EPOCH 230:
  batch 1000 loss: 3.5333084778785704
LOSS train 3.5333084778785704 valid 3.585348606109619
EPOCH 231:
  batch 1000 loss: 3.572183223724365
Epoch 00231: reducing learning rate of group 0 to 1.5259e-08.
LOSS train 3.572183223724365 valid 3.584744930267334
EPOCH 232:
  batch 1000 loss: 3.5273171644210817
LOSS train 3.5273171644210817 valid 3.585683822631836
EPOCH 233:
  batch 1000 loss: 3.5404069578647612
LOSS train 3.5404069578647612 valid 3.5852930545806885
EPOCH 234:
  batch 1000 loss: 3.5365276592969894
LOSS train 3.5365276592969894 valid 3.584491014480591
EPOCH 235:
  batch 1000 loss: 3.5591342623233797
LOSS train 3.5591342623233797 valid 3.5857536792755127
EPOCH 236:
  batch 1000 loss: 3.559515455007553
LOSS train 3.559515455007553 valid 3.5859909057617188
EPOCH 237:
  batch 1000 loss: 3.551465573310852
LOSS train 3.551465573310852 valid 3.5851781368255615
EPOCH 238:
  batch 1000 loss: 3.546146006464958
LOSS train 3.546146006464958 valid 3.586315393447876
EPOCH 239:
  batch 1000 loss: 3.5281908025741577
LOSS train 3.5281908025741577 valid 3.585282564163208
EPOCH 240:
  batch 1000 loss: 3.5456408284902574
LOSS train 3.5456408284902574 valid 3.5857741832733154
EPOCH 241:
  batch 1000 loss: 3.517751929998398
LOSS train 3.517751929998398 valid 3.585733652114868
EPOCH 242:
  batch 1000 loss: 3.551595108628273
LOSS train 3.551595108628273 valid 3.586209774017334
EPOCH 243:
  batch 1000 loss: 3.5560603103637694
LOSS train 3.5560603103637694 valid 3.5855355262756348
EPOCH 244:
  batch 1000 loss: 3.537817425608635
LOSS train 3.537817425608635 valid 3.5855090618133545
EPOCH 245:
  batch 1000 loss: 3.5373848848342897
LOSS train 3.5373848848342897 valid 3.5867369174957275
EPOCH 246:
  batch 1000 loss: 3.5406696305274963
LOSS train 3.5406696305274963 valid 3.5848324298858643
EPOCH 247:
  batch 1000 loss: 3.547162449359894
LOSS train 3.547162449359894 valid 3.58567214012146
EPOCH 248:
  batch 1000 loss: 3.555782160639763
LOSS train 3.555782160639763 valid 3.585150957107544
EPOCH 249:
  batch 1000 loss: 3.559142475605011
LOSS train 3.559142475605011 valid 3.5857224464416504
EPOCH 250:
  batch 1000 loss: 3.5546709234714506
LOSS train 3.5546709234714506 valid 3.5855681896209717
EPOCH 251:
  batch 1000 loss: 3.5401595546007156
LOSS train 3.5401595546007156 valid 3.5843851566314697
EPOCH 252:
  batch 1000 loss: 3.56036572265625
LOSS train 3.56036572265625 valid 3.585747241973877
EPOCH 253:
  batch 1000 loss: 3.529380673289299
LOSS train 3.529380673289299 valid 3.585505485534668
EPOCH 254:
  batch 1000 loss: 3.534304096221924
LOSS train 3.534304096221924 valid 3.586540460586548
EPOCH 255:
  batch 1000 loss: 3.5597994965314865
LOSS train 3.5597994965314865 valid 3.5855369567871094
EPOCH 256:
  batch 1000 loss: 3.543490086555481
LOSS train 3.543490086555481 valid 3.5852108001708984
EPOCH 257:
  batch 1000 loss: 3.5524242988824843
LOSS train 3.5524242988824843 valid 3.5855777263641357
EPOCH 258:
  batch 1000 loss: 3.5330095006227493
LOSS train 3.5330095006227493 valid 3.5854976177215576
EPOCH 259:
  batch 1000 loss: 3.533178339242935
LOSS train 3.533178339242935 valid 3.5853495597839355
EPOCH 260:
  batch 1000 loss: 3.519005439400673
LOSS train 3.519005439400673 valid 3.5858447551727295
EPOCH 261:
  batch 1000 loss: 3.5425443543195723
LOSS train 3.5425443543195723 valid 3.586036205291748
EPOCH 262:
  batch 1000 loss: 3.560797788619995
LOSS train 3.560797788619995 valid 3.5860400199890137
EPOCH 263:
  batch 1000 loss: 3.5389034638404846
LOSS train 3.5389034638404846 valid 3.585941791534424
EPOCH 264:
  batch 1000 loss: 3.5581290719509124
LOSS train 3.5581290719509124 valid 3.5864055156707764
EPOCH 265:
  batch 1000 loss: 3.5417485460042952
LOSS train 3.5417485460042952 valid 3.5863149166107178
EPOCH 266:
  batch 1000 loss: 3.5595546542406082
LOSS train 3.5595546542406082 valid 3.586853265762329
EPOCH 267:
  batch 1000 loss: 3.5570823286771773
LOSS train 3.5570823286771773 valid 3.5840375423431396
EPOCH 268:
  batch 1000 loss: 3.5343278890848158
LOSS train 3.5343278890848158 valid 3.5858328342437744
EPOCH 269:
  batch 1000 loss: 3.5517273606061934
LOSS train 3.5517273606061934 valid 3.586435556411743
EPOCH 270:
  batch 1000 loss: 3.5502051248550415
LOSS train 3.5502051248550415 valid 3.585022211074829
EPOCH 271:
  batch 1000 loss: 3.55531688284874
LOSS train 3.55531688284874 valid 3.586577892303467
EPOCH 272:
  batch 1000 loss: 3.5419604251384733
LOSS train 3.5419604251384733 valid 3.5857324600219727
EPOCH 273:
  batch 1000 loss: 3.5363883229494095
LOSS train 3.5363883229494095 valid 3.585510015487671
EPOCH 274:
  batch 1000 loss: 3.5462333762645724
LOSS train 3.5462333762645724 valid 3.5852158069610596
EPOCH 275:
  batch 1000 loss: 3.538603281021118
LOSS train 3.538603281021118 valid 3.58622145652771
EPOCH 276:
  batch 1000 loss: 3.5396614426374438
LOSS train 3.5396614426374438 valid 3.585228681564331
EPOCH 277:
  batch 1000 loss: 3.5410603147745134
LOSS train 3.5410603147745134 valid 3.58540940284729
EPOCH 278:
  batch 1000 loss: 3.530620859861374
LOSS train 3.530620859861374 valid 3.585773229598999
EPOCH 279:
  batch 1000 loss: 3.5343429584503174
LOSS train 3.5343429584503174 valid 3.5854709148406982
EPOCH 280:
  batch 1000 loss: 3.5820037350654603
LOSS train 3.5820037350654603 valid 3.584970712661743
EPOCH 281:
  batch 1000 loss: 3.53492592549324
LOSS train 3.53492592549324 valid 3.5853638648986816
EPOCH 282:
  batch 1000 loss: 3.5554382135868074
LOSS train 3.5554382135868074 valid 3.5848538875579834
EPOCH 283:
  batch 1000 loss: 3.5523188410997393
LOSS train 3.5523188410997393 valid 3.5859930515289307
EPOCH 284:
  batch 1000 loss: 3.541271427154541
LOSS train 3.541271427154541 valid 3.585301399230957
EPOCH 285:
  batch 1000 loss: 3.5459751222133638
LOSS train 3.5459751222133638 valid 3.585437536239624
EPOCH 286:
  batch 1000 loss: 3.5501073367595675
LOSS train 3.5501073367595675 valid 3.586388349533081
EPOCH 287:
  batch 1000 loss: 3.5492321710586547
LOSS train 3.5492321710586547 valid 3.5855250358581543
EPOCH 288:
  batch 1000 loss: 3.534215410351753
LOSS train 3.534215410351753 valid 3.5860595703125
EPOCH 289:
  batch 1000 loss: 3.5533370788097383
LOSS train 3.5533370788097383 valid 3.58542799949646
EPOCH 290:
  batch 1000 loss: 3.564929615497589
LOSS train 3.564929615497589 valid 3.5853943824768066
EPOCH 291:
  batch 1000 loss: 3.5416219663619994
LOSS train 3.5416219663619994 valid 3.5843024253845215
EPOCH 292:
  batch 1000 loss: 3.5487820813655855
LOSS train 3.5487820813655855 valid 3.5855705738067627
EPOCH 293:
  batch 1000 loss: 3.54114897108078
LOSS train 3.54114897108078 valid 3.585806131362915
EPOCH 294:
  batch 1000 loss: 3.546822165846825
LOSS train 3.546822165846825 valid 3.5853631496429443
EPOCH 295:
  batch 1000 loss: 3.5621821216344833
LOSS train 3.5621821216344833 valid 3.58559513092041
EPOCH 296:
  batch 1000 loss: 3.565289582490921
LOSS train 3.565289582490921 valid 3.586115598678589
EPOCH 297:
  batch 1000 loss: 3.555166466355324
LOSS train 3.555166466355324 valid 3.585892915725708
EPOCH 298:
  batch 1000 loss: 3.553227809548378
LOSS train 3.553227809548378 valid 3.5859107971191406
EPOCH 299:
  batch 1000 loss: 3.5672705686092376
LOSS train 3.5672705686092376 valid 3.5843799114227295
EPOCH 300:
  batch 1000 loss: 3.5637423129081727
LOSS train 3.5637423129081727 valid 3.5857255458831787
EPOCH 301:
  batch 1000 loss: 3.527895532131195
LOSS train 3.527895532131195 valid 3.585545539855957
EPOCH 302:
  batch 1000 loss: 3.5372372682094575
LOSS train 3.5372372682094575 valid 3.585439443588257
EPOCH 303:
  batch 1000 loss: 3.5323319044113157
LOSS train 3.5323319044113157 valid 3.5845465660095215
EPOCH 304:
  batch 1000 loss: 3.5253971598148346
LOSS train 3.5253971598148346 valid 3.5855209827423096
EPOCH 305:
  batch 1000 loss: 3.539698406100273
LOSS train 3.539698406100273 valid 3.585165023803711
EPOCH 306:
  batch 1000 loss: 3.544479059457779
LOSS train 3.544479059457779 valid 3.585270881652832
EPOCH 307:
  batch 1000 loss: 3.5571541321277618
LOSS train 3.5571541321277618 valid 3.5848116874694824
EPOCH 308:
  batch 1000 loss: 3.550639246582985
LOSS train 3.550639246582985 valid 3.5849392414093018
EPOCH 309:
  batch 1000 loss: 3.5527845937013627
LOSS train 3.5527845937013627 valid 3.585317850112915
EPOCH 310:
  batch 1000 loss: 3.552811929702759
LOSS train 3.552811929702759 valid 3.5848262310028076
EPOCH 311:
  batch 1000 loss: 3.5651189744472505
LOSS train 3.5651189744472505 valid 3.5848770141601562
EPOCH 312:
  batch 1000 loss: 3.557490399122238
LOSS train 3.557490399122238 valid 3.5850343704223633
EPOCH 313:
  batch 1000 loss: 3.5403461080789564
LOSS train 3.5403461080789564 valid 3.58591890335083
EPOCH 314:
  batch 1000 loss: 3.552218853712082
LOSS train 3.552218853712082 valid 3.585484027862549
EPOCH 315:
  batch 1000 loss: 3.5506317608356475
LOSS train 3.5506317608356475 valid 3.5852925777435303
EPOCH 316:
  batch 1000 loss: 3.5433228385448454
LOSS train 3.5433228385448454 valid 3.5858066082000732
EPOCH 317:
  batch 1000 loss: 3.557606585741043
LOSS train 3.557606585741043 valid 3.5854110717773438
EPOCH 318:
  batch 1000 loss: 3.527740346670151
LOSS train 3.527740346670151 valid 3.585792064666748
EPOCH 319:
  batch 1000 loss: 3.542907653093338
LOSS train 3.542907653093338 valid 3.5855207443237305
EPOCH 320:
  batch 1000 loss: 3.539949612379074
LOSS train 3.539949612379074 valid 3.5856127738952637
EPOCH 321:
  batch 1000 loss: 3.546927978157997
LOSS train 3.546927978157997 valid 3.584486961364746
EPOCH 322:
  batch 1000 loss: 3.556489553332329
LOSS train 3.556489553332329 valid 3.585763931274414
EPOCH 323:
  batch 1000 loss: 3.539133054733276
LOSS train 3.539133054733276 valid 3.585510492324829
EPOCH 324:
  batch 1000 loss: 3.5404190511703493
LOSS train 3.5404190511703493 valid 3.5848324298858643
EPOCH 325:
  batch 1000 loss: 3.5383038859367373
LOSS train 3.5383038859367373 valid 3.5845439434051514
EPOCH 326:
  batch 1000 loss: 3.541121328115463
LOSS train 3.541121328115463 valid 3.5853919982910156
EPOCH 327:
  batch 1000 loss: 3.551095042228699
LOSS train 3.551095042228699 valid 3.5857019424438477
EPOCH 328:
  batch 1000 loss: 3.543384560585022
LOSS train 3.543384560585022 valid 3.584726333618164
EPOCH 329:
  batch 1000 loss: 3.5443433570861815
LOSS train 3.5443433570861815 valid 3.585789203643799
EPOCH 330:
  batch 1000 loss: 3.556633780360222
LOSS train 3.556633780360222 valid 3.585394859313965
EPOCH 331:
  batch 1000 loss: 3.55359588098526
LOSS train 3.55359588098526 valid 3.5854523181915283
EPOCH 332:
  batch 1000 loss: 3.555677583217621
LOSS train 3.555677583217621 valid 3.586181879043579
EPOCH 333:
  batch 1000 loss: 3.5530867989063264
LOSS train 3.5530867989063264 valid 3.585266590118408
EPOCH 334:
  batch 1000 loss: 3.5437667607069017
LOSS train 3.5437667607069017 valid 3.584531307220459
EPOCH 335:
  batch 1000 loss: 3.554732422232628
LOSS train 3.554732422232628 valid 3.5853497982025146
EPOCH 336:
  batch 1000 loss: 3.5514781959056854
LOSS train 3.5514781959056854 valid 3.5856947898864746
EPOCH 337:
  batch 1000 loss: 3.547786147713661
LOSS train 3.547786147713661 valid 3.5854110717773438
EPOCH 338:
  batch 1000 loss: 3.544640344142914
LOSS train 3.544640344142914 valid 3.5853543281555176
EPOCH 339:
  batch 1000 loss: 3.547680421590805
LOSS train 3.547680421590805 valid 3.5858662128448486
EPOCH 340:
  batch 1000 loss: 3.546672372341156
LOSS train 3.546672372341156 valid 3.585259437561035
EPOCH 341:
  batch 1000 loss: 3.559872698068619
LOSS train 3.559872698068619 valid 3.5848867893218994
EPOCH 342:
  batch 1000 loss: 3.563284541606903
LOSS train 3.563284541606903 valid 3.5855400562286377
EPOCH 343:
  batch 1000 loss: 3.5568395273685454
LOSS train 3.5568395273685454 valid 3.5853748321533203
EPOCH 344:
  batch 1000 loss: 3.5501231710910797
LOSS train 3.5501231710910797 valid 3.584871768951416
EPOCH 345:
  batch 1000 loss: 3.561093489408493
LOSS train 3.561093489408493 valid 3.58530592918396
EPOCH 346:
  batch 1000 loss: 3.54228418302536
LOSS train 3.54228418302536 valid 3.585509777069092
EPOCH 347:
  batch 1000 loss: 3.5322140966653826
LOSS train 3.5322140966653826 valid 3.584519147872925
EPOCH 348:
  batch 1000 loss: 3.5476893435716628
LOSS train 3.5476893435716628 valid 3.5855817794799805
EPOCH 349:
  batch 1000 loss: 3.561497948050499
LOSS train 3.561497948050499 valid 3.5848727226257324
EPOCH 350:
  batch 1000 loss: 3.553575103402138
LOSS train 3.553575103402138 valid 3.586646556854248
EPOCH 351:
  batch 1000 loss: 3.562426125407219
LOSS train 3.562426125407219 valid 3.586148500442505
EPOCH 352:
  batch 1000 loss: 3.5842453763484956
LOSS train 3.5842453763484956 valid 3.585639476776123
EPOCH 353:
  batch 1000 loss: 3.535988352894783
LOSS train 3.535988352894783 valid 3.58481502532959
EPOCH 354:
  batch 1000 loss: 3.543101591825485
LOSS train 3.543101591825485 valid 3.586155414581299
EPOCH 355:
  batch 1000 loss: 3.5395144027471543
LOSS train 3.5395144027471543 valid 3.5858168601989746
EPOCH 356:
  batch 1000 loss: 3.5575360119342805
LOSS train 3.5575360119342805 valid 3.586202621459961
EPOCH 357:
  batch 1000 loss: 3.557531541824341
LOSS train 3.557531541824341 valid 3.5862107276916504
EPOCH 358:
  batch 1000 loss: 3.5383579747676848
LOSS train 3.5383579747676848 valid 3.5852935314178467
EPOCH 359:
  batch 1000 loss: 3.5432226499319075
LOSS train 3.5432226499319075 valid 3.5866668224334717
EPOCH 360:
  batch 1000 loss: 3.5412705179452897
LOSS train 3.5412705179452897 valid 3.5854032039642334
EPOCH 361:
  batch 1000 loss: 3.526496756196022
LOSS train 3.526496756196022 valid 3.585503101348877
EPOCH 362:
  batch 1000 loss: 3.5447590074539184
LOSS train 3.5447590074539184 valid 3.5845818519592285
EPOCH 363:
  batch 1000 loss: 3.554141778945923
LOSS train 3.554141778945923 valid 3.5848400592803955
EPOCH 364:
  batch 1000 loss: 3.550344119787216
LOSS train 3.550344119787216 valid 3.5844433307647705
EPOCH 365:
  batch 1000 loss: 3.5475558106899263
LOSS train 3.5475558106899263 valid 3.586183547973633
EPOCH 366:
  batch 1000 loss: 3.560053811073303
LOSS train 3.560053811073303 valid 3.585268497467041
EPOCH 367:
  batch 1000 loss: 3.535485607981682
LOSS train 3.535485607981682 valid 3.5857245922088623
EPOCH 368:
  batch 1000 loss: 3.55817165851593
LOSS train 3.55817165851593 valid 3.5854902267456055
EPOCH 369:
  batch 1000 loss: 3.548470860004425
LOSS train 3.548470860004425 valid 3.584785223007202
EPOCH 370:
  batch 1000 loss: 3.5638554871082304
LOSS train 3.5638554871082304 valid 3.585831642150879
EPOCH 371:
  batch 1000 loss: 3.544066842675209
LOSS train 3.544066842675209 valid 3.5843751430511475
EPOCH 372:
  batch 1000 loss: 3.550623550057411
LOSS train 3.550623550057411 valid 3.585299015045166
EPOCH 373:
  batch 1000 loss: 3.5488508813381197
LOSS train 3.5488508813381197 valid 3.586122512817383
EPOCH 374:
  batch 1000 loss: 3.5423302434682844
LOSS train 3.5423302434682844 valid 3.585379123687744
EPOCH 375:
  batch 1000 loss: 3.5303790493011475
LOSS train 3.5303790493011475 valid 3.5858964920043945
EPOCH 376:
  batch 1000 loss: 3.5514432199001313
LOSS train 3.5514432199001313 valid 3.5857772827148438
EPOCH 377:
  batch 1000 loss: 3.5408506606817247
LOSS train 3.5408506606817247 valid 3.585705280303955
EPOCH 378:
  batch 1000 loss: 3.541331382036209
LOSS train 3.541331382036209 valid 3.5853729248046875
EPOCH 379:
  batch 1000 loss: 3.5626830797195437
LOSS train 3.5626830797195437 valid 3.5857455730438232
EPOCH 380:
  batch 1000 loss: 3.546778102874756
LOSS train 3.546778102874756 valid 3.585134744644165
EPOCH 381:
  batch 1000 loss: 3.5458230100870134
LOSS train 3.5458230100870134 valid 3.585599422454834
EPOCH 382:
  batch 1000 loss: 3.5412927026748657
LOSS train 3.5412927026748657 valid 3.585069417953491
EPOCH 383:
  batch 1000 loss: 3.5471968080997467
LOSS train 3.5471968080997467 valid 3.5855281352996826
EPOCH 384:
  batch 1000 loss: 3.5461908575296404
LOSS train 3.5461908575296404 valid 3.5852713584899902
EPOCH 385:
  batch 1000 loss: 3.5435281207561493
LOSS train 3.5435281207561493 valid 3.586118698120117
EPOCH 386:
  batch 1000 loss: 3.5596884895563123
LOSS train 3.5596884895563123 valid 3.5854299068450928
EPOCH 387:
  batch 1000 loss: 3.546836533665657
LOSS train 3.546836533665657 valid 3.5853641033172607
EPOCH 388:
  batch 1000 loss: 3.5535143632888793
LOSS train 3.5535143632888793 valid 3.585418939590454
EPOCH 389:
  batch 1000 loss: 3.544366651415825
LOSS train 3.544366651415825 valid 3.58528208732605
EPOCH 390:
  batch 1000 loss: 3.555640388846397
LOSS train 3.555640388846397 valid 3.5853021144866943
EPOCH 391:
  batch 1000 loss: 3.5237271218299866
LOSS train 3.5237271218299866 valid 3.5854599475860596
EPOCH 392:
  batch 1000 loss: 3.536051658153534
LOSS train 3.536051658153534 valid 3.585120916366577
EPOCH 393:
  batch 1000 loss: 3.5607772965431215
LOSS train 3.5607772965431215 valid 3.585827112197876
EPOCH 394:
  batch 1000 loss: 3.546385141134262
LOSS train 3.546385141134262 valid 3.586031436920166
EPOCH 395:
  batch 1000 loss: 3.543740177512169
LOSS train 3.543740177512169 valid 3.5859503746032715
EPOCH 396:
  batch 1000 loss: 3.553477086544037
LOSS train 3.553477086544037 valid 3.5861997604370117
EPOCH 397:
  batch 1000 loss: 3.5405602810382844
LOSS train 3.5405602810382844 valid 3.5855562686920166
EPOCH 398:
  batch 1000 loss: 3.551116631150246
LOSS train 3.551116631150246 valid 3.586668014526367
EPOCH 399:
  batch 1000 loss: 3.546265888214111
LOSS train 3.546265888214111 valid 3.5854547023773193
EPOCH 400:
  batch 1000 loss: 3.553737188577652
LOSS train 3.553737188577652 valid 3.585084915161133
EPOCH 401:
  batch 1000 loss: 3.54917203605175
LOSS train 3.54917203605175 valid 3.5855941772460938
EPOCH 402:
  batch 1000 loss: 3.5546190474033357
LOSS train 3.5546190474033357 valid 3.5849952697753906
EPOCH 403:
  batch 1000 loss: 3.5566914818286897
LOSS train 3.5566914818286897 valid 3.5845580101013184
EPOCH 404:
  batch 1000 loss: 3.534160053014755
LOSS train 3.534160053014755 valid 3.585749864578247
EPOCH 405:
  batch 1000 loss: 3.551907339453697
LOSS train 3.551907339453697 valid 3.585545301437378
EPOCH 406:
  batch 1000 loss: 3.5273092752695083
LOSS train 3.5273092752695083 valid 3.585681915283203
EPOCH 407:
  batch 1000 loss: 3.5314611761569976
LOSS train 3.5314611761569976 valid 3.585585355758667
EPOCH 408:
  batch 1000 loss: 3.554103083372116
LOSS train 3.554103083372116 valid 3.5847203731536865
EPOCH 409:
  batch 1000 loss: 3.5510011357069016
LOSS train 3.5510011357069016 valid 3.585742235183716
EPOCH 410:
  batch 1000 loss: 3.5457546212673186
LOSS train 3.5457546212673186 valid 3.5853614807128906
EPOCH 411:
  batch 1000 loss: 3.5568689203262327
LOSS train 3.5568689203262327 valid 3.5846009254455566
EPOCH 412:
  batch 1000 loss: 3.565858922481537
LOSS train 3.565858922481537 valid 3.585296630859375
EPOCH 413:
  batch 1000 loss: 3.5486097244024277
LOSS train 3.5486097244024277 valid 3.5858583450317383
EPOCH 414:
  batch 1000 loss: 3.5552798025608063
LOSS train 3.5552798025608063 valid 3.585477113723755
EPOCH 415:
  batch 1000 loss: 3.5476912851333617
LOSS train 3.5476912851333617 valid 3.585787296295166
EPOCH 416:
  batch 1000 loss: 3.557457566022873
LOSS train 3.557457566022873 valid 3.5854458808898926
EPOCH 417:
  batch 1000 loss: 3.558903070807457
LOSS train 3.558903070807457 valid 3.5854039192199707
EPOCH 418:
  batch 1000 loss: 3.5467750881910325
LOSS train 3.5467750881910325 valid 3.586082696914673
EPOCH 419:
  batch 1000 loss: 3.559292693376541
LOSS train 3.559292693376541 valid 3.5858092308044434
EPOCH 420:
  batch 1000 loss: 3.532777665734291
LOSS train 3.532777665734291 valid 3.585491418838501
EPOCH 421:
  batch 1000 loss: 3.534808545470238
LOSS train 3.534808545470238 valid 3.585174083709717
EPOCH 422:
  batch 1000 loss: 3.5709447939395904
LOSS train 3.5709447939395904 valid 3.5864028930664062
EPOCH 423:
  batch 1000 loss: 3.54731135737896
LOSS train 3.54731135737896 valid 3.584016799926758
EPOCH 424:
  batch 1000 loss: 3.553808291912079
LOSS train 3.553808291912079 valid 3.5862183570861816
EPOCH 425:
  batch 1000 loss: 3.5399242796897887
LOSS train 3.5399242796897887 valid 3.5861620903015137
EPOCH 426:
  batch 1000 loss: 3.5367829505205153
LOSS train 3.5367829505205153 valid 3.585177183151245
EPOCH 427:
  batch 1000 loss: 3.5460058344602583
LOSS train 3.5460058344602583 valid 3.5844411849975586
EPOCH 428:
  batch 1000 loss: 3.5506941931247713
LOSS train 3.5506941931247713 valid 3.58524489402771
EPOCH 429:
  batch 1000 loss: 3.5444672119617464
LOSS train 3.5444672119617464 valid 3.5854578018188477
EPOCH 430:
  batch 1000 loss: 3.552509038925171
LOSS train 3.552509038925171 valid 3.585597276687622
EPOCH 431:
  batch 1000 loss: 3.5359193638563156
LOSS train 3.5359193638563156 valid 3.585611343383789
EPOCH 432:
  batch 1000 loss: 3.561604715824127
LOSS train 3.561604715824127 valid 3.585515022277832
EPOCH 433:
  batch 1000 loss: 3.5567038106918334
LOSS train 3.5567038106918334 valid 3.585798501968384
EPOCH 434:
  batch 1000 loss: 3.5566948158740996
LOSS train 3.5566948158740996 valid 3.58577561378479
EPOCH 435:
  batch 1000 loss: 3.5453009612560273
LOSS train 3.5453009612560273 valid 3.585681438446045
EPOCH 436:
  batch 1000 loss: 3.5457502853870393
LOSS train 3.5457502853870393 valid 3.5847134590148926
EPOCH 437:
  batch 1000 loss: 3.5564127717018126
LOSS train 3.5564127717018126 valid 3.58478045463562
EPOCH 438:
  batch 1000 loss: 3.5575642676353456
LOSS train 3.5575642676353456 valid 3.5869228839874268
EPOCH 439:
  batch 1000 loss: 3.5455242348909377
LOSS train 3.5455242348909377 valid 3.5852394104003906
EPOCH 440:
  batch 1000 loss: 3.548411250114441
LOSS train 3.548411250114441 valid 3.5858335494995117
EPOCH 441:
  batch 1000 loss: 3.5488289389610292
LOSS train 3.5488289389610292 valid 3.586031675338745
EPOCH 442:
  batch 1000 loss: 3.5446792895793915
LOSS train 3.5446792895793915 valid 3.5853798389434814
EPOCH 443:
  batch 1000 loss: 3.5330459862947463
LOSS train 3.5330459862947463 valid 3.5863101482391357
EPOCH 444:
  batch 1000 loss: 3.549759997844696
LOSS train 3.549759997844696 valid 3.5864548683166504
EPOCH 445:
  batch 1000 loss: 3.5500019134283067
LOSS train 3.5500019134283067 valid 3.586148500442505
EPOCH 446:
  batch 1000 loss: 3.5444890649318697
LOSS train 3.5444890649318697 valid 3.5854856967926025
EPOCH 447:
  batch 1000 loss: 3.5621715576648714
LOSS train 3.5621715576648714 valid 3.585251808166504
EPOCH 448:
  batch 1000 loss: 3.5510206863880156
LOSS train 3.5510206863880156 valid 3.5854618549346924
EPOCH 449:
  batch 1000 loss: 3.560656334400177
LOSS train 3.560656334400177 valid 3.5856730937957764
EPOCH 450:
  batch 1000 loss: 3.564450091958046
LOSS train 3.564450091958046 valid 3.5853443145751953
EPOCH 451:
  batch 1000 loss: 3.536359186768532
LOSS train 3.536359186768532 valid 3.5855677127838135
EPOCH 452:
  batch 1000 loss: 3.549246044039726
LOSS train 3.549246044039726 valid 3.5860812664031982
EPOCH 453:
  batch 1000 loss: 3.559929481625557
LOSS train 3.559929481625557 valid 3.586254358291626
EPOCH 454:
  batch 1000 loss: 3.551886850595474
LOSS train 3.551886850595474 valid 3.5858047008514404
EPOCH 455:
  batch 1000 loss: 3.536119549036026
LOSS train 3.536119549036026 valid 3.5845913887023926
EPOCH 456:
  batch 1000 loss: 3.557372390151024
LOSS train 3.557372390151024 valid 3.5857157707214355
EPOCH 457:
  batch 1000 loss: 3.5486298274993895
LOSS train 3.5486298274993895 valid 3.58479380607605
EPOCH 458:
  batch 1000 loss: 3.557791607737541
LOSS train 3.557791607737541 valid 3.5848164558410645
EPOCH 459:
  batch 1000 loss: 3.541402764439583
LOSS train 3.541402764439583 valid 3.5857691764831543
EPOCH 460:
  batch 1000 loss: 3.5485034679174423
LOSS train 3.5485034679174423 valid 3.5861263275146484
EPOCH 461:
  batch 1000 loss: 3.534083092212677
LOSS train 3.534083092212677 valid 3.5851809978485107
EPOCH 462:
  batch 1000 loss: 3.543195232629776
LOSS train 3.543195232629776 valid 3.5853281021118164
EPOCH 463:
  batch 1000 loss: 3.5445558264255523
LOSS train 3.5445558264255523 valid 3.5854580402374268
EPOCH 464:
  batch 1000 loss: 3.540091156244278
LOSS train 3.540091156244278 valid 3.585691213607788
EPOCH 465:
  batch 1000 loss: 3.553168073415756
LOSS train 3.553168073415756 valid 3.5861763954162598
EPOCH 466:
  batch 1000 loss: 3.538814460515976
LOSS train 3.538814460515976 valid 3.5848305225372314
EPOCH 467:
  batch 1000 loss: 3.5698839049339295
LOSS train 3.5698839049339295 valid 3.5846328735351562
EPOCH 468:
  batch 1000 loss: 3.556904987692833
LOSS train 3.556904987692833 valid 3.5855345726013184
EPOCH 469:
  batch 1000 loss: 3.555946726322174
LOSS train 3.555946726322174 valid 3.5859506130218506
EPOCH 470:
  batch 1000 loss: 3.5460985176563264
LOSS train 3.5460985176563264 valid 3.584030866622925
EPOCH 471:
  batch 1000 loss: 3.5364658399820326
LOSS train 3.5364658399820326 valid 3.584559202194214
EPOCH 472:
  batch 1000 loss: 3.554172984004021
LOSS train 3.554172984004021 valid 3.5853312015533447
EPOCH 473:
  batch 1000 loss: 3.540238422393799
LOSS train 3.540238422393799 valid 3.585339307785034
EPOCH 474:
  batch 1000 loss: 3.542167507648468
LOSS train 3.542167507648468 valid 3.5849716663360596
EPOCH 475:
  batch 1000 loss: 3.552130628347397
LOSS train 3.552130628347397 valid 3.5856103897094727
EPOCH 476:
  batch 1000 loss: 3.5459331681728363
LOSS train 3.5459331681728363 valid 3.585878849029541
EPOCH 477:
  batch 1000 loss: 3.540825493812561
LOSS train 3.540825493812561 valid 3.5857105255126953
EPOCH 478:
  batch 1000 loss: 3.5520864909887315
LOSS train 3.5520864909887315 valid 3.585653066635132
EPOCH 479:
  batch 1000 loss: 3.5625931062698366
LOSS train 3.5625931062698366 valid 3.585740566253662
EPOCH 480:
  batch 1000 loss: 3.54671152305603
LOSS train 3.54671152305603 valid 3.5853304862976074
EPOCH 481:
  batch 1000 loss: 3.5381267448663714
LOSS train 3.5381267448663714 valid 3.584195375442505
EPOCH 482:
  batch 1000 loss: 3.5419104111194613
LOSS train 3.5419104111194613 valid 3.585853338241577
EPOCH 483:
  batch 1000 loss: 3.5563578135967253
LOSS train 3.5563578135967253 valid 3.5851218700408936
EPOCH 484:
  batch 1000 loss: 3.547307657957077
LOSS train 3.547307657957077 valid 3.5858054161071777
EPOCH 485:
  batch 1000 loss: 3.5305545132160185
LOSS train 3.5305545132160185 valid 3.5856974124908447
EPOCH 486:
  batch 1000 loss: 3.545392477273941
LOSS train 3.545392477273941 valid 3.5851757526397705
EPOCH 487:
  batch 1000 loss: 3.5407927269935606
LOSS train 3.5407927269935606 valid 3.585336685180664
EPOCH 488:
  batch 1000 loss: 3.5390084373950956
LOSS train 3.5390084373950956 valid 3.584979295730591
EPOCH 489:
  batch 1000 loss: 3.538403481125832
LOSS train 3.538403481125832 valid 3.5863966941833496
EPOCH 490:
  batch 1000 loss: 3.55546204662323
LOSS train 3.55546204662323 valid 3.5859363079071045
EPOCH 491:
  batch 1000 loss: 3.559226755619049
LOSS train 3.559226755619049 valid 3.5858514308929443
EPOCH 492:
  batch 1000 loss: 3.5547604213953017
LOSS train 3.5547604213953017 valid 3.5856947898864746
EPOCH 493:
  batch 1000 loss: 3.5490192267894747
LOSS train 3.5490192267894747 valid 3.5848605632781982
EPOCH 494:
  batch 1000 loss: 3.5319310536384583
LOSS train 3.5319310536384583 valid 3.585613489151001
EPOCH 495:
  batch 1000 loss: 3.547927903294563
LOSS train 3.547927903294563 valid 3.5857045650482178
EPOCH 496:
  batch 1000 loss: 3.5435169063806535
LOSS train 3.5435169063806535 valid 3.5854053497314453
EPOCH 497:
  batch 1000 loss: 3.574893291711807
LOSS train 3.574893291711807 valid 3.5855884552001953
EPOCH 498:
  batch 1000 loss: 3.547457062959671
LOSS train 3.547457062959671 valid 3.584460973739624
EPOCH 499:
  batch 1000 loss: 3.5598399039506914
LOSS train 3.5598399039506914 valid 3.585294485092163
EPOCH 500:
  batch 1000 loss: 3.5450632836818694
LOSS train 3.5450632836818694 valid 3.585585117340088
